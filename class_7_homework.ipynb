{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1d9404",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation & Fine-Tuning (QLoRA) Assignment\n",
    "\n",
    "## Project Design\n",
    "\n",
    "This week‚Äôs project involves creating a synthetic dataset and using it to fine-tune the model for better academic Q\\&A performance. The plan is as follows:\n",
    "\n",
    "1. **Data Sampling:** Select **100 academic papers** (e.g. using their abstracts and key sections). Ensure a diverse mix of subjects or paper types to provide a broad training base.\n",
    "2. **Synthetic Q\\&A Generation:** Use **GPT-4** to generate \\~5 question-answer pairs for each paper. Craft a prompt that provides GPT-4 with the paper‚Äôs abstract or content and asks for informative Q\\&A pairs. The questions should cover important points, definitions, or insights from the paper, and the answers should be correct summaries or explanations based on the text. This yields roughly **500 Q\\&A pairs** in total.\n",
    "3. **Include Edge-Case Examples:** Incorporate some **edge-case questions** among the above pairs ‚Äì for example, a question that reflects a misunderstanding or a **hallucinated detail** about the paper. For these, provide an answer that corrects the false premise or clarifies that the paper doesn‚Äôt contain that information. Including a few such Q\\&A examples (e.g. *‚ÄúQ: According to the paper, what is the value of constant XYZ?‚Äù* when XYZ is not actually in the paper, and *‚ÄúA: The paper does not specify XYZ; in fact, that detail is not discussed.‚Äù*) will teach the model to handle incorrect or unanswerable queries gracefully.\n",
    "4. **Format Data for Instruction Tuning:** Convert all the Q\\&A pairs into the **instruction-tuning JSONL format** expected by our fine-tuning pipeline. Each line in the dataset should represent a complete prompt-response dialogue. We will use a chat-style format with explicit roles. For example, you can prepend a fixed system instruction (such as `\"You are a helpful academic assistant.\"`) and then format each Q\\&A as:\n",
    "\n",
    "   ```\n",
    "   <|system|> You are a helpful academic Q&A assistant specialized in scholarly content.\n",
    "   <|user|> [Question from the dataset]\n",
    "   <|assistant|> [Answer from the dataset]\n",
    "   ```\n",
    "\n",
    "   Structure each JSONL entry to contain this composite prompt. This ensures the model is trained in a conversational format where it receives a user question and produces an answer, following any system instructions (tone, style) you provided.\n",
    "5. **Fine-Tune LLaMA¬†3 7B with QLoRA:** Run a fine-tuning job on **Google Colab** (or a local GPU) using **QLoRA** via the Unsloth library. QLoRA (Quantized LoRA) will load the 7B model in 4-bit precision and train low-rank adaptation weights. This drastically lowers memory usage, allowing even a 7B (and larger) model to be fine-tuned on a single GPU without out-of-memory errors. Using Unsloth‚Äôs tools, load the base LLaMA¬†3 (7B) model (preferably an instruct variant) and fine-tune it on your synthetic Q\\&A dataset. We‚Äôll use LoRA adapters so the base model weights remain fixed; the training will produce a small set of adapted weights after 1‚Äì3 epochs over the dataset. *(Expect the fine-tuning to be relatively fast given \\~500 examples ‚Äî on a T4 or similar GPU, a few epochs should only take minutes.)*\n",
    "6. **Evaluation (Pre vs. Post-Tuning):** Finally, evaluate the model‚Äôs academic QA performance **before and after fine-tuning**. Prepare a set of **10 test questions** covering various papers or concepts (you can come up with these manually, ensuring they are challenging). Run the original base model and the fine-tuned model on each question, and compare the answers. Look for improvements such as: the fine-tuned model‚Äôs answers are more detailed, use terminology from the papers, correct mistakes the base model made, or cite relevant concepts from the training data. This comparison will let you quantify accuracy gains. You might measure accuracy as the number of questions answered correctly or with relevant info, or simply note qualitatively how the responses differ.\n",
    "\n",
    "Throughout this design, the key idea is that **domain-aligned data** will make the model more knowledgeable in that domain. Instead of the agent relying solely on retrieval each time, the fine-tuned model will have *internalized* some academic knowledge and answer patterns. Fine-tuning on a well-structured QA dataset (as opposed to just dumping raw text) is crucial for the model to learn effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1e584",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fc631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting arxiv\n",
      "  Downloading arxiv-2.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting dotenv\n",
      "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.5.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting feedparser~=6.0.10 (from arxiv)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting requests~=2.32.0 (from arxiv)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.32.0->arxiv) (2024.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (23.2.0)\n",
      "Collecting python-dotenv (from dotenv)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading arxiv-2.3.1-py3-none-any.whl (11 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading pypdf-6.5.0-py3-none-any.whl (329 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "\u001b[33m  DEPRECATION: Building 'sgmllib3k' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'sgmllib3k'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6089 sha256=bf375e0b978f7b18739692d5bec43fb631668063aaab1de3e387f31e99232845\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-va_s13tz/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, requests, python-dotenv, pypdf, jsonlines, jiter, feedparser, distro, dotenv, arxiv, openai\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11/11\u001b[0m [openai]10/11\u001b[0m [openai]ser]\n",
      "\u001b[1A\u001b[2KSuccessfully installed arxiv-2.3.1 distro-1.9.0 dotenv-0.9.9 feedparser-6.0.12 jiter-0.12.0 jsonlines-4.0.0 openai-2.14.0 pypdf-6.5.0 python-dotenv-1.2.1 requests-2.32.5 sgmllib3k-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install arxiv openai tqdm pandas jsonlines dotenv pypdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "697bf8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using .env at: /home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin/.env\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import arxiv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "# üîë Set your OpenAI API key\n",
    "\n",
    "# Load environment variables (make sure you have OPENAI_API_KEY in your .env file)\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ENV_PATH = Path.cwd() / \".env\"\n",
    "load_dotenv(dotenv_path=ENV_PATH, override=True)\n",
    "\n",
    "print(\"Using .env at:\", ENV_PATH)\n",
    "\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"dataset_arxiv_json\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785806cb",
   "metadata": {},
   "source": [
    "## Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558eede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching arXiv categories:   0%|          | 0/13 [00:00<?, ?it/s]/tmp/ipykernel_4929/1861694540.py:105: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n",
      "Fetching arXiv categories:  15%|‚ñà‚ñå        | 2/13 [02:56<16:01, 87.40s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 44 0 (offset 0)\n",
      "Ignoring wrong pointing object 53 0 (offset 0)\n",
      "Ignoring wrong pointing object 65 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 69 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 114 0 (offset 0)\n",
      "Ignoring wrong pointing object 116 0 (offset 0)\n",
      "Ignoring wrong pointing object 138 0 (offset 0)\n",
      "Ignoring wrong pointing object 230 0 (offset 0)\n",
      "Fetching arXiv categories:  23%|‚ñà‚ñà‚ñé       | 3/13 [04:24<14:38, 87.83s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 117 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n",
      "Ignoring wrong pointing object 237 0 (offset 0)\n",
      "Ignoring wrong pointing object 244 0 (offset 0)\n",
      "Fetching arXiv categories:  31%|‚ñà‚ñà‚ñà       | 4/13 [05:27<11:40, 77.81s/it]Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Fetching arXiv categories:  38%|‚ñà‚ñà‚ñà‚ñä      | 5/13 [06:38<10:04, 75.53s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 49 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Ignoring wrong pointing object 75 0 (offset 0)\n",
      "Ignoring wrong pointing object 77 0 (offset 0)\n",
      "Ignoring wrong pointing object 111 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 37 0 (offset 0)\n",
      "Ignoring wrong pointing object 39 0 (offset 0)\n",
      "Ignoring wrong pointing object 55 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Ignoring wrong pointing object 83 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 37 0 (offset 0)\n",
      "Ignoring wrong pointing object 96 0 (offset 0)\n",
      "Ignoring wrong pointing object 98 0 (offset 0)\n",
      "Ignoring wrong pointing object 140 0 (offset 0)\n",
      "Ignoring wrong pointing object 143 0 (offset 0)\n",
      "Ignoring wrong pointing object 145 0 (offset 0)\n",
      "Ignoring wrong pointing object 150 0 (offset 0)\n",
      "Ignoring wrong pointing object 152 0 (offset 0)\n",
      "Ignoring wrong pointing object 231 0 (offset 0)\n",
      "Ignoring wrong pointing object 235 0 (offset 0)\n",
      "Ignoring wrong pointing object 237 0 (offset 0)\n",
      "Ignoring wrong pointing object 239 0 (offset 0)\n",
      "Ignoring wrong pointing object 241 0 (offset 0)\n",
      "Ignoring wrong pointing object 243 0 (offset 0)\n",
      "Ignoring wrong pointing object 255 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "Ignoring wrong pointing object 322 0 (offset 0)\n",
      "Ignoring wrong pointing object 331 0 (offset 0)\n",
      "Ignoring wrong pointing object 348 0 (offset 0)\n",
      "Ignoring wrong pointing object 358 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 57 0 (offset 0)\n",
      "Fetching arXiv categories:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 8/13 [07:39<02:41, 32.36s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 27 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 85 0 (offset 0)\n",
      "Ignoring wrong pointing object 87 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 97 0 (offset 0)\n",
      "Ignoring wrong pointing object 99 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 106 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 123 0 (offset 0)\n",
      "Ignoring wrong pointing object 131 0 (offset 0)\n",
      "Fetching arXiv categories:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 10/13 [09:35<02:13, 44.37s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 90 0 (offset 0)\n",
      "Ignoring wrong pointing object 92 0 (offset 0)\n",
      "Ignoring wrong pointing object 94 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 110 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 118 0 (offset 0)\n",
      "Ignoring wrong pointing object 126 0 (offset 0)\n",
      "Ignoring wrong pointing object 128 0 (offset 0)\n",
      "Ignoring wrong pointing object 141 0 (offset 0)\n",
      "Ignoring wrong pointing object 143 0 (offset 0)\n",
      "Ignoring wrong pointing object 145 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 164 0 (offset 0)\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 32 0 (offset 0)\n",
      "Ignoring wrong pointing object 127 0 (offset 0)\n",
      "Ignoring wrong pointing object 148 0 (offset 0)\n",
      "Ignoring wrong pointing object 175 0 (offset 0)\n",
      "Fetching arXiv categories:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 11/13 [10:43<01:43, 51.58s/it]Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 46 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 59 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "Fetching arXiv categories: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [13:45<00:00, 63.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved (metadata): 455\n",
      "‚úÖ Enriched (p1-5 text): 455\n",
      "‚ö†Ô∏è Extraction failed: 3\n",
      "üì¶ Output folder size: 4.26 MB\n",
      "- papers_meta.jsonl.gz: 0.40 MB\n",
      "- papers_text_p1_5.jsonl.gz: 3.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, gzip, time, hashlib, tempfile\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, Iterable, Set\n",
    "\n",
    "import arxiv\n",
    "from tqdm import tqdm\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "CATEGORIES = [\n",
    "    \"q-fin.MF\", \"q-fin.TR\", \"q-fin.ST\", \"q-fin.RM\", \"q-fin.PR\",\n",
    "    \"q-fin.CP\", \"q-fin\", \"q-fin.EC\", \"q-fin.GN\", \"q-fin.PM\", \n",
    "    \"econ.EM\", \"econ.GN\", \"econ.TH\"\n",
    "]\n",
    "MAX_RESULTS_PER_CAT = 50\n",
    "\n",
    "FIRST_N_PAGES = 10\n",
    "MAX_BODY_CHARS = 25000\n",
    "MAX_ABS_CHARS  = 3000\n",
    "MIN_BODY_CHARS = 3000\n",
    "\n",
    "\n",
    "OUT_DIR = Path(\"arxiv_finance_corpus\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "META_PATH = OUT_DIR / \"papers_meta.jsonl.gz\"\n",
    "TEXT_PATH = OUT_DIR / \"papers_text_p1_10.jsonl.gz\"\n",
    "\n",
    "SLEEP_BETWEEN_REQUESTS_SEC = 0.5  # be polite / avoid throttling\n",
    "\n",
    "# -----------------------------\n",
    "# Utilities\n",
    "# -----------------------------\n",
    "_ws = re.compile(r\"\\s+\")\n",
    "def clean_text(s: str) -> str:\n",
    "    if not s:\n",
    "        return \"\"\n",
    "    s = s.replace(\"\\x00\", \" \")\n",
    "    s = _ws.sub(\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def safe_trunc(s: str, max_chars: int) -> str:\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    # cut on a boundary to avoid mid-word spam\n",
    "    cut = s[:max_chars]\n",
    "    last_space = cut.rfind(\" \")\n",
    "    return (cut[:last_space] if last_space > 0 else cut).rstrip()\n",
    "\n",
    "def sha1(s: str) -> str:\n",
    "    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()\n",
    "\n",
    "def gzip_jsonl_append(path: Path, record: Dict[str, Any]) -> None:\n",
    "    # append in text mode\n",
    "    with gzip.open(path, \"at\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def extract_first_pages_text(pdf_path: Path, n_pages: int) -> str:\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "    texts = []\n",
    "    for i in range(min(n_pages, len(reader.pages))):\n",
    "        try:\n",
    "            t = reader.pages[i].extract_text() or \"\"\n",
    "        except Exception:\n",
    "            t = \"\"\n",
    "        texts.append(t)\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "def download_pdf_to_temp(result: arxiv.Result) -> Path:\n",
    "    # arxiv library can download via result.download_pdf()\n",
    "    # We force temp dir and then delete after.\n",
    "    tmpdir = Path(tempfile.mkdtemp(prefix=\"arxiv_pdf_\"))\n",
    "    pdf_path = Path(result.download_pdf(dirpath=str(tmpdir)))\n",
    "    return pdf_path\n",
    "\n",
    "def sizeof_dir(path: Path) -> int:\n",
    "    total = 0\n",
    "    for p in path.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            total += p.stat().st_size\n",
    "    return total\n",
    "\n",
    "# -----------------------------\n",
    "# Main collection\n",
    "# -----------------------------\n",
    "seen_ids: Set[str] = set()\n",
    "retrieved = 0\n",
    "enriched = 0\n",
    "failed_extract = 0\n",
    "\n",
    "# fresh files each run (comment out if you want to append)\n",
    "for p in [META_PATH, TEXT_PATH]:\n",
    "    if p.exists():\n",
    "        p.unlink()\n",
    "\n",
    "for cat in tqdm(CATEGORIES, desc=\"Fetching arXiv categories\"):\n",
    "    search = arxiv.Search(\n",
    "        query=f\"cat:{cat}\",\n",
    "        max_results=MAX_RESULTS_PER_CAT,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    for result in search.results():\n",
    "        arxiv_id = (result.get_short_id() if hasattr(result, \"get_short_id\") else None) or result.entry_id\n",
    "        arxiv_id = arxiv_id.replace(\"http://arxiv.org/abs/\", \"\").replace(\"https://arxiv.org/abs/\", \"\")\n",
    "        if arxiv_id in seen_ids:\n",
    "            continue\n",
    "        seen_ids.add(arxiv_id)\n",
    "\n",
    "        title = clean_text(result.title or \"\")\n",
    "        abstract = clean_text(result.summary or \"\")\n",
    "        abstract = safe_trunc(abstract, MAX_ABS_CHARS)\n",
    "\n",
    "        authors = []\n",
    "        try:\n",
    "            authors = [a.name for a in (result.authors or [])][:8]\n",
    "        except Exception:\n",
    "            authors = []\n",
    "\n",
    "        categories = []\n",
    "        try:\n",
    "            categories = list(getattr(result, \"categories\", []) or [])\n",
    "        except Exception:\n",
    "            categories = []\n",
    "\n",
    "        published = None\n",
    "        try:\n",
    "            published = result.published.isoformat() if result.published else None\n",
    "        except Exception:\n",
    "            published = None\n",
    "\n",
    "        pdf_url = \"\"\n",
    "        try:\n",
    "            pdf_url = result.pdf_url or \"\"\n",
    "        except Exception:\n",
    "            pdf_url = \"\"\n",
    "\n",
    "        meta = {\n",
    "            \"id\": arxiv_id,\n",
    "            \"source_category\": cat,\n",
    "            \"primary_title\": title,\n",
    "            \"authors\": authors,\n",
    "            \"categories\": categories,\n",
    "            \"published\": published,\n",
    "            \"pdf_url\": pdf_url,\n",
    "            \"abstract\": abstract,\n",
    "            \"abstract_chars\": len(abstract),\n",
    "            \"title_hash\": sha1(title.lower()),\n",
    "        }\n",
    "        gzip_jsonl_append(META_PATH, meta)\n",
    "        retrieved += 1\n",
    "\n",
    "        # Enrich: first 5 pages text (then discard pdf)\n",
    "        body_text = \"\"\n",
    "        ok = True\n",
    "        try:\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS_SEC)\n",
    "            pdf_path = download_pdf_to_temp(result)\n",
    "            raw = extract_first_pages_text(pdf_path, FIRST_N_PAGES)\n",
    "            body_text = clean_text(raw)\n",
    "            body_text = safe_trunc(body_text, MAX_BODY_CHARS)\n",
    "        except Exception:\n",
    "            ok = False\n",
    "            failed_extract += 1\n",
    "        finally:\n",
    "            # delete temp dir\n",
    "            try:\n",
    "                if \"pdf_path\" in locals() and pdf_path.exists():\n",
    "                    tmp = pdf_path.parent\n",
    "                    for fp in tmp.glob(\"*\"):\n",
    "                        fp.unlink(missing_ok=True)\n",
    "                    tmp.rmdir()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        text_rec = {\n",
    "            **meta,\n",
    "            \"body_p1_5\": body_text,\n",
    "            \"body_chars\": len(body_text),\n",
    "            \"extraction_ok\": ok,\n",
    "        }\n",
    "        gzip_jsonl_append(TEXT_PATH, text_rec)\n",
    "        enriched += 1\n",
    "\n",
    "print(f\"‚úÖ Retrieved (metadata): {retrieved}\")\n",
    "print(f\"‚úÖ Enriched (p1-5 text): {enriched}\")\n",
    "print(f\"‚ö†Ô∏è Extraction failed: {failed_extract}\")\n",
    "\n",
    "total_bytes = sizeof_dir(OUT_DIR)\n",
    "print(f\"üì¶ Output folder size: {total_bytes/1024/1024:.2f} MB\")\n",
    "print(f\"- {META_PATH.name}: {META_PATH.stat().st_size/1024/1024:.2f} MB\")\n",
    "print(f\"- {TEXT_PATH.name}: {TEXT_PATH.stat().st_size/1024/1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b16fdfe",
   "metadata": {},
   "source": [
    "## Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1bcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_PATH: arxiv_finance_corpus/papers_text_p1_10.jsonl.gz (exists=True)\n",
      "OUT_PATH: arxiv_finance_corpus/synthetic_finance_qa.chatml.jsonl\n",
      "Counting papers (for progress bar)...\n",
      "Total records in corpus file: 451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:   2%|‚ñè         | 10/451 [07:11<4:51:18, 39.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=10/451 | used=10 | qas=50 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=7.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:   4%|‚ñç         | 19/451 [15:31<6:31:00, 54.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=20/451 | used=20 | qas=100 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=17.0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:   7%|‚ñã         | 30/451 [26:26<7:03:20, 60.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=30/451 | used=30 | qas=150 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=26.4m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:   9%|‚ñâ         | 40/451 [35:25<5:36:59, 49.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=40/451 | used=40 | qas=200 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=35.4m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  11%|‚ñà         | 50/451 [46:32<6:41:36, 60.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=50/451 | used=50 | qas=250 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=46.5m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  13%|‚ñà‚ñé        | 60/451 [54:56<5:24:13, 49.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=60/451 | used=60 | qas=300 | skipped(extraction=0, short=0, empty_body=0) | model_failures=0 | elapsed=54.9m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  15%|‚ñà‚ñå        | 69/451 [1:01:45<5:18:12, 49.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=70/451 | used=69 | qas=345 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=62.6m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  18%|‚ñà‚ñä        | 79/451 [1:10:55<5:07:39, 49.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=80/451 | used=79 | qas=395 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=71.6m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  20%|‚ñà‚ñâ        | 90/451 [1:20:19<5:00:27, 49.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: read=90/451 | used=89 | qas=445 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=80.3m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  20%|‚ñà‚ñà        | 91/451 [1:20:54<4:32:47, 45.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Paper #92 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #92 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  20%|‚ñà‚ñà        | 92/451 [1:21:06<3:32:00, 35.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #92 FAILED after 3 retries. id=2510.22341v1\n",
      "   title='Understanding Carbon Trade Dynamics: A European Union Emissions Trading System Perspective'\n",
      "\n",
      "‚ö†Ô∏è Paper #93 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #93 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  21%|‚ñà‚ñà        | 93/451 [1:21:17<2:47:58, 28.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #93 FAILED after 3 retries. id=2510.22206v1\n",
      "   title='Right Place, Right Time: Market Simulation-based RL for Execution Optimisation'\n",
      "\n",
      "‚ö†Ô∏è Paper #94 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #94 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  21%|‚ñà‚ñà        | 94/451 [1:21:28<2:16:05, 22.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #94 FAILED after 3 retries. id=2510.17165v1\n",
      "   title='Trading with the Devil: Risk and Return in Foundation Model Strategies'\n",
      "\n",
      "‚ö†Ô∏è Paper #95 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #95 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  21%|‚ñà‚ñà        | 95/451 [1:21:38<1:53:20, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #95 FAILED after 3 retries. id=2510.15612v1\n",
      "   title='SoK: Market Microstructure for Decentralized Prediction Markets (DePMs)'\n",
      "\n",
      "‚ö†Ô∏è Paper #96 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #96 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  21%|‚ñà‚ñà‚ñè       | 96/451 [1:21:49<1:38:06, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #96 FAILED after 3 retries. id=2510.15995v1\n",
      "   title='The Invisible Handshake: Tacit Collusion between Adaptive Market Agents'\n",
      "\n",
      "‚ö†Ô∏è Paper #97 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #97 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  22%|‚ñà‚ñà‚ñè       | 97/451 [1:21:59<1:26:39, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #97 FAILED after 3 retries. id=2512.20477v1\n",
      "   title='Switching between states and the COVID-19 turbulence'\n",
      "\n",
      "‚ö†Ô∏è Paper #98 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #98 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  22%|‚ñà‚ñà‚ñè       | 98/451 [1:22:09<1:18:18, 13.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #98 FAILED after 3 retries. id=2512.20460v1\n",
      "   title='The Aligned Economic Index & The State Switching Model'\n",
      "\n",
      "‚ö†Ô∏è Paper #99 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #99 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  22%|‚ñà‚ñà‚ñè       | 99/451 [1:22:19<1:13:10, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #99 FAILED after 3 retries. id=2512.17225v1\n",
      "   title='Modelling financial time series with $œÜ^{4}$ quantum field theory'\n",
      "\n",
      "‚ö†Ô∏è Paper #100 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #100 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  22%|‚ñà‚ñà‚ñè       | 100/451 [1:22:30<1:09:38, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #100 FAILED after 3 retries. id=2512.17945v1\n",
      "   title=\"What's the Price of Monotonicity? A Multi-Dataset Benchmark of Monotone-Constrained Gradient Boosting for Credit PD\"\n",
      "\n",
      "‚ö†Ô∏è Paper #102 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #102 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  23%|‚ñà‚ñà‚ñé       | 102/451 [1:22:41<51:45,  8.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #102 FAILED after 3 retries. id=2512.12334v1\n",
      "   title='Extending the application of dynamic Bayesian networks in calculating market risk: Standard and stressed expected shortf'\n",
      "\n",
      "‚ö†Ô∏è Paper #103 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #103 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  23%|‚ñà‚ñà‚ñé       | 103/451 [1:22:51<54:09,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #103 FAILED after 3 retries. id=2512.12054v1\n",
      "   title='Universal Dynamics of Financial Bubbles in Isolated Markets: Evidence from the Iranian Stock Market'\n",
      "\n",
      "‚ö†Ô∏è Paper #104 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #104 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  23%|‚ñà‚ñà‚ñé       | 104/451 [1:23:02<55:36,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #104 FAILED after 3 retries. id=2512.19705v1\n",
      "   title='Generative AI for Analysts'\n",
      "\n",
      "‚ö†Ô∏è Paper #105 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #105 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  23%|‚ñà‚ñà‚ñé       | 105/451 [1:23:12<56:38,  9.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #105 FAILED after 3 retries. id=2512.17936v1\n",
      "   title='Risk-Aware Financial Forecasting Enhanced by Machine Learning and Intuitionistic Fuzzy Multi-Criteria Decision-Making'\n",
      "\n",
      "‚ö†Ô∏è Paper #106 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #106 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  24%|‚ñà‚ñà‚ñé       | 106/451 [1:23:23<58:05, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #106 FAILED after 3 retries. id=2512.17929v1\n",
      "   title='Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation'\n",
      "\n",
      "‚ö†Ô∏è Paper #107 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #107 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  24%|‚ñà‚ñà‚ñé       | 107/451 [1:23:33<58:26, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #107 FAILED after 3 retries. id=2512.17925v1\n",
      "   title='Stylized Facts and Their Microscopic Origins: Clustering, Persistence, and Stability in a 2D Ising Framework'\n",
      "\n",
      "‚ö†Ô∏è Paper #108 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #108 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  24%|‚ñà‚ñà‚ñç       | 108/451 [1:23:44<59:02, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #108 FAILED after 3 retries. id=2512.08000v1\n",
      "   title=\"Analysis of Contagion in China's Stock Market: A Hawkes Process Perspective\"\n",
      "\n",
      "‚ö†Ô∏è Paper #109 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #109 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  24%|‚ñà‚ñà‚ñç       | 109/451 [1:23:55<59:31, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #109 FAILED after 3 retries. id=2512.17923v1\n",
      "   title='Inferring Latent Market Forces: Evaluating LLM Detection of Gamma Exposure Patterns via Obfuscation Testing'\n",
      "\n",
      "‚ö†Ô∏è Paper #110 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #110 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  24%|‚ñà‚ñà‚ñç       | 110/451 [1:24:05<59:03, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #110 FAILED after 3 retries. id=2512.15738v1\n",
      "   title='Hybrid Quantum-Classical Ensemble Learning for S\\\\&P 500 Directional Prediction'\n",
      "\n",
      "‚ö†Ô∏è Paper #111 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #111 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  25%|‚ñà‚ñà‚ñç       | 111/451 [1:24:16<59:20, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #111 FAILED after 3 retries. id=2512.06473v1\n",
      "   title='Detrended cross-correlations and their random matrix limit: an example from the cryptocurrency market'\n",
      "\n",
      "‚ö†Ô∏è Paper #112 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #112 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  25%|‚ñà‚ñà‚ñç       | 112/451 [1:24:26<59:26, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #112 FAILED after 3 retries. id=2512.06420v1\n",
      "   title='Thermodynamic description of world GDP distribution over countries'\n",
      "\n",
      "‚ö†Ô∏è Paper #113 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #113 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  25%|‚ñà‚ñà‚ñå       | 113/451 [1:24:37<58:49, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #113 FAILED after 3 retries. id=2512.07887v1\n",
      "   title='Does it take two to tango: Interaction between Credit Default Swaps and National Stock Indices'\n",
      "\n",
      "‚ö†Ô∏è Paper #114 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #114 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  25%|‚ñà‚ñà‚ñå       | 114/451 [1:24:48<59:15, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #114 FAILED after 3 retries. id=2512.07886v1\n",
      "   title='The Endogenous Constraint: Hysteresis, Stagflation, and the Structural Inhibition of Monetary Velocity in the Bitcoin Ne'\n",
      "\n",
      "‚ö†Ô∏è Paper #115 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #115 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  25%|‚ñà‚ñà‚ñå       | 115/451 [1:24:58<59:09, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #115 FAILED after 3 retries. id=2512.00893v1\n",
      "   title='Early-Warning Signals of Political Risk in Stablecoin Markets: Human and Algorithmic Behavior Around the 2024 U.S. Elect'\n",
      "\n",
      "‚ö†Ô∏è Paper #116 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #116 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  26%|‚ñà‚ñà‚ñå       | 116/451 [1:25:08<58:29, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #116 FAILED after 3 retries. id=2512.07860v1\n",
      "   title='Integrating LSTM Networks with Neural Levy Processes for Financial Forecasting'\n",
      "\n",
      "‚ö†Ô∏è Paper #117 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #117 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  26%|‚ñà‚ñà‚ñå       | 117/451 [1:25:19<58:33, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #117 FAILED after 3 retries. id=2511.18125v1\n",
      "   title='Random processes for long-term market simulations'\n",
      "\n",
      "‚ö†Ô∏è Paper #118 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #118 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  26%|‚ñà‚ñà‚ñå       | 118/451 [1:25:30<58:45, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #118 FAILED after 3 retries. id=2512.02037v1\n",
      "   title='Statistical Arbitrage in Polish Equities Market Using Deep Learning Techniques'\n",
      "\n",
      "‚ö†Ô∏è Paper #119 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #119 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  26%|‚ñà‚ñà‚ñã       | 119/451 [1:25:40<58:49, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #119 FAILED after 3 retries. id=2512.02029v1\n",
      "   title='HODL Strategy or Fantasy? 480 Million Crypto Market Simulations and the Macro-Sentiment Effect'\n",
      "\n",
      "‚ö†Ô∏è Paper #120 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #120 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  27%|‚ñà‚ñà‚ñã       | 120/451 [1:25:51<58:35, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #120 FAILED after 3 retries. id=2511.14408v1\n",
      "   title='The Hidden Constant of Market Rhythms: How $1-1/e$ Defines Scaling in Intrinsic Time'\n",
      "\n",
      "‚ö†Ô∏è Paper #121 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #121 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  27%|‚ñà‚ñà‚ñã       | 121/451 [1:26:02<58:15, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #121 FAILED after 3 retries. id=2511.13959v1\n",
      "   title='Opportunity Cost in Insurance'\n",
      "\n",
      "‚ö†Ô∏è Paper #122 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #122 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  27%|‚ñà‚ñà‚ñã       | 122/451 [1:26:12<58:01, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #122 FAILED after 3 retries. id=2511.13384v4\n",
      "   title='CBDC Stress Test in a Dual-Currency Setting'\n",
      "\n",
      "‚ö†Ô∏è Paper #123 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #123 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  27%|‚ñà‚ñà‚ñã       | 123/451 [1:26:23<57:58, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #123 FAILED after 3 retries. id=2511.12763v2\n",
      "   title='Impact by design: translating Lead times in flux into an R handbook with code'\n",
      "\n",
      "‚ö†Ô∏è Paper #124 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #124 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  27%|‚ñà‚ñà‚ñã       | 124/451 [1:26:33<57:51, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #124 FAILED after 3 retries. id=2511.08658v1\n",
      "   title='\"It Looks All the Same to Me\": Cross-index Training for Long-term Financial Series Prediction'\n",
      "\n",
      "‚ö†Ô∏è Paper #125 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #125 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  28%|‚ñà‚ñà‚ñä       | 125/451 [1:26:44<57:51, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #125 FAILED after 3 retries. id=2511.06224v1\n",
      "   title='Bitcoin Forecasting with Classical Time Series Models on Prices and Volatility'\n",
      "\n",
      "‚ö†Ô∏è Paper #126 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #126 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  28%|‚ñà‚ñà‚ñä       | 126/451 [1:26:55<57:22, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #126 FAILED after 3 retries. id=2511.08622v1\n",
      "   title='Multi-period Learning for Financial Time Series Forecasting'\n",
      "\n",
      "‚ö†Ô∏è Paper #127 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #127 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  28%|‚ñà‚ñà‚ñä       | 127/451 [1:27:05<57:05, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #127 FAILED after 3 retries. id=2511.08621v1\n",
      "   title='The LLM Pro Finance Suite: Multilingual Large Language Models for Financial Applications'\n",
      "\n",
      "‚ö†Ô∏è Paper #128 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #128 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  28%|‚ñà‚ñà‚ñä       | 128/451 [1:27:15<56:14, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #128 FAILED after 3 retries. id=2511.05030v2\n",
      "   title='The Shape of Markets: Machine learning modeling and Prediction Using 2-Manifold Geometries'\n",
      "\n",
      "‚ö†Ô∏è Paper #129 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #129 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  29%|‚ñà‚ñà‚ñä       | 129/451 [1:27:26<56:10, 10.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #129 FAILED after 3 retries. id=2511.04784v1\n",
      "   title='Insights into Tail-Based and Order Statistics'\n",
      "\n",
      "‚ö†Ô∏è Paper #130 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #130 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  29%|‚ñà‚ñà‚ñâ       | 130/451 [1:27:36<56:17, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #130 FAILED after 3 retries. id=2511.08616v1\n",
      "   title='Reasoning on Time-Series for Financial Technical Analysis'\n",
      "\n",
      "‚ö†Ô∏è Paper #131 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #131 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  29%|‚ñà‚ñà‚ñâ       | 131/451 [1:27:47<56:09, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #131 FAILED after 3 retries. id=2511.03314v1\n",
      "   title='Multifractality and sample size influence on Bitcoin volatility patterns'\n",
      "\n",
      "‚ö†Ô∏è Paper #132 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #132 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  29%|‚ñà‚ñà‚ñâ       | 132/451 [1:27:57<55:49, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #132 FAILED after 3 retries. id=2511.08608v1\n",
      "   title=\"When Reasoning Fails: Evaluating 'Thinking' LLMs for Stock Prediction\"\n",
      "\n",
      "‚ö†Ô∏è Paper #133 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #133 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  29%|‚ñà‚ñà‚ñâ       | 133/451 [1:28:08<56:08, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #133 FAILED after 3 retries. id=2511.01271v1\n",
      "   title='High-Dimensional Spatial Arbitrage Pricing Theory with Heterogeneous Interactions'\n",
      "\n",
      "‚ö†Ô∏è Paper #134 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #134 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  30%|‚ñà‚ñà‚ñâ       | 134/451 [1:28:19<56:04, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #134 FAILED after 3 retries. id=2510.26035v1\n",
      "   title='Budget Forecasting and Integrated Strategic Planning for Leaders'\n",
      "\n",
      "‚ö†Ô∏è Paper #135 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #135 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  30%|‚ñà‚ñà‚ñâ       | 135/451 [1:28:30<56:01, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #135 FAILED after 3 retries. id=2511.05523v1\n",
      "   title='The Evolution of Probabilistic Price Forecasting Techniques: A Review of the Day-Ahead, Intra-Day, and Balancing Markets'\n",
      "\n",
      "‚ö†Ô∏è Paper #136 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #136 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  30%|‚ñà‚ñà‚ñà       | 136/451 [1:28:40<55:52, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #136 FAILED after 3 retries. id=2512.21092v1\n",
      "   title='Portfolio Optimization for Index Tracking with Constraints on Downside Risk and Carbon Footprint'\n",
      "\n",
      "‚ö†Ô∏è Paper #137 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #137 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  30%|‚ñà‚ñà‚ñà       | 137/451 [1:28:51<55:21, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #137 FAILED after 3 retries. id=2512.20515v1\n",
      "   title='Modeling Bank Systemic Risk of Emerging Markets under Geopolitical Shocks: Empirical Evidence from BRICS Countries'\n",
      "\n",
      "‚ö†Ô∏è Paper #138 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #138 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  31%|‚ñà‚ñà‚ñà       | 138/451 [1:29:01<55:05, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #138 FAILED after 3 retries. id=2512.20190v1\n",
      "   title='Pricing of wrapped Bitcoin and Ethereum on-chain options'\n",
      "\n",
      "‚ö†Ô∏è Paper #139 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #139 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  31%|‚ñà‚ñà‚ñà       | 139/451 [1:29:12<54:43, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #139 FAILED after 3 retries. id=2512.19821v1\n",
      "   title='How to choose my stochastic volatility parameters? A review'\n",
      "\n",
      "‚ö†Ô∏è Paper #140 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #140 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  31%|‚ñà‚ñà‚ñà       | 140/451 [1:29:22<54:54, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #140 FAILED after 3 retries. id=2512.19621v1\n",
      "   title='Counterexamples for FX Options Interpolations -- Part I'\n",
      "\n",
      "‚ö†Ô∏è Paper #141 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #141 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  31%|‚ñà‚ñà‚ñà‚ñè      | 141/451 [1:29:33<54:39, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #141 FAILED after 3 retries. id=2512.18790v1\n",
      "   title='Optimal Catastrophe Risk Pooling'\n",
      "\n",
      "‚ö†Ô∏è Paper #142 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #142 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  31%|‚ñà‚ñà‚ñà‚ñè      | 142/451 [1:29:44<54:28, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #142 FAILED after 3 retries. id=2512.17185v1\n",
      "   title='Systemic Risk Radar: A Multi-Layer Graph Framework for Early Market Crash Warning'\n",
      "\n",
      "‚ö†Ô∏è Paper #143 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #143 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  32%|‚ñà‚ñà‚ñà‚ñè      | 143/451 [1:29:54<54:22, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #143 FAILED after 3 retries. id=2512.13562v1\n",
      "   title='Disability insurance with collective health claims: A mean-field approach'\n",
      "\n",
      "‚ö†Ô∏è Paper #144 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #144 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  32%|‚ñà‚ñà‚ñà‚ñè      | 144/451 [1:30:05<54:31, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #144 FAILED after 3 retries. id=2512.12420v1\n",
      "   title='Deep Hedging with Reinforcement Learning: A Practical Framework for Option Risk Management'\n",
      "\n",
      "‚ö†Ô∏è Paper #145 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #145 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  32%|‚ñà‚ñà‚ñà‚ñè      | 145/451 [1:30:15<53:42, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #145 FAILED after 3 retries. id=2512.11976v1\n",
      "   title='Institutionalizing risk curation in decentralized credit'\n",
      "\n",
      "‚ö†Ô∏è Paper #146 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #146 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  32%|‚ñà‚ñà‚ñà‚ñè      | 146/451 [1:30:26<53:15, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #146 FAILED after 3 retries. id=2512.11666v2\n",
      "   title='Risk Limited Asset Allocation with a Budget Threshold Utility Function and Leptokurtotic Distributions of Returns'\n",
      "\n",
      "‚ö†Ô∏è Paper #147 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #147 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  33%|‚ñà‚ñà‚ñà‚ñé      | 147/451 [1:30:36<53:15, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #147 FAILED after 3 retries. id=2512.11430v1\n",
      "   title='Pareto-optimal reinsurance under dependence uncertainty'\n",
      "\n",
      "‚ö†Ô∏è Paper #148 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #148 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  33%|‚ñà‚ñà‚ñà‚ñé      | 148/451 [1:30:47<53:05, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #148 FAILED after 3 retries. id=2512.08851v1\n",
      "   title=\"A New Application of Hoeffding's Inequality Can Give Traders Early Warning of Financial Regime Change\"\n",
      "\n",
      "‚ö†Ô∏è Paper #149 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #149 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  33%|‚ñà‚ñà‚ñà‚ñé      | 149/451 [1:30:57<52:44, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #149 FAILED after 3 retries. id=2512.07787v2\n",
      "   title='VaR at Its Extremes: Impossibilities and Conditions for One-Sided Random Variables'\n",
      "\n",
      "‚ö†Ô∏è Paper #150 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #150 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  33%|‚ñà‚ñà‚ñà‚ñé      | 150/451 [1:31:08<52:46, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #150 FAILED after 3 retries. id=2512.07526v1\n",
      "   title='The Suicide Region: Option Games and the Race to Artificial General Intelligence'\n",
      "\n",
      "‚ö†Ô∏è Paper #151 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #151 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  33%|‚ñà‚ñà‚ñà‚ñé      | 151/451 [1:31:18<52:38, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #151 FAILED after 3 retries. id=2512.06639v1\n",
      "   title='Learning to Hedge Swaptions'\n",
      "\n",
      "‚ö†Ô∏è Paper #152 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #152 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  34%|‚ñà‚ñà‚ñà‚ñé      | 152/451 [1:31:29<52:26, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #152 FAILED after 3 retries. id=2512.15739v1\n",
      "   title='Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance'\n",
      "\n",
      "‚ö†Ô∏è Paper #153 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #153 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  34%|‚ñà‚ñà‚ñà‚ñç      | 153/451 [1:31:39<52:27, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #153 FAILED after 3 retries. id=2512.05661v1\n",
      "   title='Standard and stressed value at risk forecasting using dynamic Bayesian networks'\n",
      "\n",
      "‚ö†Ô∏è Paper #154 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #154 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  34%|‚ñà‚ñà‚ñà‚ñç      | 154/451 [1:31:50<51:56, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #154 FAILED after 3 retries. id=2512.03267v1\n",
      "   title='Orlicz-Lorentz premia and distortion Haezendonck-Goovaerts risk measures'\n",
      "\n",
      "‚ö†Ô∏è Paper #155 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #155 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  34%|‚ñà‚ñà‚ñà‚ñç      | 155/451 [1:32:00<51:46, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #155 FAILED after 3 retries. id=2512.03242v1\n",
      "   title='A Theoretical Framework Bridging Model Validation and Loss Ratio in Insurance'\n",
      "\n",
      "‚ö†Ô∏è Paper #156 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #156 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  35%|‚ñà‚ñà‚ñà‚ñç      | 156/451 [1:32:11<51:26, 10.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #156 FAILED after 3 retries. id=2512.01623v1\n",
      "   title='Monopoly Pricing of Weather Index Insurance'\n",
      "\n",
      "‚ö†Ô∏è Paper #157 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #157 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  35%|‚ñà‚ñà‚ñà‚ñç      | 157/451 [1:32:21<51:47, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #157 FAILED after 3 retries. id=2512.00916v1\n",
      "   title='An Imbalance-Robust Evaluation Framework for Extreme Risk Forecasts'\n",
      "\n",
      "‚ö†Ô∏è Paper #158 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #158 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  35%|‚ñà‚ñà‚ñà‚ñå      | 158/451 [1:32:32<51:31, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #158 FAILED after 3 retries. id=2511.22782v1\n",
      "   title='Factors Influencing Cryptocurrency Prices: Evidence from Bitcoin, Ethereum, Dash, Litecoin, and Monero'\n",
      "\n",
      "‚ö†Ô∏è Paper #159 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #159 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  35%|‚ñà‚ñà‚ñà‚ñå      | 159/451 [1:32:42<51:16, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #159 FAILED after 3 retries. id=2511.22272v1\n",
      "   title='Statistics of Extremes for the Insurance Industry'\n",
      "\n",
      "‚ö†Ô∏è Paper #160 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #160 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  35%|‚ñà‚ñà‚ñà‚ñå      | 160/451 [1:32:53<51:25, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #160 FAILED after 3 retries. id=2511.21975v1\n",
      "   title='The Risk-Adjusted Intelligence Dividend: A Quantitative Framework for Measuring AI Return on Investment Integrating ISO '\n",
      "\n",
      "‚ö†Ô∏è Paper #161 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #161 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  36%|‚ñà‚ñà‚ñà‚ñå      | 161/451 [1:33:04<51:18, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #161 FAILED after 3 retries. id=2511.21929v1\n",
      "   title='Extended Convolution Bounds on the Fr√©chet Problem: Robust Risk Aggregation and Risk Sharing'\n",
      "\n",
      "‚ö†Ô∏è Paper #162 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #162 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  36%|‚ñà‚ñà‚ñà‚ñå      | 162/451 [1:33:15<51:13, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #162 FAILED after 3 retries. id=2511.21901v1\n",
      "   title='Standardized Threat Taxonomy for AI Security, Governance, and Regulatory Compliance'\n",
      "\n",
      "‚ö†Ô∏è Paper #163 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #163 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  36%|‚ñà‚ñà‚ñà‚ñå      | 163/451 [1:33:25<51:04, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #163 FAILED after 3 retries. id=2512.07867v1\n",
      "   title='LLM-Generated Counterfactual Stress Scenarios for Portfolio Risk Simulation via Hybrid Prompt-RAG Pipeline'\n",
      "\n",
      "‚ö†Ô∏è Paper #164 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #164 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  36%|‚ñà‚ñà‚ñà‚ñã      | 164/451 [1:33:36<51:19, 10.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #164 FAILED after 3 retries. id=2511.21556v1\n",
      "   title='Informative Risk Measures in the Banking Industry: A Proposal based on the Magnitude-Propensity Approach'\n",
      "\n",
      "‚ö†Ô∏è Paper #165 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #165 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  37%|‚ñà‚ñà‚ñà‚ñã      | 165/451 [1:33:47<51:19, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #165 FAILED after 3 retries. id=2511.21515v2\n",
      "   title='The Quantum Network of Assets: A Non-Classical Framework for Market Correlation and Structural Risk'\n",
      "\n",
      "‚ö†Ô∏è Paper #166 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #166 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  37%|‚ñà‚ñà‚ñà‚ñã      | 166/451 [1:33:58<51:57, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #166 FAILED after 3 retries. id=2511.19701v1\n",
      "   title='Optimal dividend and capital injection under self-exciting claims'\n",
      "\n",
      "‚ö†Ô∏è Paper #167 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #167 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  37%|‚ñà‚ñà‚ñà‚ñã      | 167/451 [1:34:09<51:23, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #167 FAILED after 3 retries. id=2511.18614v1\n",
      "   title='A calibrated model of debt recycling with interest costs and tax shields: viability under different fiscal regimes and j'\n",
      "\n",
      "‚ö†Ô∏è Paper #168 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #168 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  37%|‚ñà‚ñà‚ñà‚ñã      | 168/451 [1:34:20<50:52, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #168 FAILED after 3 retries. id=2511.18169v1\n",
      "   title='Superhedging under Proportional Transaction Costs in Continuous Time'\n",
      "\n",
      "‚ö†Ô∏è Paper #169 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #169 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  37%|‚ñà‚ñà‚ñà‚ñã      | 169/451 [1:34:30<50:41, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #169 FAILED after 3 retries. id=2511.17954v1\n",
      "   title='A multi-view contrastive learning framework for spatial embeddings in risk modelling'\n",
      "\n",
      "‚ö†Ô∏è Paper #170 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #170 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  38%|‚ñà‚ñà‚ñà‚ñä      | 170/451 [1:34:41<50:01, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #170 FAILED after 3 retries. id=2511.16302v2\n",
      "   title='Dynamic Risk Assessment of Wildland-Urban Interface Fires'\n",
      "\n",
      "‚ö†Ô∏è Paper #171 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #171 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  38%|‚ñà‚ñà‚ñà‚ñä      | 171/451 [1:34:51<49:43, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #171 FAILED after 3 retries. id=2511.13878v1\n",
      "   title='HSBC 1950 to 2025: Conquering the world from British Hong Kong and London'\n",
      "\n",
      "‚ö†Ô∏è Paper #172 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #172 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  38%|‚ñà‚ñà‚ñà‚ñä      | 172/451 [1:35:02<49:09, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #172 FAILED after 3 retries. id=2511.12391v3\n",
      "   title='Sharpening Shapley Allocation: from Basel 2.5 to FRTB'\n",
      "\n",
      "‚ö†Ô∏è Paper #173 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #173 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  38%|‚ñà‚ñà‚ñà‚ñä      | 173/451 [1:35:12<48:46, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #173 FAILED after 3 retries. id=2511.12292v1\n",
      "   title='Mean Field Analysis of Mutual Insurance Market'\n",
      "\n",
      "‚ö†Ô∏è Paper #174 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #174 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  39%|‚ñà‚ñà‚ñà‚ñä      | 174/451 [1:35:23<48:47, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #174 FAILED after 3 retries. id=2511.11416v1\n",
      "   title='Enhancing Efficiency of Pension Schemes through Effective Risk Governance: A Kenyan Perspective'\n",
      "\n",
      "‚ö†Ô∏è Paper #175 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #175 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  39%|‚ñà‚ñà‚ñà‚ñâ      | 175/451 [1:35:34<49:00, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #175 FAILED after 3 retries. id=2511.11364v1\n",
      "   title='Loss given default after default'\n",
      "\n",
      "‚ö†Ô∏è Paper #176 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #176 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  39%|‚ñà‚ñà‚ñà‚ñâ      | 176/451 [1:35:45<48:59, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #176 FAILED after 3 retries. id=2512.20027v1\n",
      "   title='GIFfluence: A Visual Approach to Investor Sentiment and the Stock Market'\n",
      "\n",
      "‚ö†Ô∏è Paper #177 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #177 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  39%|‚ñà‚ñà‚ñà‚ñâ      | 177/451 [1:35:55<48:47, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #177 FAILED after 3 retries. id=2512.19625v1\n",
      "   title='Counterexamples for FX Options Interpolations -- Part II'\n",
      "\n",
      "‚ö†Ô∏è Paper #178 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #178 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  39%|‚ñà‚ñà‚ñà‚ñâ      | 178/451 [1:36:06<48:23, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #178 FAILED after 3 retries. id=2512.16251v2\n",
      "   title='Interpretable Deep Learning for Stock Returns: A Consensus-Bottleneck Asset Pricing Model'\n",
      "\n",
      "‚ö†Ô∏è Paper #179 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #179 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  40%|‚ñà‚ñà‚ñà‚ñâ      | 179/451 [1:36:16<48:00, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #179 FAILED after 3 retries. id=2512.12871v1\n",
      "   title='CapOptix: An Options-Framework for Capacity Market Pricing'\n",
      "\n",
      "‚ö†Ô∏è Paper #180 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #180 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  40%|‚ñà‚ñà‚ñà‚ñâ      | 180/451 [1:36:27<48:02, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #180 FAILED after 3 retries. id=2512.10823v1\n",
      "   title='Option-Implied Zero-Coupon Yields: Unifying Bond and Equity Markets'\n",
      "\n",
      "‚ö†Ô∏è Paper #181 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #181 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  40%|‚ñà‚ñà‚ñà‚ñà      | 181/451 [1:36:38<47:49, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #181 FAILED after 3 retries. id=2512.08890v1\n",
      "   title='Modelling and valuation of catastrophe bonds across multiple regions'\n",
      "\n",
      "‚ö†Ô∏è Paper #182 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #182 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  40%|‚ñà‚ñà‚ñà‚ñà      | 182/451 [1:36:48<47:31, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #182 FAILED after 3 retries. id=2512.05326v1\n",
      "   title='Convolution-FFT for option pricing in the Heston model'\n",
      "\n",
      "‚ö†Ô∏è Paper #183 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #183 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  41%|‚ñà‚ñà‚ñà‚ñà      | 183/451 [1:36:58<47:04, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #183 FAILED after 3 retries. id=2512.05301v1\n",
      "   title='Differential ML with a Difference'\n",
      "\n",
      "‚ö†Ô∏è Paper #184 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #184 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  41%|‚ñà‚ñà‚ñà‚ñà      | 184/451 [1:37:09<47:17, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #184 FAILED after 3 retries. id=2512.03922v1\n",
      "   title='A Co-evolutionary Approach for Heston Calibration'\n",
      "\n",
      "‚ö†Ô∏è Paper #185 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #185 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  41%|‚ñà‚ñà‚ñà‚ñà      | 185/451 [1:37:20<47:06, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #185 FAILED after 3 retries. id=2512.00280v2\n",
      "   title='Retail Investor Horizon and Earnings Announcements'\n",
      "\n",
      "‚ö†Ô∏è Paper #186 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #186 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  41%|‚ñà‚ñà‚ñà‚ñà      | 186/451 [1:37:30<46:41, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #186 FAILED after 3 retries. id=2511.21873v1\n",
      "   title='A3T-GCN for FTSE100 Components Price Forecasting'\n",
      "\n",
      "‚ö†Ô∏è Paper #187 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #187 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 187/451 [1:37:41<46:38, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #187 FAILED after 3 retries. id=2511.18578v1\n",
      "   title='Re(Visiting) Time Series Foundation Models in Finance'\n",
      "\n",
      "‚ö†Ô∏è Paper #188 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #188 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 188/451 [1:37:52<46:47, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #188 FAILED after 3 retries. id=2511.09061v1\n",
      "   title='Generative Pricing of Basket Options via Signature-Conditioned Mixture Density Networks'\n",
      "\n",
      "‚ö†Ô∏è Paper #189 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #189 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 189/451 [1:38:02<46:16, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #189 FAILED after 3 retries. id=2511.06274v1\n",
      "   title=\"Why `Fair Market Valuations' are Inappropirate for Employee-Owned Firms and Partnerships\"\n",
      "\n",
      "‚ö†Ô∏è Paper #190 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #190 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 190/451 [1:38:13<45:43, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #190 FAILED after 3 retries. id=2511.04412v3\n",
      "   title='On the Estimation of Own Funds for Life Insurers: A Study of Direct, Indirect, and Control Variate Methods in a Risk-Neu'\n",
      "\n",
      "‚ö†Ô∏è Paper #191 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #191 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 191/451 [1:38:23<45:36, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #191 FAILED after 3 retries. id=2511.00308v1\n",
      "   title='Asset Pricing in the Presence of Market Microstructure Noise'\n",
      "\n",
      "‚ö†Ô∏è Paper #192 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #192 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 192/451 [1:38:34<45:38, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #192 FAILED after 3 retries. id=2510.27277v1\n",
      "   title='Black-Scholes Model, comparison between Analytical Solution and Numerical Analysis'\n",
      "\n",
      "‚ö†Ô∏è Paper #193 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #193 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 193/451 [1:38:45<45:49, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #193 FAILED after 3 retries. id=2510.26228v1\n",
      "   title='ChatGPT in Systematic Investing -- Enhancing Risk-Adjusted Returns with LLMs'\n",
      "\n",
      "‚ö†Ô∏è Paper #194 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #194 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 194/451 [1:38:55<45:32, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #194 FAILED after 3 retries. id=2510.21297v1\n",
      "   title='Jump risk premia in the presence of clustered jumps'\n",
      "\n",
      "‚ö†Ô∏è Paper #195 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #195 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 195/451 [1:39:06<45:24, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #195 FAILED after 3 retries. id=2510.19126v1\n",
      "   title='An Efficient Calibration Framework for Volatility Derivatives under Rough Volatility with Jumps'\n",
      "\n",
      "‚ö†Ô∏è Paper #196 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #196 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 196/451 [1:39:17<45:20, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #196 FAILED after 3 retries. id=2510.18159v1\n",
      "   title='Semi-analytical pricing of American options with hybrid dividends via integral equations and the GIT method'\n",
      "\n",
      "‚ö†Ô∏è Paper #197 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #197 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 197/451 [1:39:27<44:45, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #197 FAILED after 3 retries. id=2510.17221v1\n",
      "   title='Design and valuation of multi-region CoCoCat bonds'\n",
      "\n",
      "‚ö†Ô∏è Paper #198 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #198 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 198/451 [1:39:38<44:45, 10.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #198 FAILED after 3 retries. id=2510.15984v2\n",
      "   title='Berms without Calibration'\n",
      "\n",
      "‚ö†Ô∏è Paper #199 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "\n",
      "‚ö†Ô∏è Paper #199 attempt 2 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 199/451 [1:39:48<44:36, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùå Paper #199 FAILED after 3 retries. id=2510.10343v2\n",
      "   title='Learning the Exact SABR Model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 199/451 [1:39:50<2:06:25, 30.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è Paper #200 attempt 1 failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 175\u001b[0m\n\u001b[1;32m    174\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 175\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1191\u001b[0m validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1256\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m )\n\u001b[0;32m-> 1259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1047\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1046\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 194\u001b[0m\n\u001b[1;32m    192\u001b[0m         snip \u001b[38;5;241m=\u001b[39m clean_text(last_raw)[:SNIPPET_CHARS]\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   model snippet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msnip\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 194\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBACKOFF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     model_failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, json, gzip, re, time, sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "CORPUS_DIR = Path(\"arxiv_finance_corpus\")\n",
    "IN_PATH = CORPUS_DIR / \"papers_text_p1_10.jsonl.gz\"\n",
    "OUT_PATH = CORPUS_DIR / \"synthetic_finance_qa.chatml.jsonl\"\n",
    "\n",
    "# -------------------------\n",
    "# Controls\n",
    "# -------------------------\n",
    "MODEL = \"gpt-5\"\n",
    "TEMPERATURE = 1\n",
    "RETRIES = 3\n",
    "BACKOFF = 2\n",
    "SLEEP_BETWEEN_CALLS = 0.2\n",
    "\n",
    "MIN_BODY_CHARS = 3000\n",
    "MAX_CONTEXT_CHARS = 22000\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a finance and investing expert. You explain concepts clearly, \"\n",
    "    \"use correct financial terminology, and avoid speculation. \"\n",
    "    \"When answering, you only use information provided in my training knowledge.\"\n",
    ")\n",
    "\n",
    "PRINT_EVERY = 10          # per N papers processed, print status\n",
    "SNIPPET_CHARS = 400       # show small snippet of model output on failure\n",
    "FLUSH_EVERY = 20          # flush output file every N successful papers\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "_ws = re.compile(r\"\\s+\")\n",
    "def clean_text(s: str) -> str:\n",
    "    s = (s or \"\").replace(\"\\x00\", \" \")\n",
    "    return _ws.sub(\" \", s).strip()\n",
    "\n",
    "def trunc(s: str, max_chars: int) -> str:\n",
    "    s = s or \"\"\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    cut = s[:max_chars]\n",
    "    last_space = cut.rfind(\" \")\n",
    "    return (cut[:last_space] if last_space > 0 else cut).rstrip()\n",
    "\n",
    "def make_generation_prompt(title: str, abstract: str, body: str) -> str:\n",
    "    source = f\"TITLE: {title}\\n\\nABSTRACT: {abstract}\\n\\nEXCERPT: {body}\"\n",
    "    source = trunc(source, MAX_CONTEXT_CHARS)\n",
    "    return f\"\"\"\n",
    "You will create training Q&A pairs to teach a model finance/investing expertise.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY my training knowledge. Do not invent facts, datasets, results, or numbers.\n",
    "- If details are missing, say so explicitly (e.g., \"The abstract does not specify ...\").\n",
    "- Questions should be what a serious finance student or analyst would ask:\n",
    "  mix of conceptual, methodology, implications, limitations, and definitions.\n",
    "- Answers should be precise, finance-literate, and grounded.\n",
    "- Return STRICT JSON with exactly 5 items.\n",
    "\n",
    "Output JSON schema:\n",
    "{{\n",
    "  \"qas\": [\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "SOURCE:\n",
    "\\\"\\\"\\\"{source}\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "def parse_qas(content: str) -> Optional[List[Dict[str, str]]]:\n",
    "    try:\n",
    "        obj = json.loads(content)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not isinstance(obj, dict) or \"qas\" not in obj or not isinstance(obj[\"qas\"], list):\n",
    "        return None\n",
    "    qas = []\n",
    "    for item in obj[\"qas\"]:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        q, a = item.get(\"question\"), item.get(\"answer\")\n",
    "        if isinstance(q, str) and isinstance(a, str):\n",
    "            qas.append({\"question\": q.strip(), \"answer\": a.strip()})\n",
    "    return qas if len(qas) == 5 else None\n",
    "\n",
    "def chatml_line(system_prompt: str, user_q: str, assistant_a: str) -> Dict[str, str]:\n",
    "    return {\"text\": f\"<|system|>{system_prompt}<|user|>{user_q}<|assistant|>{assistant_a}\"}\n",
    "\n",
    "# -------------------------\n",
    "# OpenAI client\n",
    "# -------------------------\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"Missing OPENAI_API_KEY in environment. Add it to .env or export it.\")\n",
    "\n",
    "# -------------------------\n",
    "# Load count for tqdm\n",
    "# -------------------------\n",
    "def count_lines_gz(path: Path) -> int:\n",
    "    n = 0\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for _ in f:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "print(f\"IN_PATH: {IN_PATH} (exists={IN_PATH.exists()})\")\n",
    "print(f\"OUT_PATH: {OUT_PATH}\")\n",
    "print(\"Counting papers (for progress bar)...\")\n",
    "total_lines = count_lines_gz(IN_PATH)\n",
    "print(f\"Total records in corpus file: {total_lines}\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "total_papers = 0\n",
    "used_papers = 0\n",
    "total_qas = 0\n",
    "\n",
    "skipped_extraction = 0\n",
    "skipped_short = 0\n",
    "skipped_empty_body_field = 0\n",
    "model_failures = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with gzip.open(IN_PATH, \"rt\", encoding=\"utf-8\") as fin, open(OUT_PATH, \"a\", encoding=\"utf-8\") as fout:\n",
    "    for line in tqdm(fin, total=total_lines, desc=\"Generating QAs\"):\n",
    "        total_papers += 1\n",
    "        rec = json.loads(line)\n",
    "\n",
    "        # Check which body field exists\n",
    "        # Your corpus writer used \"body_p1_5\" even when FIRST_N_PAGES=10.\n",
    "        # We'll try both keys and print if missing.\n",
    "        body = rec.get(\"body_p1_10\")\n",
    "        if body is None:\n",
    "            body = rec.get(\"body_p1_5\", \"\")\n",
    "\n",
    "        if not rec.get(\"extraction_ok\", True):\n",
    "            skipped_extraction += 1\n",
    "            continue\n",
    "\n",
    "        if int(rec.get(\"body_chars\", 0)) < MIN_BODY_CHARS:\n",
    "            skipped_short += 1\n",
    "            continue\n",
    "\n",
    "        body = clean_text(body)\n",
    "        if not body:\n",
    "            skipped_empty_body_field += 1\n",
    "            continue\n",
    "\n",
    "        title = clean_text(rec.get(\"primary_title\", \"\"))\n",
    "        abstract = clean_text(rec.get(\"abstract\", \"\"))\n",
    "\n",
    "        prompt = make_generation_prompt(title, abstract, body)\n",
    "\n",
    "        qas = None\n",
    "        last_raw = None\n",
    "\n",
    "        for attempt in range(1, RETRIES + 1):\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=TEMPERATURE,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                dt = time.time() - t0\n",
    "                last_raw = resp.choices[0].message.content\n",
    "                qas = parse_qas(last_raw)\n",
    "                if qas is None:\n",
    "                    raise ValueError(\"Invalid JSON or not exactly 5 qas\")\n",
    "                # success\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt < RETRIES:\n",
    "                    print(f\"\\n‚ö†Ô∏è Paper #{total_papers} attempt {attempt} failed: {e}\")\n",
    "                    if last_raw:\n",
    "                        snip = clean_text(last_raw)[:SNIPPET_CHARS]\n",
    "                        print(f\"   model snippet: {snip!r}\")\n",
    "                    time.sleep(BACKOFF * attempt)\n",
    "                else:\n",
    "                    model_failures += 1\n",
    "                    print(f\"\\n‚ùå Paper #{total_papers} FAILED after {RETRIES} retries. id={rec.get('id')}\")\n",
    "                    print(f\"   title={title[:120]!r}\")\n",
    "                    if last_raw:\n",
    "                        snip = clean_text(last_raw)[:SNIPPET_CHARS]\n",
    "                        print(f\"   last model snippet: {snip!r}\")\n",
    "                    qas = None\n",
    "\n",
    "        if qas is None:\n",
    "            continue\n",
    "\n",
    "        # write 5 lines\n",
    "        for qa in qas:\n",
    "            row = chatml_line(SYSTEM_PROMPT, qa[\"question\"], qa[\"answer\"])\n",
    "            fout.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            total_qas += 1\n",
    "\n",
    "        used_papers += 1\n",
    "\n",
    "        if used_papers % FLUSH_EVERY == 0:\n",
    "            fout.flush()\n",
    "\n",
    "        if total_papers % PRINT_EVERY == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"\\nüìå Progress: read={total_papers}/{total_lines} | used={used_papers} | qas={total_qas} | \"\n",
    "                f\"skipped(extraction={skipped_extraction}, short={skipped_short}, empty_body={skipped_empty_body_field}) | \"\n",
    "                f\"model_failures={model_failures} | elapsed={elapsed/60:.1f}m\"\n",
    "            )\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "print(\"\\n‚úÖ DONE\")\n",
    "print(f\"Read papers: {total_papers}\")\n",
    "print(f\"Used papers: {used_papers}\")\n",
    "print(f\"Total QAs written: {total_qas}\")\n",
    "print(f\"Skipped - extraction_ok false: {skipped_extraction}\")\n",
    "print(f\"Skipped - body_chars too small: {skipped_short}\")\n",
    "print(f\"Skipped - empty body field: {skipped_empty_body_field}\")\n",
    "print(f\"Model failures: {model_failures}\")\n",
    "print(f\"Output: {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e3145",
   "metadata": {},
   "source": [
    "## Ran out of Chatgpt API Balance. The below is an addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93862e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_PATH: arxiv_finance_corpus/papers_text_p1_10.jsonl.gz (exists=True)\n",
      "OUT_PATH: arxiv_finance_corpus/synthetic_finance_qa.chatml.jsonl (append mode, will NOT overwrite)\n",
      "Counting papers (for progress bar)...\n",
      "Total records in corpus file: 451\n",
      "Starting at paper #92 (1-based), line index 91 (0-based).\n",
      "Will generate 2 QA pairs per usable paper.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:   2%|‚ñé         | 9/360 [07:45<5:06:55, 52.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=102 | used=10 | qas=20 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=8.6m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:   6%|‚ñå         | 21/360 [15:09<3:28:06, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=112 | used=20 | qas=40 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=15.2m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:   9%|‚ñä         | 31/360 [21:57<3:14:48, 35.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=122 | used=30 | qas=60 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=21.9m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  11%|‚ñà         | 40/360 [29:27<4:12:19, 47.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=132 | used=40 | qas=80 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=30.3m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  14%|‚ñà‚ñç        | 51/360 [38:33<4:10:08, 48.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=142 | used=50 | qas=100 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=38.6m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  17%|‚ñà‚ñã        | 61/360 [45:39<3:27:11, 41.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=152 | used=60 | qas=120 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=45.7m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  19%|‚ñà‚ñâ        | 70/360 [55:09<4:02:04, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=162 | used=70 | qas=140 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=55.8m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  22%|‚ñà‚ñà‚ñè       | 80/360 [1:01:11<2:51:19, 36.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìå Progress: start_paper=92 | current_paper=172 | used=80 | qas=160 | skipped(extraction=1, short=0, empty_body=0) | model_failures=0 | elapsed=61.6m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating QAs from paper #92+:  24%|‚ñà‚ñà‚ñç       | 88/360 [1:06:24<3:25:15, 45.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 208\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, RETRIES \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m         last_raw \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    215\u001b[0m         qas \u001b[38;5;241m=\u001b[39m parse_qas(last_raw)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:1192\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[1;32m   1190\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1288\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1285\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1286\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1287\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1161\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# followup_generate_qas_from_paper92.py\n",
    "# Continues generation starting at paper index 92 (1-based),\n",
    "# generates 2 QA pairs per paper, and APPENDS to OUT_PATH (no overwrite).\n",
    "\n",
    "import os, json, gzip, re, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------\n",
    "# Paths\n",
    "# -------------------------\n",
    "CORPUS_DIR = Path(\"arxiv_finance_corpus\")\n",
    "IN_PATH = CORPUS_DIR / \"papers_text_p1_10.jsonl.gz\"\n",
    "OUT_PATH = CORPUS_DIR / \"synthetic_finance_qa.chatml.jsonl\"\n",
    "\n",
    "# -------------------------\n",
    "# Controls\n",
    "# -------------------------\n",
    "MODEL = \"gpt-5\"\n",
    "TEMPERATURE = 1\n",
    "RETRIES = 3\n",
    "BACKOFF = 2\n",
    "SLEEP_BETWEEN_CALLS = 0.2\n",
    "\n",
    "MIN_BODY_CHARS = 3000\n",
    "MAX_CONTEXT_CHARS = 22000\n",
    "\n",
    "# Continue from paper 92 (1-based). If you want to start at paper #92 exactly,\n",
    "# set START_PAPER_NUM = 92. If you want to start AFTER paper 91, also 92.\n",
    "START_PAPER_NUM = 92  # 1-based inclusive\n",
    "\n",
    "# We generate exactly 2 QAs per paper now.\n",
    "QAS_PER_PAPER = 2\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a finance and investing expert. You explain concepts clearly, \"\n",
    "    \"use correct financial terminology, and avoid speculation. \"\n",
    "    \"When answering, you only use information provided in my training knowledge.\"\n",
    ")\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "SNIPPET_CHARS = 400\n",
    "FLUSH_EVERY = 20\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "_ws = re.compile(r\"\\s+\")\n",
    "def clean_text(s: str) -> str:\n",
    "    s = (s or \"\").replace(\"\\x00\", \" \")\n",
    "    return _ws.sub(\" \", s).strip()\n",
    "\n",
    "def trunc(s: str, max_chars: int) -> str:\n",
    "    s = s or \"\"\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    cut = s[:max_chars]\n",
    "    last_space = cut.rfind(\" \")\n",
    "    return (cut[:last_space] if last_space > 0 else cut).rstrip()\n",
    "\n",
    "def make_generation_prompt(title: str, abstract: str, body: str) -> str:\n",
    "    source = f\"TITLE: {title}\\n\\nABSTRACT: {abstract}\\n\\nEXCERPT: {body}\"\n",
    "    source = trunc(source, MAX_CONTEXT_CHARS)\n",
    "    return f\"\"\"\n",
    "You will create training Q&A pairs to teach a model finance/investing expertise.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY my training knowledge. Do not invent facts, datasets, results, or numbers.\n",
    "- If details are missing, say so explicitly (e.g., \"The abstract does not specify ...\").\n",
    "- Questions should be what a serious finance student or analyst would ask:\n",
    "  mix of conceptual, methodology, implications, limitations, and definitions.\n",
    "- Answers should be precise, finance-literate, and grounded.\n",
    "- Return STRICT JSON with exactly {QAS_PER_PAPER} items.\n",
    "\n",
    "Output JSON schema:\n",
    "{{\n",
    "  \"qas\": [\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}},\n",
    "    {{\"question\": \"...\", \"answer\": \"...\"}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "SOURCE:\n",
    "\\\"\\\"\\\"{source}\\\"\\\"\\\"\n",
    "\"\"\".strip()\n",
    "\n",
    "def parse_qas(content: str) -> Optional[List[Dict[str, str]]]:\n",
    "    try:\n",
    "        obj = json.loads(content)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if not isinstance(obj, dict) or \"qas\" not in obj or not isinstance(obj[\"qas\"], list):\n",
    "        return None\n",
    "\n",
    "    qas: List[Dict[str, str]] = []\n",
    "    for item in obj[\"qas\"]:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        q, a = item.get(\"question\"), item.get(\"answer\")\n",
    "        if isinstance(q, str) and isinstance(a, str):\n",
    "            qas.append({\"question\": q.strip(), \"answer\": a.strip()})\n",
    "\n",
    "    return qas if len(qas) == QAS_PER_PAPER else None\n",
    "\n",
    "def chatml_line(system_prompt: str, user_q: str, assistant_a: str) -> Dict[str, str]:\n",
    "    return {\"text\": f\"<|system|>{system_prompt}<|user|>{user_q}<|assistant|>{assistant_a}\"}\n",
    "\n",
    "# -------------------------\n",
    "# OpenAI client\n",
    "# -------------------------\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"Missing OPENAI_API_KEY in environment. Add it to .env or export it.\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# -------------------------\n",
    "# Load count for tqdm\n",
    "# -------------------------\n",
    "def count_lines_gz(path: Path) -> int:\n",
    "    n = 0\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        for _ in f:\n",
    "            n += 1\n",
    "    return n\n",
    "\n",
    "print(f\"IN_PATH: {IN_PATH} (exists={IN_PATH.exists()})\")\n",
    "print(f\"OUT_PATH: {OUT_PATH} (append mode, will NOT overwrite)\")\n",
    "print(\"Counting papers (for progress bar)...\")\n",
    "total_lines = count_lines_gz(IN_PATH)\n",
    "print(f\"Total records in corpus file: {total_lines}\")\n",
    "\n",
    "# Convert desired start paper number (1-based) to zero-based index\n",
    "start_index = max(0, START_PAPER_NUM - 1)\n",
    "if start_index >= total_lines:\n",
    "    raise RuntimeError(f\"START_PAPER_NUM={START_PAPER_NUM} is beyond total_lines={total_lines}\")\n",
    "\n",
    "print(f\"Starting at paper #{START_PAPER_NUM} (1-based), line index {start_index} (0-based).\")\n",
    "print(f\"Will generate {QAS_PER_PAPER} QA pairs per usable paper.\\n\")\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "total_papers_read = 0          # papers iterated over after start_index\n",
    "global_paper_num = 0           # absolute 1-based paper number in corpus\n",
    "used_papers = 0\n",
    "total_qas = 0\n",
    "\n",
    "skipped_extraction = 0\n",
    "skipped_short = 0\n",
    "skipped_empty_body_field = 0\n",
    "model_failures = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with gzip.open(IN_PATH, \"rt\", encoding=\"utf-8\") as fin, open(OUT_PATH, \"a\", encoding=\"utf-8\") as fout:\n",
    "    # Advance to start_index without loading all lines\n",
    "    for i, _ in enumerate(fin):\n",
    "        if i + 1 >= START_PAPER_NUM:\n",
    "            # We‚Äôve just consumed START_PAPER_NUM-1 lines; rewind one line by keeping it\n",
    "            # But gzip streams can't seek back; instead we break and handle by reopening.\n",
    "            break\n",
    "\n",
    "# Reopen and skip precisely start_index lines\n",
    "with gzip.open(IN_PATH, \"rt\", encoding=\"utf-8\") as fin, open(OUT_PATH, \"a\", encoding=\"utf-8\") as fout:\n",
    "    for _ in range(start_index):\n",
    "        next(fin)\n",
    "\n",
    "    # tqdm total is remaining lines\n",
    "    remaining = total_lines - start_index\n",
    "\n",
    "    for line in tqdm(fin, total=remaining, desc=f\"Generating QAs from paper #{START_PAPER_NUM}+\"):\n",
    "        total_papers_read += 1\n",
    "        global_paper_num = start_index + total_papers_read  # 1-based absolute paper number\n",
    "\n",
    "        rec = json.loads(line)\n",
    "\n",
    "        # Body field selection\n",
    "        body = rec.get(\"body_p1_10\")\n",
    "        if body is None:\n",
    "            body = rec.get(\"body_p1_5\", \"\")\n",
    "\n",
    "        if not rec.get(\"extraction_ok\", True):\n",
    "            skipped_extraction += 1\n",
    "            continue\n",
    "\n",
    "        if int(rec.get(\"body_chars\", 0)) < MIN_BODY_CHARS:\n",
    "            skipped_short += 1\n",
    "            continue\n",
    "\n",
    "        body = clean_text(body)\n",
    "        if not body:\n",
    "            skipped_empty_body_field += 1\n",
    "            continue\n",
    "\n",
    "        title = clean_text(rec.get(\"primary_title\", \"\"))\n",
    "        abstract = clean_text(rec.get(\"abstract\", \"\"))\n",
    "\n",
    "        prompt = make_generation_prompt(title, abstract, body)\n",
    "\n",
    "        qas = None\n",
    "        last_raw = None\n",
    "\n",
    "        for attempt in range(1, RETRIES + 1):\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=TEMPERATURE,\n",
    "                    response_format={\"type\": \"json_object\"},\n",
    "                )\n",
    "                last_raw = resp.choices[0].message.content\n",
    "                qas = parse_qas(last_raw)\n",
    "                if qas is None:\n",
    "                    raise ValueError(f\"Invalid JSON or not exactly {QAS_PER_PAPER} qas\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt < RETRIES:\n",
    "                    print(f\"\\n‚ö†Ô∏è Paper #{global_paper_num} attempt {attempt} failed: {e}\")\n",
    "                    if last_raw:\n",
    "                        snip = clean_text(last_raw)[:SNIPPET_CHARS]\n",
    "                        print(f\"   model snippet: {snip!r}\")\n",
    "                    time.sleep(BACKOFF * attempt)\n",
    "                else:\n",
    "                    model_failures += 1\n",
    "                    print(f\"\\n‚ùå Paper #{global_paper_num} FAILED after {RETRIES} retries. id={rec.get('id')}\")\n",
    "                    print(f\"   title={title[:120]!r}\")\n",
    "                    if last_raw:\n",
    "                        snip = clean_text(last_raw)[:SNIPPET_CHARS]\n",
    "                        print(f\"   last model snippet: {snip!r}\")\n",
    "                    qas = None\n",
    "\n",
    "        if qas is None:\n",
    "            continue\n",
    "\n",
    "        # Append QAS_PER_PAPER lines to the existing OUT_PATH\n",
    "        for qa in qas:\n",
    "            row = chatml_line(SYSTEM_PROMPT, qa[\"question\"], qa[\"answer\"])\n",
    "            fout.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "            total_qas += 1\n",
    "\n",
    "        used_papers += 1\n",
    "\n",
    "        if used_papers % FLUSH_EVERY == 0:\n",
    "            fout.flush()\n",
    "\n",
    "        if used_papers % PRINT_EVERY == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                f\"\\nüìå Progress: start_paper={START_PAPER_NUM} | current_paper={global_paper_num} | \"\n",
    "                f\"used={used_papers} | qas={total_qas} | \"\n",
    "                f\"skipped(extraction={skipped_extraction}, short={skipped_short}, empty_body={skipped_empty_body_field}) | \"\n",
    "                f\"model_failures={model_failures} | elapsed={elapsed/60:.1f}m\"\n",
    "            )\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "print(\"\\n‚úÖ DONE (follow-up run)\")\n",
    "print(f\"Started at paper #: {START_PAPER_NUM}\")\n",
    "print(f\"Papers read (from start): {total_papers_read}\")\n",
    "print(f\"Used papers: {used_papers}\")\n",
    "print(f\"Total QAs appended: {total_qas}\")\n",
    "print(f\"Skipped - extraction_ok false: {skipped_extraction}\")\n",
    "print(f\"Skipped - body_chars too small: {skipped_short}\")\n",
    "print(f\"Skipped - empty body field: {skipped_empty_body_field}\")\n",
    "print(f\"Model failures: {model_failures}\")\n",
    "print(f\"Output (appended): {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c80afa",
   "metadata": {},
   "source": [
    "## Add edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dfb8b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Appended 20 edge-case refusal QAs to: arxiv_finance_corpus/synthetic_finance_qa.chatml.jsonl\n"
     ]
    }
   ],
   "source": [
    "# add_20_edgecase_qas_refusal.py\n",
    "# Appends 20 edge-case QAs (false-logic / irrelevant) to your ChatML JSONL.\n",
    "# Each answer explicitly refuses and explains why (not grounded in provided source text).\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "CORPUS_DIR = Path(\"arxiv_finance_corpus\")\n",
    "OUT_PATH = CORPUS_DIR / \"synthetic_finance_qa.chatml.jsonl\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a finance and investing expert. You explain concepts clearly, \"\n",
    "    \"use correct financial terminology, and avoid speculation. \"\n",
    "    \"When answering, you only use information provided in the source text.\"\n",
    ")\n",
    "\n",
    "def chatml_line(system_prompt: str, user_q: str, assistant_a: str) -> dict:\n",
    "    return {\"text\": f\"<|system|>{system_prompt}<|user|>{user_q}<|assistant|>{assistant_a}\"}\n",
    "\n",
    "# 20 edge-case prompts that are either:\n",
    "# - logically invalid / contradictory\n",
    "# - not finance-related\n",
    "# - require external info not present in any provided source text\n",
    "# Each answer MUST refuse and state why.\n",
    "EDGE_CASE_QAS = [\n",
    "    (\n",
    "        \"If inflation is 2% and 3% at the same time, what is the exact real return?\",\n",
    "        \"I can‚Äôt give an exact real return because the question is internally contradictory (inflation can‚Äôt be both 2% and 3% for the same period in a single calculation), and no source text is provided to clarify which value applies.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Prove that every stock that goes down must go back up eventually.\",\n",
    "        \"I can‚Äôt answer because the claim is false as stated (there is no guarantee a stock must recover), and there‚Äôs no source text provided that defines assumptions or a model under which such a statement could be evaluated.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is Warren Buffett‚Äôs current cash balance to the dollar?\",\n",
    "        \"I can‚Äôt answer because that requires up-to-date external information that is not included in my training knowledge provided.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What‚Äôs the best crypto to buy tomorrow for guaranteed profit?\",\n",
    "        \"I can‚Äôt answer because it asks for guaranteed future profits (which isn‚Äôt possible to guarantee), and it requires speculation and market prediction not supported by any provided source text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If P/E is negative, does that mean the company is infinitely cheap and therefore a buy?\",\n",
    "        \"I can‚Äôt answer as framed because the conclusion doesn‚Äôt follow from the premise (negative P/E usually reflects negative earnings and doesn‚Äôt imply ‚Äúinfinitely cheap‚Äù), and no source text is provided to define the context or metrics being used.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Explain the plot twist in Inception and how it impacts bond yields.\",\n",
    "        \"I can‚Äôt answer because the question is not related to the finance source text and mixes an unrelated film discussion with bond yields without any provided evidence or context.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If a portfolio has 0% risk, why not lever it 1000x to become rich?\",\n",
    "        \"I can‚Äôt answer because the premise is unrealistic/undefined (0% risk isn‚Äôt established here), and no source text is provided to specify constraints like borrowing costs, margin rules, tail risk, or model assumptions.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What was the exact closing price of AAPL on my birthday?\",\n",
    "        \"I can‚Äôt answer because it requires external historical market data and your birthday date, neither of which are included in the provided source text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Since diversification reduces risk, does adding infinitely many stocks reduce risk to exactly zero?\",\n",
    "        \"I can‚Äôt give a definitive numeric answer because the question assumes a specific risk model and correlation structure that are not provided in my training knowledge; in general, diversification reduces idiosyncratic risk but does not eliminate systematic risk.\"\n",
    "    ),\n",
    "    (\n",
    "        \"In the paper, what is the author‚Äôs political opinion about taxation?\",\n",
    "        \"I can‚Äôt answer because political opinions are not finance methodology/results, and no relevant statement is provided in my training knowledge to support an answer.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If GDP goes up, does that always mean every stock must rise the same day?\",\n",
    "        \"I can‚Äôt answer as stated because the logic is invalid (macro growth doesn‚Äôt force same-day uniform stock moves), and no source text is provided that claims or models such a deterministic relationship.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the secret algorithm hedge funds use to beat the market?\",\n",
    "        \"I can‚Äôt answer because that asks for unspecified proprietary information and isn‚Äôt grounded in any provided source text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If interest rates are 5%, how many years until my money doubles exactly (no assumptions needed)?\",\n",
    "        \"I can‚Äôt give an exact answer because doubling time depends on compounding conventions (simple vs compound, frequency), and no source text specifies which assumptions to use.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Summarize the entire dataset you trained on and list the top 10 sources.\",\n",
    "        \"I can‚Äôt answer because that information isn‚Äôt included in the provided source text, and I don‚Äôt have access to your full training dataset or its sources from this prompt.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Is the statement 'all arbitrage is risk-free' always true? Answer yes or no.\",\n",
    "        \"I can‚Äôt answer with a simple yes/no because the statement depends on definitions and market frictions; without source text defining arbitrage conditions (execution risk, latency, funding, settlement), a binary answer would be unsupported.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is my portfolio‚Äôs Sharpe ratio if I don‚Äôt tell you returns or volatility?\",\n",
    "        \"I can‚Äôt compute it because the required inputs (return, risk-free rate, volatility) are not provided in my training knowledge or the question.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If a stablecoin depegs, does that mean it‚Äôs illegal?\",\n",
    "        \"I can‚Äôt answer because legality depends on jurisdiction and facts not provided in my training knowledge; the question also mixes a market event (depeg) with legal status without evidence.\"\n",
    "    ),\n",
    "    (\n",
    "        \"How many LPs lost money on Uniswap v3 last week, exactly?\",\n",
    "        \"I can‚Äôt answer because it requires specific time-bounded on-chain analysis data not included in the provided source text.\"\n",
    "    ),\n",
    "    (\n",
    "        \"If two assets have correlation 0, does that prove they are independent and safe to pair trade?\",\n",
    "        \"I can‚Äôt answer as stated because zero correlation does not prove independence, and the safety of a pair trade depends on assumptions and data not provided in my training knowledge.\"\n",
    "    ),\n",
    "    (\n",
    "        \"What is the capital of France and how does it affect the yield curve?\",\n",
    "        \"I can‚Äôt answer because the first part is general trivia unrelated to the finance source text, and the second part asserts a relationship without any provided evidence or context to support it.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "def main():\n",
    "    if not OUT_PATH.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"OUT_PATH does not exist: {OUT_PATH}\\n\"\n",
    "            f\"Create it first (run your main generator once), or correct CORPUS_DIR/OUT_PATH.\"\n",
    "        )\n",
    "\n",
    "    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(OUT_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        for q, a in EDGE_CASE_QAS:\n",
    "            row = chatml_line(SYSTEM_PROMPT, q, a)\n",
    "            f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    print(f\"‚úÖ Appended {len(EDGE_CASE_QAS)} edge-case refusal QAs to: {OUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880187a1",
   "metadata": {},
   "source": [
    "## Clean/ Normalize the dataset.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7dfe0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset written to: arxiv_finance_corpus/synthetic_finance_qa.chatml.clean.jsonl\n",
      "Kept: 644, Dropped: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import unicodedata\n",
    "\n",
    "IN  = \"arxiv_finance_corpus/synthetic_finance_qa.chatml.jsonl\"\n",
    "OUT = \"arxiv_finance_corpus/synthetic_finance_qa.chatml.clean.jsonl\"\n",
    "\n",
    "kept = 0\n",
    "dropped = 0\n",
    "\n",
    "with open(IN, \"r\", encoding=\"utf-8\", errors=\"replace\") as fin, \\\n",
    "     open(OUT, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for i, line in enumerate(fin, 1):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            dropped += 1\n",
    "            continue\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            if \"text\" not in obj or not isinstance(obj[\"text\"], str):\n",
    "                dropped += 1\n",
    "                continue\n",
    "\n",
    "            # Normalize unicode (this removes ambiguous characters)\n",
    "            clean_text = unicodedata.normalize(\"NFKC\", obj[\"text\"])\n",
    "            fout.write(json.dumps({\"text\": clean_text}, ensure_ascii=False) + \"\\n\")\n",
    "            kept += 1\n",
    "        except Exception:\n",
    "            dropped += 1\n",
    "\n",
    "print(f\"‚úÖ Cleaned dataset written to: {OUT}\")\n",
    "print(f\"Kept: {kept}, Dropped: {dropped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af8c52",
   "metadata": {},
   "source": [
    "## Fine tuning setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c87231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.12.9-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.4.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0a0+07cecf4168.nv24.5)\n",
      "Collecting unsloth_zoo>=2025.12.7 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.12.7-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.19.0a0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.24.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.8)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-1.0.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.24.4)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting accelerate>=0.34.1 (from unsloth)\n",
      "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/jovyan/.local/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.9.5)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.34.0->unsloth) (4.11.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "  Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "Collecting packaging (from unsloth)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (9.5.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2025.12.7->unsloth)\n",
      "  Downloading msgspec-0.20.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->diffusers->unsloth) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading unsloth-2025.12.9-py3-none-any.whl (376 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m157.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m278.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m270.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m266.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Downloading peft-0.18.0-py3-none-any.whl (556 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m275.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m342.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.1-cp310-cp310-manylinux_2_28_x86_64.whl (899.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m235.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m291.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m306.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m264.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m591.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m249.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m303.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m614.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m322.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m297.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m305.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m307.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m256.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m338.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m327.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.3/170.3 MB\u001b[0m \u001b[31m330.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Downloading pyarrow-22.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (47.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m233.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.7.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (507 kB)\n",
      "Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m384.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m327.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.12.7-py3-none-any.whl (290 kB)\n",
      "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading torchao-0.15.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m275.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl (122.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m168.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading diffusers-0.36.0-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m305.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m328.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.20.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (222 kB)\n",
      "Downloading torchvision-0.24.1-cp310-cp310-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m338.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.3-py3-none-any.whl (180 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: torchao, nvidia-cusparselt-cu12, xxhash, typing-extensions, triton, sympy, sentencepiece, safetensors, pyarrow, packaging, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, hf-xet, hf_transfer, docstring-parser, dill, typeguard, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, huggingface_hub, tyro, tokenizers, nvidia-cusolver-cu12, transformers, torch, diffusers, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47/47\u001b[0m [unsloth][unsloth][unsloth_zoo]]er-cu12]2]2]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.4.0 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 22.0.0 which is incompatible.\n",
      "torch-tensorrt 2.4.0a0 requires torch<2.5.0,>=2.4.0.dev, but you have torch 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0 bitsandbytes-0.49.0 cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.36.0 dill-0.4.0 docstring-parser-0.17.0 hf-xet-1.2.0 hf_transfer-0.1.9 huggingface_hub-0.36.0 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 packaging-25.0 peft-0.18.0 pyarrow-22.0.0 safetensors-0.7.0 sentencepiece-0.2.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 torchao-0.15.0 torchvision-0.24.1 transformers-4.57.3 triton-3.5.1 trl-0.24.0 typeguard-4.4.4 typing-extensions-4.15.0 tyro-1.0.3 unsloth-2025.12.9 unsloth_zoo-2025.12.7 xformers-0.0.33.post2 xxhash-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unsloth transformers peft bitsandbytes datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c1acfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CUDA: inference-ai GPU cuda\n",
      "‚úÖ DATA_PATH: /home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin/arxiv_finance_corpus/synthetic_finance_qa.chatml.clean.jsonl\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "‚úÖ Loaded 644 examples\n",
      "üîé Example snippet: <|system|>You are a finance and investing expert. You explain concepts clearly, use correct financial terminology, and avoid speculation. When answering, you only use information provided in the sourc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 644 | Num Epochs = 2 | Total steps = 82\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='82' max='82' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [82/82 28:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>56.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>40.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>39.033800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved LoRA adapters + tokenizer to: llama31-8b-finance-qlora-lora\n"
     ]
    }
   ],
   "source": [
    "# Finetune Llama-3.1-8B-Instruct (Unsloth 4-bit) on ChatML JSONL\n",
    "# WITHOUT HuggingFace datasets/pyarrow (fixes DatasetGenerationError).\n",
    "#\n",
    "# Input JSONL format (one per line):\n",
    "# {\"text\": \"<|system|>...<|user|>...<|assistant|>...\"}\n",
    "#\n",
    "# Output:\n",
    "# - LoRA adapters saved to OUTPUT_DIR\n",
    "# - tokenizer saved to OUTPUT_DIR\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "DATA_PATH = \"arxiv_finance_corpus/synthetic_finance_qa.chatml.clean.jsonl\"\n",
    "OUTPUT_DIR = \"llama31-8b-finance-qlora-lora\"\n",
    "\n",
    "MODEL_NAME = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "\n",
    "PER_DEVICE_BATCH = 2\n",
    "GRAD_ACCUM = 8\n",
    "EPOCHS = 2\n",
    "LR = 1e-4\n",
    "WARMUP_RATIO = 0.03\n",
    "LOGGING_STEPS = 25\n",
    "SAVE_STEPS = 50\n",
    "\n",
    "# LoRA\n",
    "LORA_R = 16\n",
    "LORA_ALPHA = 32\n",
    "LORA_DROPOUT = 0.05\n",
    "\n",
    "# -------------------------\n",
    "# Sanity checks\n",
    "# -------------------------\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Dataset not found at: {DATA_PATH}\")\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA GPU not detected. QLoRA fine-tuning requires a GPU.\")\n",
    "\n",
    "print(\"‚úÖ CUDA:\", torch.cuda.get_device_name(0))\n",
    "print(\"‚úÖ DATA_PATH:\", os.path.abspath(DATA_PATH))\n",
    "\n",
    "# -------------------------\n",
    "# Load model + tokenizer (4-bit)\n",
    "# -------------------------\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,\n",
    "    max_seq_length=MAX_SEQ_LENGTH,\n",
    "    dtype=None,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# Important: ensure tokenizer has a pad token for padding=\"max_length\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -------------------------\n",
    "# Attach LoRA adapters (QLoRA)\n",
    "# -------------------------\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Read JSONL into memory (650-ish rows is fine)\n",
    "# -------------------------\n",
    "texts = []\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        t = obj.get(\"text\", None)\n",
    "        if isinstance(t, str) and t.strip():\n",
    "            texts.append(t)\n",
    "\n",
    "if len(texts) == 0:\n",
    "    raise RuntimeError(\"Loaded 0 training examples. Check your JSONL content.\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(texts)} examples\")\n",
    "print(\"üîé Example snippet:\", texts[0][:200].replace(\"\\n\", \"\\\\n\"))\n",
    "\n",
    "# -------------------------\n",
    "# Torch Dataset (no pyarrow)\n",
    "# -------------------------\n",
    "class ChatMLJsonlDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        input_ids = enc[\"input_ids\"][0]\n",
    "        attention_mask = enc[\"attention_mask\"][0]\n",
    "        labels = input_ids.clone()  # causal LM labels\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "train_dataset = ChatMLJsonlDataset(texts, tokenizer, MAX_SEQ_LENGTH)\n",
    "\n",
    "# -------------------------\n",
    "# Training args + Trainer\n",
    "# -------------------------\n",
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=PER_DEVICE_BATCH,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    save_total_limit=2,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    report_to=\"none\",\n",
    "    seed=42,\n",
    "    remove_unused_columns=False,  # IMPORTANT for custom datasets\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Train\n",
    "# -------------------------\n",
    "trainer.train()\n",
    "\n",
    "# -------------------------\n",
    "# Save LoRA adapters + tokenizer\n",
    "# -------------------------\n",
    "model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"‚úÖ Saved LoRA adapters + tokenizer to: {OUTPUT_DIR}\")\n",
    "\n",
    "# -------------------------\n",
    "# OPTIONAL: Merge LoRA -> 16-bit full model (often OOM; skip if unsure)\n",
    "# -------------------------\n",
    "# MERGED_DIR = \"llama31-8b-finance-merged\"\n",
    "# model.save_pretrained_merged(MERGED_DIR, tokenizer, save_method=\"merged_16bit\")\n",
    "# print(f\"‚úÖ Saved merged 16-bit model to: {MERGED_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1f48f",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a518b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: unsloth in /home/jovyan/.local/lib/python3.10/site-packages (2025.12.9)\n",
      "Requirement already satisfied: transformers in /home/jovyan/.local/lib/python3.10/site-packages (4.57.3)\n",
      "Requirement already satisfied: peft in /home/jovyan/.local/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: accelerate in /home/jovyan/.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/jovyan/.local/lib/python3.10/site-packages (0.49.0)\n",
      "Requirement already satisfied: torch in /home/jovyan/.local/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.12.7 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (2025.12.7)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torchvision in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.24.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.24.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.8)\n",
      "Requirement already satisfied: tyro in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (1.0.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.24.4)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.0.33.post2)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (3.5.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (4.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.4.28)\n",
      "Requirement already satisfied: requests in /home/jovyan/.local/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/jovyan/.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jovyan/.local/lib/python3.10/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.9.5)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.15.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (9.5.0)\n",
      "Requirement already satisfied: msgspec in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.20.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->diffusers->unsloth) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from tyro->unsloth) (4.4.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U unsloth transformers peft accelerate bitsandbytes torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59846d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Unsloth cannot find any torch accelerator? You need a GPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Config\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/__init__.py:92\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     81\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please update Unsloth and Unsloth-Zoo to the latest version!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo this via `pip install --upgrade --force-reinstall --no-cache-dir --no-deps unsloth unsloth_zoo`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         )\n\u001b[1;32m     84\u001b[0m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munsloth_zoo\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PackageNotFoundError:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo` then retry!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth_zoo/__init__.py:146\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m logging, torchao_logger, HideLoggingMessage\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Get device types and other variables\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_type\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    147\u001b[0m     is_hip,\n\u001b[1;32m    148\u001b[0m     get_device_type,\n\u001b[1;32m    149\u001b[0m     DEVICE_TYPE,\n\u001b[1;32m    150\u001b[0m     DEVICE_TYPE_TORCH,\n\u001b[1;32m    151\u001b[0m     DEVICE_COUNT,\n\u001b[1;32m    152\u001b[0m     ALLOW_PREQUANTIZED_MODELS,\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Torch 2.9 removed PYTORCH_HIP_ALLOC_CONF and PYTORCH_CUDA_ALLOC_CONF\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m major_torch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m minor_torch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth_zoo/device_type.py:56\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth currently only works on NVIDIA, AMD and Intel GPUs.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m DEVICE_TYPE : \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mget_device_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# HIP fails for autocast and other torch functions. Use CUDA instead\u001b[39;00m\n\u001b[1;32m     58\u001b[0m DEVICE_TYPE_TORCH \u001b[38;5;241m=\u001b[39m DEVICE_TYPE\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth_zoo/device_type.py:46\u001b[0m, in \u001b[0;36mget_device_type\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m---> 46\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth cannot find any torch accelerator? You need a GPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     accelerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(torch\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mcurrent_accelerator())\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accelerator \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhip\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Unsloth cannot find any torch accelerator? You need a GPU."
     ]
    }
   ],
   "source": [
    "# Finetuning eval: compare your FT LoRA (llama31-8b-finance-qlora-lora)\n",
    "# vs the original Unsloth base (Meta-Llama-3.1-8B-Instruct-bnb-4bit)\n",
    "#\n",
    "# Works in a notebook or a .py file.\n",
    "#\n",
    "# If you haven't installed deps:\n",
    "# pip install -U unsloth transformers peft accelerate bitsandbytes torch\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE_MODEL_ID = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "# Set this to your local adapter folder OR a HF repo id containing the LoRA adapter weights\n",
    "FT_ADAPTER_PATH = \"llama31-8b-finance-qlora-lora\"  # e.g., \"./llama31-8b-finance-qlora-lora\"\n",
    "\n",
    "MAX_NEW_TOKENS = 384\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.9\n",
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# 5 finance/investing questions (picked from your list)\n",
    "# -----------------------------\n",
    "test_questions = [\n",
    "    \"Explain look-ahead bias in backtesting and how to avoid it.\",\n",
    "    \"What is survivorship bias and why does it matter in equity datasets?\",\n",
    "    \"Compare VaR and Expected Shortfall conceptually. When is ES preferred?\",\n",
    "    \"Why might a model have high AUC but poor calibration?\",\n",
    "    \"Why can a high Sharpe ratio be misleading in small samples?\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def load_base_model():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=BASE_MODEL_ID,\n",
    "        max_seq_length=4096,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,  # let unsloth choose\n",
    "    )\n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_ft_model(tokenizer):\n",
    "    # Load the same base again (clean weights), then attach the LoRA adapter\n",
    "    model, _tok = FastLanguageModel.from_pretrained(\n",
    "        model_name=BASE_MODEL_ID,\n",
    "        max_seq_length=4096,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    # Attach adapter robustly across PEFT versions:\n",
    "    # - Prefer PeftModel.from_pretrained (most compatible)\n",
    "    # - If you have a merged model instead of an adapter, load that as a normal HF model instead.\n",
    "    model = PeftModel.from_pretrained(model, FT_ADAPTER_PATH)\n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "    return model\n",
    "\n",
    "def format_chat(tokenizer, user_text):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful finance and investing assistant. Be accurate, concise, and practical.\"},\n",
    "        {\"role\": \"user\", \"content\": user_text},\n",
    "    ]\n",
    "    # Unsloth tokenizers support apply_chat_template\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return input_ids\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_answer(model, tokenizer, question):\n",
    "    input_ids = format_chat(tokenizer, question).to(model.device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=model.device)\n",
    "\n",
    "    gen = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        do_sample=(TEMPERATURE > 0),\n",
    "        top_p=TOP_P,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(gen[0], skip_special_tokens=False)\n",
    "\n",
    "    # Extract only the assistant completion if possible\n",
    "    # (Works for most ChatML-ish templates)\n",
    "    # Fallback: return full decoded text.\n",
    "    for marker in [\"<|assistant|>\", \"assistant\\n\", \"### Assistant:\"]:\n",
    "        if marker in text:\n",
    "            return text.split(marker, 1)[-1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def judge_with_base(base_model, tokenizer, question, base_answer, ft_answer):\n",
    "    \"\"\"\n",
    "    Optional: LLM-as-judge using the BASE model only.\n",
    "    Produces a score (1-10) for each answer + short rationale.\n",
    "    \"\"\"\n",
    "    judge_prompt = f\"\"\"\n",
    "You are grading two answers to the same finance/investing question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer A (BASE):\n",
    "{base_answer}\n",
    "\n",
    "Answer B (FT):\n",
    "{ft_answer}\n",
    "\n",
    "Rubric (most important first):\n",
    "1) Factual correctness (no hallucinations)\n",
    "2) Finance-specific insight / domain depth\n",
    "3) Practical usefulness (how-to, pitfalls, examples)\n",
    "4) Clarity and concision\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{{\n",
    "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
    "  \"score_A\": 1-10,\n",
    "  \"score_B\": 1-10,\n",
    "  \"rationale\": \"1-3 sentences\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    input_ids = format_chat(tokenizer, judge_prompt).to(base_model.device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=base_model.device)\n",
    "    gen = base_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.0,  # deterministic judging\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    out = tokenizer.decode(gen[0], skip_special_tokens=False)\n",
    "    # best-effort extract JSON-ish tail\n",
    "    if \"{\" in out and \"}\" in out:\n",
    "        out = out[out.find(\"{\"): out.rfind(\"}\") + 1]\n",
    "    return out.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# Run evaluation\n",
    "# -----------------------------\n",
    "print(\"Loading BASE model...\")\n",
    "base_model, tokenizer = load_base_model()\n",
    "\n",
    "print(\"Loading FT (LoRA) model...\")\n",
    "ft_model = load_ft_model(tokenizer)\n",
    "\n",
    "results = []\n",
    "start = time.time()\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*90}\\nQ{i}: {q}\\n{'='*90}\")\n",
    "\n",
    "    base_ans = generate_answer(base_model, tokenizer, q)\n",
    "    ft_ans   = generate_answer(ft_model, tokenizer, q)\n",
    "\n",
    "    print(\"\\n--- BASE ANSWER ------------------------------------------------------------\")\n",
    "    print(base_ans)\n",
    "\n",
    "    print(\"\\n--- FT ANSWER --------------------------------------------------------------\")\n",
    "    print(ft_ans)\n",
    "\n",
    "    judge_json = judge_with_base(base_model, tokenizer, q, base_ans, ft_ans)\n",
    "    print(\"\\n--- JUDGE (BASE as judge, JSON) -------------------------------------------\")\n",
    "    print(judge_json)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"base_answer\": base_ans,\n",
    "        \"ft_answer\": ft_ans,\n",
    "        \"judge_json\": judge_json,\n",
    "    })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\nDone. Evaluated {len(test_questions)} questions in {elapsed:.1f}s.\")\n",
    "\n",
    "# If you want to save results:\n",
    "import json\n",
    "with open(\"eval_results_sft_ft_vs_base.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Saved: eval_results_sft_ft_vs_base.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed25391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BASE model...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading FT model...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "\n",
      "==========================================================================================\n",
      "Q1: What is the difference between market impact and slippage?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is the difference between market impact and slippage?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Market impact and slippage are two related but distinct concepts in finance, particularly in trading and investing.\n",
      "\n",
      "**Market Impact:**\n",
      "Market impact refers to the effect of a large trade on the price of a security. When a significant order is executed, it can influence the market price, causing it to move away from its original level. This is because the trade can absorb a large portion of the available liquidity, leading to a temporary imbalance in supply and demand. As a result, the price may move against the trader, increasing the cost of the trade.\n",
      "\n",
      "**Slippage:**\n",
      "Slippage, on the other hand, is the difference between the expected price of a trade and the actual price at which the trade is executed. It is a measure of the price movement that occurs due to market impact, liquidity issues, or other market conditions. Slippage can be positive (in favor of the trader) or negative (against the trader), depending on the direction of the price movement.\n",
      "\n",
      "To illustrate the difference:\n",
      "\n",
      "* Market impact: A large buy order is executed, causing the price to rise due to the increased demand.\n",
      "* Slippage: The trader expected to buy the security at $100, but due to market impact, the price rose to $105, resulting in a slippage of $5.\n",
      "\n",
      "In summary, market impact is the cause of price movement, while slippage is the effect of that movement, measured as the difference between the expected and actual prices.<|eot_id|>\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is the difference between market impact and slippage?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Market impact and slippage are related but distinct concepts in finance:\n",
      "\n",
      "Market Impact: The market impact is the change in the price of a security due to the order flow, typically caused by a large trade or a series of trades. It reflects the cost of executing a trade in a market where the order size exceeds the available liquidity. Market impact is usually measured as a percentage of the trade size and can be positive (increasing price) or negative (decreasing price).\n",
      "\n",
      "Slippage: Slippage is the difference between the expected execution price and the actual execution price. It's the cost of executing a trade at a price that's different from the desired price, often due to market conditions, liquidity, or order execution timing. Slippage can be positive (loss) or negative (gain), but it's usually considered a loss.\n",
      "\n",
      "To illustrate the difference:\n",
      "\n",
      "- Market impact: A large buy order increases the price of a stock, causing the market impact to be positive.\n",
      "- Slippage: If the order is executed at a higher price than the desired price, the slippage is positive (a loss).<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provided a clear and concise explanation of the difference between market impact and slippage, including a practical example. It also highlighted the key points of market impact and slippage, making it easier to understand the concepts. Answer B provided a good explanation, but it was slightly less clear and concise.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q2: How does return autocorrelation affect performance evaluation?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does return autocorrelation affect performance evaluation?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Return autocorrelation, also known as serial correlation or autocorrelation, refers to the tendency of returns to be correlated with each other over time. In other words, if a security's return is high (or low) in one period, it is likely to be high (or low) in the next period as well.\n",
      "\n",
      "Autocorrelation can significantly affect performance evaluation in several ways:\n",
      "\n",
      "1. **Overestimation of returns**: If a security's returns are autocorrelated, it may appear to have a higher return than it actually does. This is because the autocorrelated returns are likely to be followed by similar returns, which can artificially inflate the security's average return.\n",
      "2. **Underestimation of risk**: Autocorrelated returns can also lead to an underestimation of risk. If a security's returns are autocorrelated, it may appear to be less volatile than it actually is, which can result in a lower estimated risk.\n",
      "3. **Incorrect ranking**: Autocorrelation can also affect the ranking of securities. If two securities have similar returns, but one has autocorrelated returns and the other does not, the autocorrelated security may appear to be more attractive than it actually is.\n",
      "4. **Incorrect calculation of Sharpe ratio**: The Sharpe ratio, which is a measure of risk-adjusted return, can be affected by autocorrelation. If a security's returns are autocorrelated, its Sharpe ratio may be artificially inflated, leading to incorrect conclusions about its performance.\n",
      "\n",
      "To account for autocorrelation in performance evaluation, analysts can use techniques such as:\n",
      "\n",
      "1. **Detrending**: Removing the trend from the returns to reduce autocorrelation.\n",
      "2. **Differencing**: Subtracting the previous period's return from the current period's return to reduce autocorrelation.\n",
      "3. **Using autocorrelation-adjusted returns**: Using returns that have\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How does return autocorrelation affect performance evaluation?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Return autocorrelation, or serial correlation, refers to the tendency of returns to be correlated with each other over time. This can impact performance evaluation in several ways:\n",
      "\n",
      "1. **Overestimation of Sharpe ratio**: Serial correlation can inflate the Sharpe ratio, as it artificially increases the return while keeping the standard deviation the same. This can lead to overestimation of a strategy's risk-adjusted return.\n",
      "2. **Incorrect calculation of VaR**: Value-at-Risk (VaR) is a measure of potential loss. Serial correlation can lead to incorrect VaR estimates, as it can cause the VaR to be underestimated (or overestimated) due to the autocorrelated nature of returns.\n",
      "3. **Misleading conclusions about diversification**: Serial correlation can make it appear as though a portfolio is more diversified than it actually is, as the autocorrelation can mask the underlying correlations between assets.\n",
      "4. **Impact on backtesting**: Serial correlation can affect the accuracy of backtesting, as it can lead to overfitting or underfitting of the model.\n",
      "5. **Difficulty in estimating true risk**: Serial correlation can make it challenging to estimate the true risk of a portfolio, as the autocorrelation can inflate the standard deviation.\n",
      "\n",
      "To account for return autocorrelation, performance evaluation methods often use:\n",
      "\n",
      "1. **Adjusted Sharpe ratio**: Using a modified Sharpe ratio that accounts for serial correlation, such as the \"adjusted Sharpe ratio\" or \"autocorrelation-corrected Sharpe ratio.\"\n",
      "2. **Corrected VaR**: Using a VaR estimation method that accounts for serial correlation, such as the \"conditional VaR\" or \"autoregressive VaR.\"\n",
      "3. **Adjusted risk measures**: Using risk measures that are less sensitive to serial correlation, such as the \"Conditional Value-at-Risk\" (CVaR) or \"Expected Shortfall\" (\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 8,\n",
      "  \"score_B\": 6,\n",
      "  \"rationale\": \"Answer A provides a clear and concise explanation of the impact of return autocorrelation on performance evaluation, including its effects on the Sharpe ratio, VaR, and diversification. It also provides practical suggestions for accounting for autocorrelation in performance evaluation. Answer B provides some relevant information, but it is less comprehensive and lacks practical suggestions.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q3: What is selection bias in empirical finance studies?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is selection bias in empirical finance studies?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Selection bias in empirical finance studies refers to a type of bias that occurs when the sample of observations used in a study is not representative of the population being studied. This can happen when the selection process for the sample is not random or when certain observations are excluded from the analysis.\n",
      "\n",
      "In finance, selection bias can manifest in several ways:\n",
      "\n",
      "1. **Survivorship bias**: This occurs when only surviving firms or investments are included in the sample, while those that have failed or exited the market are excluded. This can lead to an overestimation of the performance of the surviving firms or investments.\n",
      "2. **Look-back bias**: This occurs when the sample includes only firms or investments that have been in existence for a certain period, while those that have exited the market earlier are excluded.\n",
      "3. **Self-selection bias**: This occurs when firms or investors self-select into the sample based on certain characteristics, such as size or performance.\n",
      "\n",
      "Selection bias can lead to inaccurate conclusions and recommendations in finance research. For example, a study that finds that small-cap stocks outperform large-cap stocks may be biased if it only includes small-cap stocks that have survived for a certain period.\n",
      "\n",
      "To mitigate selection bias, researchers can use techniques such as:\n",
      "\n",
      "1. **Matching**: Matching firms or investments with similar characteristics to those in the sample.\n",
      "2. **Weighting**: Weighting the sample to reflect the population being studied.\n",
      "3. **Bootstrapping**: Using resampling techniques to estimate the distribution of the sample.\n",
      "4. **Using alternative datasets**: Using datasets that are less prone to selection bias, such as those that include failed or exited firms or investments.\n",
      "\n",
      "By being aware of selection bias and using techniques to mitigate it, researchers can increase the validity and reliability of their findings in finance research.<|eot_id|>\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is selection bias in empirical finance studies?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Selection bias in empirical finance studies occurs when the sample used to estimate a relationship or test a hypothesis is not representative of the population of interest, leading to biased or misleading conclusions. This can happen in various ways:\n",
      "\n",
      "1. **Survivorship bias**: Focusing on firms or assets that have survived to the present, ignoring those that have failed or been delisted. This can lead to an upward bias in performance metrics, as only successful firms are included.\n",
      "2. **Look-ahead bias**: Using data that is not available at the time of the analysis, such as future returns or events. This can create a self-fulfilling prophecy, where the analysis predicts outcomes that are already known.\n",
      "3. **Data snooping**: Testing multiple hypotheses or models on the same data set, increasing the likelihood of false positives.\n",
      "4. **Sample selection**: Selecting a sample based on specific characteristics, such as size or industry, that may not be representative of the broader population.\n",
      "5. **Time-varying bias**: Failing to account for changes in market conditions, regulations, or other factors that affect the relationship being studied.\n",
      "\n",
      "To mitigate selection bias, researchers should:\n",
      "\n",
      "1. **Use representative samples**: Ensure the sample is representative of the population of interest.\n",
      "2. **Use robust estimation techniques**: Employ techniques that are less sensitive to outliers or non-normality, such as robust regression or bootstrapping.\n",
      "3. **Control for confounding variables**: Include variables that may affect the relationship being studied.\n",
      "4. **Use out-of-sample testing**: Validate findings using data not used in the initial analysis.\n",
      "5. **Report limitations**: Clearly disclose potential biases and limitations of the study.<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provides a clear and concise explanation of selection bias in empirical finance studies, including its types and mitigation techniques. It also provides practical examples and uses finance-specific language. Answer B provides a good explanation, but is slightly less clear and concise, and lacks specific examples.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q4: When would you use log returns instead of simple returns, and why?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "When would you use log returns instead of simple returns, and why?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "You would use log returns instead of simple returns in the following situations:\n",
      "\n",
      "1. **Accurate representation of compounding**: Log returns accurately capture the compounding effect of returns over time, especially when returns are not constant. Simple returns can lead to an overestimation of returns when compounded over time.\n",
      "\n",
      "2. **Comparability across different time periods**: Log returns allow for easier comparison of returns across different time periods, as they are not affected by the time period's length. Simple returns can make it difficult to compare returns between periods of different lengths.\n",
      "\n",
      "3. **Calculating volatility**: Log returns are used to calculate volatility, which is a measure of the standard deviation of returns. This is because log returns are normally distributed, making it easier to calculate volatility.\n",
      "\n",
      "4. **Calculating Sharpe Ratio**: The Sharpe Ratio is a measure of risk-adjusted return. It requires log returns to accurately calculate the standard deviation of returns.\n",
      "\n",
      "5. **Analyzing returns in the presence of negative returns**: Log returns can handle negative returns without causing issues, whereas simple returns can lead to negative values when returns are negative.\n",
      "\n",
      "6. **Calculating Value-at-Risk (VaR)**: VaR requires log returns to accurately calculate the probability of returns falling below a certain threshold.\n",
      "\n",
      "In general, log returns are preferred over simple returns when you need to accurately capture the compounding effect, compare returns across different time periods, or calculate volatility and other risk metrics.<|eot_id|>\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "When would you use log returns instead of simple returns, and why?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "You use log returns instead of simple returns when:\n",
      "\n",
      "1. **Multiplicative growth**: Log returns are suitable for assets with multiplicative growth, like stocks, where a 10% increase today means a 110% value tomorrow. Simple returns would be 11%, which is incorrect.\n",
      "2. **Compounding**: Log returns accurately capture compounding effects, such as reinvested dividends or interest. Simple returns would underestimate the growth.\n",
      "3. **Volatility**: Log returns are more robust to extreme events, like crashes or blowups, as they are less sensitive to outliers.\n",
      "4. **Mathematical properties**: Log returns have desirable mathematical properties, like additive linearity and the ability to model geometric Brownian motion.\n",
      "\n",
      "In practice, log returns are used in finance for:\n",
      "\n",
      "1. **Portfolio optimization**: Log returns are used in mean-variance optimization and other portfolio optimization techniques.\n",
      "2. **Risk analysis**: Log returns are used to calculate Value-at-Risk (VaR) and Expected Shortfall (ES).\n",
      "3. **Option pricing**: Log returns are used in Black-Scholes and other option pricing models.\n",
      "4. **Time-series analysis**: Log returns are used in time-series analysis, such as ARIMA and GARCH models.\n",
      "\n",
      "In Python, you can calculate log returns using the `numpy` library:\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "# Simple returns\n",
      "returns = np.diff(np.log(data + 1))\n",
      "\n",
      "# Log returns\n",
      "log_returns = np.diff(np.log(data))\n",
      "```\n",
      "Note that `data` should be a pandas Series or a numpy array of prices.<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provided a clear and comprehensive explanation of when to use log returns, including its advantages and practical applications in finance. It also provided a correct example of how to calculate log returns in Python. Answer B provided some correct information, but it was less comprehensive and lacked a clear example.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q5: What does overfitting look like in time-series forecasting models?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What does overfitting look like in time-series forecasting models?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Overfitting in time-series forecasting models occurs when a model is too complex and performs well on the training data but fails to generalize well to new, unseen data. This can lead to poor out-of-sample performance.\n",
      "\n",
      "Common signs of overfitting in time-series forecasting models include:\n",
      "\n",
      "1. **High training accuracy**: The model performs extremely well on the training data, often with an accuracy or R-squared value close to 1.\n",
      "2. **Poor out-of-sample performance**: The model's performance on new, unseen data is significantly worse than its performance on the training data.\n",
      "3. **Large difference between training and validation metrics**: If you're using a validation set, the difference between the training and validation metrics (e.g., accuracy, R-squared) is large, indicating that the model is overfitting.\n",
      "4. **Model complexity**: The model has a large number of parameters, which can lead to overfitting.\n",
      "5. **High variance**: The model's predictions have high variance, indicating that the model is overfitting.\n",
      "6. **Failure to capture underlying patterns**: The model fails to capture the underlying patterns in the data, such as seasonality or trends.\n",
      "\n",
      "To mitigate overfitting in time-series forecasting models, you can try the following:\n",
      "\n",
      "1. **Regularization techniques**: Use regularization techniques, such as L1 or L2 regularization, to reduce the model's complexity.\n",
      "2. **Early stopping**: Stop training the model when its performance on the validation set starts to degrade.\n",
      "3. **Cross-validation**: Use cross-validation to evaluate the model's performance on unseen data.\n",
      "4. **Simplifying the model**: Simplify the model by reducing the number of parameters or using a simpler model architecture.\n",
      "5. **Collecting more data**: Collect more data to increase the size of the training set and reduce overfitting.\n",
      "\n",
      "Some common techniques to prevent overfitting in time\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What does overfitting look like in time-series forecasting models?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Overfitting in time-series forecasting models typically manifests as:\n",
      "\n",
      "1. **High training accuracy**: The model performs exceptionally well on the training data, often with an R-squared (R¬≤) or mean absolute percentage error (MAPE) close to 0.\n",
      "2. **Poor out-of-sample performance**: When applied to new, unseen data, the model's accuracy drops significantly, indicating it has memorized the training data's noise rather than learning the underlying patterns.\n",
      "3. **Unrealistic or unstable predictions**: The model may produce implausible or erratic forecasts, such as:\n",
      "\t* Large, unexplained spikes or dips.\n",
      "\t* Unusual patterns or cycles not present in the training data.\n",
      "\t* Overly sensitive responses to small changes in inputs.\n",
      "4. **High variance or sensitivity**: Small changes in model parameters or inputs can result in drastically different forecasts, indicating the model is overly reliant on specific data points or noise.\n",
      "5. **Difficulty generalizing**: The model may struggle to adapt to new data, such as changes in seasonality, trends, or external factors, leading to poor performance in real-world applications.\n",
      "\n",
      "To mitigate overfitting, consider:\n",
      "\n",
      "1. **Regularization techniques**: Lasso, Ridge, or Elastic Net regularization can reduce model complexity and prevent overfitting.\n",
      "2. **Early stopping**: Monitor the model's performance on a validation set and stop training when performance starts to degrade.\n",
      "3. **Data augmentation**: Increase the size of the training set by adding noise, interpolating missing values, or using techniques like data imputation.\n",
      "4. **Ensemble methods**: Combine the predictions of multiple models to reduce overfitting and improve overall performance.\n",
      "5. **Cross-validation**: Evaluate the model's performance on multiple subsets of the data to ensure it generalizes well.\n",
      "6. **Feature engineering**: Extract relevant, informative features from the data to improve the model's ability to learn\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provides a clear and concise explanation of overfitting in time-series forecasting models, including its signs and mitigation techniques. It also provides a more comprehensive list of techniques to prevent overfitting. Answer B provides a good explanation, but it is less detailed and lacks some key points.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q6: Explain data snooping / multiple testing in factor research. How do you control it?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain data snooping / multiple testing in factor research. How do you control it?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Data Snooping and Multiple Testing in Factor Research**\n",
      "\n",
      "Data snooping, also known as multiple testing or the multiple comparisons problem, is a significant concern in factor research. It occurs when researchers repeatedly test various hypotheses or factors on the same dataset, leading to an inflated probability of obtaining statistically significant results by chance.\n",
      "\n",
      "**Why is data snooping a problem?**\n",
      "\n",
      "1. **Increased Type I error rate**: With multiple tests, the probability of obtaining a statistically significant result (Type I error) increases, even if there is no real effect.\n",
      "2. **Overfitting**: Researchers may inadvertently select factors that perform well on the specific dataset used but fail to generalize to new data.\n",
      "3. **Lack of robustness**: Factors that appear significant in one dataset may not be significant in another, leading to inconsistent results.\n",
      "\n",
      "**Controlling data snooping:**\n",
      "\n",
      "1. **Pre-specification**: Before analyzing the data, researchers should specify the factors they want to test and the hypotheses they aim to investigate. This helps to avoid the temptation to test multiple factors and reduces the risk of data snooping.\n",
      "2. **Cross-validation**: Divide the dataset into training and testing sets. Evaluate the performance of the factors on the training set and then test them on the held-out testing set. This helps to assess the generalizability of the factors.\n",
      "3. **Bootstrapping**: Resample the dataset with replacement to create multiple bootstrap samples. Evaluate the performance of the factors on each bootstrap sample and calculate the proportion of samples where the factor is significant. This provides an estimate of the probability of obtaining a statistically significant result by chance.\n",
      "4. **False discovery rate (FDR) control**: Use techniques like the Benjamini-Hochberg procedure to control the FDR, which is the expected proportion of false discoveries among all discoveries.\n",
      "5. **Regularization**: Use regularization techniques, such as Lasso or Ridge regression,\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain data snooping / multiple testing in factor research. How do you control it?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Data snooping, also known as multiple testing or the multiple-comparisons problem, occurs when a researcher tests many hypotheses on the same data set, increasing the likelihood of false positives. In factor research, this issue arises when:\n",
      "\n",
      "1. **Many factors are tested**: A researcher may examine hundreds of potential factors (e.g., stock characteristics, economic indicators, or sentiment metrics) to identify those that are statistically significant.\n",
      "2. **Multiple tests are performed**: Each factor is tested separately, often using the same data set, which increases the overall Type I error rate (the probability of rejecting a true null hypothesis).\n",
      "\n",
      "To control data snooping, researchers use various techniques:\n",
      "\n",
      "1. **Bonferroni correction**: Divide the desired significance level (e.g., 0.05) by the number of tests performed. For example, if 100 factors are tested, the Bonferroni-corrected significance level would be 0.05 / 100 = 0.0005.\n",
      "2. **Holm-Bonferroni method**: A more powerful approach that adjusts the significance level based on the number of tests and the order of the results (from strongest to weakest).\n",
      "3. **False Discovery Rate (FDR) control**: Estimate the FDR, which is the expected proportion of false positives among all significant results. FDR control methods, such as the Benjamini-Hochberg procedure, adjust the significance level to control the FDR.\n",
      "4. **Cross-validation**: Split the data into training and testing sets, and perform the factor selection process on the training set. Evaluate the performance of the selected factors on the testing set to reduce overfitting.\n",
      "5. **Data splitting**: Divide the data into multiple subsets, perform the factor selection process on each subset, and combine the results to reduce overfitting.\n",
      "6. **Regularization**: Use techniques like Lasso or Ridge regression\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provides a clear and concise explanation of data snooping and multiple testing in factor research, including its causes and consequences. It also provides a comprehensive list of methods to control data snooping, including Bonferroni correction, Holm-Bonferroni method, FDR control, cross-validation, data splitting, and regularization. Answer B provides a good explanation, but it is less comprehensive and lacks the clarity of Answer A.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q7: What is walk-forward (rolling) validation and why is it preferred for time series?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is walk-forward (rolling) validation and why is it preferred for time series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Walk-Forward (Rolling) Validation:**\n",
      "\n",
      "Walk-forward validation, also known as rolling validation, is a statistical technique used to evaluate the performance of a model on a time series dataset. It involves splitting the data into training and testing sets, where the training set is used to train the model, and the testing set is used to evaluate its performance.\n",
      "\n",
      "**Key Characteristics:**\n",
      "\n",
      "1. **Rolling Window**: The data is divided into overlapping windows, where each window represents a specific period (e.g., day, week, month).\n",
      "2. **Training and Testing**: The model is trained on the data within the current window and evaluated on the data within the next window.\n",
      "3. **Overlapping Windows**: Each new window overlaps with the previous one, allowing the model to be re-trained and re-evaluated as new data becomes available.\n",
      "\n",
      "**Why Walk-Forward Validation is Preferred for Time Series:**\n",
      "\n",
      "1. **Real-time Decision Making**: Walk-forward validation allows for real-time decision making, as the model is re-trained and re-evaluated as new data becomes available.\n",
      "2. **Handling Non-Stationarity**: Time series data often exhibits non-stationarity, where the statistical properties of the data change over time. Walk-forward validation helps to account for these changes.\n",
      "3. **Reducing Overfitting**: By re-training and re-evaluating the model on new data, walk-forward validation reduces the risk of overfitting, where the model becomes too specialized to the training data.\n",
      "4. **Improved Generalizability**: Walk-forward validation helps to improve the generalizability of the model, as it is evaluated on a diverse set of data, rather than just the training data.\n",
      "\n",
      "**Example Use Case:**\n",
      "\n",
      "Suppose we want to evaluate the performance of a stock market prediction model using walk-forward validation. We divide the data into 1-year windows, where each window represents a\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is walk-forward (rolling) validation and why is it preferred for time series?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Walk-Forward (Rolling) Validation:**\n",
      "\n",
      "Walk-forward validation, also known as rolling validation, is a statistical technique used to evaluate the performance of a model or strategy on a time series dataset. It involves splitting the data into overlapping segments (windows) and training the model on each segment before evaluating its performance on the subsequent segment.\n",
      "\n",
      "**Key Steps:**\n",
      "\n",
      "1. **Window size**: Choose a fixed window size (e.g., 1 year, 3 months, etc.) that will be used to split the data.\n",
      "2. **Training**: Train the model on the current window of data (e.g., the last 1 year).\n",
      "3. **Validation**: Evaluate the model's performance on the next window of data (e.g., the next 1 year).\n",
      "4. **Overlap**: Shift the window forward by one period (e.g., one month, one quarter, etc.) and repeat steps 2-3.\n",
      "\n",
      "**Why Walk-Forward Validation is Preferred:**\n",
      "\n",
      "1. **Avoids Overfitting**: Walk-forward validation helps prevent overfitting by ensuring the model is not trained on the same data it's being evaluated on.\n",
      "2. **Captures Real-World Dynamics**: By using overlapping windows, the model is exposed to changing market conditions, allowing it to adapt and improve over time.\n",
      "3. **Provides a More Realistic Picture**: Walk-forward validation gives a more accurate representation of a model's performance in real-world scenarios, where data is typically not available in advance.\n",
      "4. **Helps Identify Robustness**: By evaluating performance on multiple windows, you can assess a model's robustness to different market conditions and identify potential weaknesses.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you're evaluating a stock forecasting model using daily data from the last 5 years. You choose a window size of 1 year and train the model on the last 4 years. Then, you evaluate\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 7,\n",
      "  \"rationale\": \"Answer A provided a clear and concise explanation of walk-forward validation, including its key characteristics and benefits. It also provided a practical example, which helped to illustrate the concept. Answer B, while providing some relevant information, was less clear and concise.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q8: Explain leakage in feature engineering for financial ML, with 2 concrete examples.\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain leakage in feature engineering for financial ML, with 2 concrete examples.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Leakage in Feature Engineering:**\n",
      "\n",
      "In feature engineering for financial machine learning (ML), leakage occurs when a model has access to information that it shouldn't have, which leads to overfitting and poor generalization. This happens when the model is trained on data that includes target variable information (e.g., labels or outcomes) that is not supposed to be used during training.\n",
      "\n",
      "**Example 1: Using future returns to predict stock prices**\n",
      "\n",
      "Suppose we want to predict the stock price of a company using historical data. We create a feature that includes the future return of the stock (e.g., the return 1 month from now). If we train a model on this data, it will learn to predict the stock price based on the future return, which is not available during testing. This is an example of leakage.\n",
      "\n",
      "**Example 2: Using account balance to predict loan defaults**\n",
      "\n",
      "In a credit risk model, we might use historical account balance data to predict the likelihood of loan defaults. However, if we include the current account balance in the training data, the model will learn to predict defaults based on this information, which is not available during testing. This is another example of leakage.\n",
      "\n",
      "**Consequences of Leakage:**\n",
      "\n",
      "Leakage can lead to:\n",
      "\n",
      "1. Overfitting: The model becomes too specialized to the training data and fails to generalize well to new data.\n",
      "2. Poor performance: The model's performance on unseen data is poor, leading to incorrect predictions.\n",
      "3. Lack of robustness: The model is not robust to changes in the data or the underlying assumptions.\n",
      "\n",
      "**Mitigating Leakage:**\n",
      "\n",
      "To avoid leakage, we can use techniques such as:\n",
      "\n",
      "1. Time-series splitting: Split the data into training and testing sets, ensuring that the testing set does not include any information that the model should not have access to.\n",
      "2. Feature engineering: Create new features that do not\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain leakage in feature engineering for financial ML, with 2 concrete examples.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Leakage in Feature Engineering:**\n",
      "Leakage occurs when a feature used in model training is also available to the user or trader, allowing them to exploit the model's predictions or patterns. This can lead to biased results, overfitting, and poor generalizability.\n",
      "\n",
      "**Example 1: Stock Price vs. Future Price**\n",
      "Suppose a model predicts stock prices based on historical data, including the current price. If the model uses the current price as a feature, it's a leakage because the user can simply look up the current price to make informed trades. To avoid leakage, use lagged or historical prices as features, e.g., the price from the previous day.\n",
      "\n",
      "**Example 2: Order Book vs. Market Order**\n",
      "In a trading scenario, a model might use the order book (bid and ask prices, quantities, and timestamps) as features to predict market orders. However, if the model uses real-time order book data, it's a leakage because the user can access the same data to execute trades. To avoid leakage, use historical order book data or aggregate features like order book depth or imbalance.\n",
      "\n",
      "**Best Practices:**\n",
      "\n",
      "1. **Use historical data**: Use lagged or historical features to avoid real-time leakage.\n",
      "2. **Aggregate features**: Use aggregated features like averages, medians, or standard deviations to reduce the impact of leakage.\n",
      "3. **Use proxy features**: Create proxy features that capture the underlying patterns without revealing the exact information.\n",
      "4. **Monitor and test**: Regularly monitor and test your model for leakage to ensure it's not exploiting available information.<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"B\",\n",
      "  \"score_A\": 8,\n",
      "  \"score_B\": 9,\n",
      "  \"rationale\": \"Answer B provides more practical and finance-specific insights, with clear examples and a better explanation of leakage in feature engineering. The response is well-structured and easy to understand.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q9: What does it mean for a strategy to be 'capacity constrained'?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What does it mean for a strategy to be 'capacity constrained'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In finance and investing, a strategy being \"capacity constrained\" means that the strategy has reached its maximum capacity to invest, and it cannot accept any more new investments or assets. This is often due to various constraints, such as:\n",
      "\n",
      "1. **Investment limits**: The strategy may have reached its maximum investment limit, which is set by the fund manager, regulator, or investor.\n",
      "2. **Asset allocation**: The strategy may have allocated all its available assets to the desired asset classes or sectors, making it difficult to add new investments.\n",
      "3. **Risk management**: The strategy may have reached its maximum risk tolerance, and adding new investments could increase the overall risk profile.\n",
      "4. **Regulatory constraints**: The strategy may be subject to regulatory limits on the amount of assets it can hold or the types of investments it can make.\n",
      "\n",
      "When a strategy is capacity constrained, it may:\n",
      "\n",
      "1. **Close to new investors**: The strategy may close to new investors to prevent dilution of existing investments or to maintain its investment discipline.\n",
      "2. **Reject new investments**: The strategy may reject new investments that do not meet its investment criteria or that would exceed its capacity constraints.\n",
      "3. **Adjust its investment approach**: The strategy may adjust its investment approach to accommodate new investments, such as by reducing its exposure to certain asset classes or sectors.\n",
      "\n",
      "Capacity constraints can be a challenge for investment strategies, as they may limit their ability to grow or adapt to changing market conditions. However, they can also provide an opportunity for the strategy to focus on its core investment objectives and maintain its investment discipline.<|eot_id|>\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What does it mean for a strategy to be 'capacity constrained'?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A capacity-constrained strategy is one where the available resources (e.g., capital, computing power, personnel) limit the strategy's ability to fully execute its intended trades or actions. This constraint can prevent the strategy from achieving its full potential or even lead to missed opportunities.\n",
      "\n",
      "Common examples of capacity constraints include:\n",
      "\n",
      "1. **Position sizing**: A strategy may be limited by the amount of capital available to take positions, preventing it from fully exploiting profitable opportunities.\n",
      "2. **Trade execution**: High-frequency trading strategies may be constrained by the number of orders that can be executed per second, limiting their ability to capture market movements.\n",
      "3. **Data processing**: Strategies that rely on complex data analysis may be limited by the processing power or memory available, slowing down or preventing the execution of trades.\n",
      "4. **Risk management**: Strategies may be constrained by risk limits, such as maximum position sizes or maximum daily losses, which can limit their ability to take on more risk.\n",
      "\n",
      "To overcome capacity constraints, traders and investors may use techniques like:\n",
      "\n",
      "1. **Scaling**: Gradually increasing the size of positions or trades to increase the strategy's capacity.\n",
      "2. **Risk management**: Implementing risk controls to limit exposure and prevent over-leveraging.\n",
      "3. **Data optimization**: Improving data processing and analysis to increase the strategy's ability to execute trades.\n",
      "4. **Collaboration**: Working with other traders or investors to share resources and increase capacity.\n",
      "\n",
      "By understanding and addressing capacity constraints, traders and investors can optimize their strategies and achieve better performance.<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provided a more comprehensive explanation of capacity constraints, including specific examples and practical implications. It also provided a clear and concise definition of the concept. Answer B provided a good explanation, but it was slightly less detailed and lacked specific examples.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q10: Why can Sharpe be gamed by smoothing returns? What metrics help detect this?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why can Sharpe be gamed by smoothing returns? What metrics help detect this?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The Sharpe ratio can be gamed by smoothing returns through a process known as \"Sharpe ratio manipulation\" or \"Sharpe ratio arbitrage.\" This occurs when an investor uses various techniques to artificially inflate their Sharpe ratio by smoothing their returns.\n",
      "\n",
      "Smoothing returns can be achieved through various methods, such as:\n",
      "\n",
      "1. **Volatility reduction**: By investing in assets with low volatility, an investor can reduce the overall volatility of their portfolio, which can lead to a higher Sharpe ratio.\n",
      "2. **Return smoothing**: By using techniques such as moving averages or exponential smoothing, an investor can smooth out their returns, making them appear more stable and increasing the Sharpe ratio.\n",
      "3. **Risk reduction**: By diversifying their portfolio or using hedging strategies, an investor can reduce their overall risk, which can lead to a higher Sharpe ratio.\n",
      "\n",
      "Metrics that can help detect Sharpe ratio manipulation include:\n",
      "\n",
      "1. **Modified Sharpe ratio**: This is a modified version of the Sharpe ratio that takes into account the smoothing of returns. It can help detect if an investor is artificially inflating their Sharpe ratio.\n",
      "2. **Sortino ratio**: This is a risk-adjusted return measure that takes into account the downside risk of an investment. It can help detect if an investor is using techniques to smooth their returns.\n",
      "3. **Calmar ratio**: This is a risk-adjusted return measure that takes into account the maximum drawdown of an investment. It can help detect if an investor is using techniques to smooth their returns.\n",
      "4. **Ulcer index**: This is a measure of the pain or discomfort of an investment, taking into account the maximum drawdown and the time spent in that drawdown. It can help detect if an investor is using techniques to smooth their returns.\n",
      "5. **Value-at-Risk (VaR)**: This is a measure of the potential loss of an investment over a\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why can Sharpe be gamed by smoothing returns? What metrics help detect this?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Sharpe ratio can be gamed by smoothing returns because it rewards volatility reduction, which can be achieved through various techniques, such as:\n",
      "\n",
      "1. **Data snooping**: Selecting a subset of data that appears to have lower volatility, thereby inflating the Sharpe ratio.\n",
      "2. **Volatility reduction**: Using techniques like moving averages, exponential smoothing, or other filters to reduce volatility, which can artificially inflate the Sharpe ratio.\n",
      "3. **Overfitting**: Fitting a model to the data and then using the same data to evaluate the model, which can lead to overly optimistic results.\n",
      "\n",
      "Metrics to detect this gaming include:\n",
      "\n",
      "1. **Backtesting**: Evaluate the strategy on out-of-sample data to ensure it generalizes well.\n",
      "2. **Walk-forward optimization**: Split the data into training and testing sets, and optimize the strategy on the training set while evaluating its performance on the testing set.\n",
      "3. **Information ratio**: This metric is similar to the Sharpe ratio but uses a benchmark's excess return instead of its volatility, making it less susceptible to gaming.\n",
      "4. **Maximum drawdown**: This metric measures the maximum peak-to-trough decline in the strategy's value, providing a more comprehensive view of risk.\n",
      "5. **Value-at-risk (VaR)**: This metric estimates the worst-case loss over a specific time horizon, providing a more robust measure of risk.\n",
      "6. **Expected shortfall (ES)**: This metric estimates the average loss beyond the VaR threshold, providing a more comprehensive view of risk.\n",
      "7. **Sharpe ratio with a robust volatility estimator**: Using a robust volatility estimator, such as the median absolute deviation (MAD) or the interquartile range (IQR), can reduce the impact of outliers and make the Sharpe ratio more resistant to gaming.\n",
      "8. **Sharpe ratio with a minimum return threshold**: This approach sets a minimum return threshold and only\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q11: Explain volatility targeting and when it can improve risk-adjusted returns.\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain volatility targeting and when it can improve risk-adjusted returns.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Volatility Targeting:**\n",
      "\n",
      "Volatility targeting is a risk management strategy used in investing, where the goal is to maintain a consistent level of portfolio volatility, rather than focusing solely on returns. This approach involves dynamically adjusting the portfolio's asset allocation to match a target volatility level, usually expressed as a standard deviation.\n",
      "\n",
      "**How Volatility Targeting Works:**\n",
      "\n",
      "1. **Define the target volatility**: Set a specific volatility level, e.g., 8% per annum, which represents the acceptable level of risk.\n",
      "2. **Monitor and adjust**: Continuously monitor the portfolio's performance and adjust the asset allocation to maintain the target volatility level.\n",
      "3. **Risk management**: When the portfolio's volatility exceeds the target, reduce the exposure to high-risk assets and increase the exposure to low-risk assets to bring the volatility back in line.\n",
      "\n",
      "**When Volatility Targeting Can Improve Risk-Adjusted Returns:**\n",
      "\n",
      "Volatility targeting can be beneficial in the following scenarios:\n",
      "\n",
      "1. **Reducing drawdowns**: By maintaining a consistent volatility level, investors can minimize the impact of significant market downturns on their portfolio.\n",
      "2. **Improving risk-adjusted returns**: By dynamically adjusting the portfolio's asset allocation, investors can potentially capture more upside while limiting the downside risk.\n",
      "3. **Enhancing portfolio resilience**: Volatility targeting can help investors build more resilient portfolios that can withstand market shocks and maintain their long-term growth prospects.\n",
      "4. **Mitigating behavioral biases**: By taking a more systematic approach to risk management, investors can reduce the influence of behavioral biases, such as fear and greed, which can lead to suboptimal investment decisions.\n",
      "\n",
      "**Key Considerations:**\n",
      "\n",
      "While volatility targeting can be a valuable risk management tool, it's essential to consider the following:\n",
      "\n",
      "1. **Fees and costs**: The dynamic rebalancing process can result in higher fees and costs, which may offset some of the benefits.\n",
      "2\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain volatility targeting and when it can improve risk-adjusted returns.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Volatility Targeting Overview**\n",
      "\n",
      "Volatility targeting is a risk management strategy that involves setting a specific target volatility level for a portfolio and dynamically adjusting the portfolio's composition to maintain that level. The goal is to achieve a consistent level of risk, rather than trying to time market movements or predict future returns.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "1. **Volatility target**: A specific level of volatility (e.g., 10%, 15%, or 20%) that the portfolio aims to maintain.\n",
      "2. **Risk management**: Regularly rebalancing the portfolio to ensure it remains within the target volatility band.\n",
      "3. **Risk metrics**: Commonly used metrics include standard deviation, Value-at-Risk (VaR), or Conditional Value-at-Risk (CVaR).\n",
      "\n",
      "**When Volatility Targeting Can Improve Risk-Adjusted Returns:**\n",
      "\n",
      "1. **Reduced drawdowns**: By maintaining a consistent volatility level, the portfolio is less likely to experience extreme drawdowns, which can improve overall performance.\n",
      "2. **Improved risk-adjusted returns**: By targeting a specific volatility level, the portfolio can achieve higher returns while maintaining a consistent level of risk, leading to improved risk-adjusted returns.\n",
      "3. **Increased diversification**: Volatility targeting can help maintain a diversified portfolio by adjusting the allocation to different assets or sectors to maintain the target volatility level.\n",
      "4. **Reduced overconfidence**: By focusing on volatility rather than returns, the portfolio manager is less likely to overconfidence and make emotional decisions based on short-term market movements.\n",
      "\n",
      "**Common Applications:**\n",
      "\n",
      "1. **Equity portfolios**: Volatility targeting can be used to manage equity portfolios, particularly those with a high beta or a large allocation to individual stocks.\n",
      "2. **Fixed income portfolios**: Volatility targeting can be used to manage fixed income portfolios, particularly those with a high duration or a large allocation to individual bonds.\n",
      "3. **Alternative investments\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provided a clear and concise explanation of volatility targeting, including its key components and benefits. It also provided practical examples of when volatility targeting can improve risk-adjusted returns. Answer B provided a good overview of the topic, but was slightly less comprehensive and lacked specific examples.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q12: What is regime dependence? How can you test if a strategy is regime-dependent?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is regime dependence? How can you test if a strategy is regime-dependent?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Regime Dependence:**\n",
      "\n",
      "Regime dependence refers to the phenomenon where the performance of a financial strategy or model is significantly influenced by the prevailing market conditions or regime. In other words, a regime-dependent strategy performs well in one market regime but poorly in another. This can lead to inconsistent results and make it challenging to predict the strategy's performance in different market environments.\n",
      "\n",
      "**Types of Regimes:**\n",
      "\n",
      "There are several types of regimes, including:\n",
      "\n",
      "1. **Bull market regime:** A period of rising prices and high investor confidence.\n",
      "2. **Bear market regime:** A period of falling prices and low investor confidence.\n",
      "3. **Volatility regime:** A period of high or low market volatility.\n",
      "4. **Economic regime:** A period of economic expansion or contraction.\n",
      "\n",
      "**Testing for Regime Dependence:**\n",
      "\n",
      "To test if a strategy is regime-dependent, you can use the following methods:\n",
      "\n",
      "1. **Visual inspection:** Plot the strategy's performance over time and visually inspect for changes in performance during different market regimes.\n",
      "2. **Regime-switching models:** Use statistical models, such as the Markov regime-switching model, to identify changes in the strategy's performance during different market regimes.\n",
      "3. **Regime-dependent performance metrics:** Use metrics, such as the Sharpe ratio or Sortino ratio, that are sensitive to changes in market conditions and can help identify regime-dependent performance.\n",
      "4. **Backtesting:** Backtest the strategy over different market regimes to evaluate its performance and identify any regime-dependent behavior.\n",
      "5. **Out-of-sample testing:** Test the strategy's performance on out-of-sample data to evaluate its ability to generalize to new market regimes.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you have a momentum-based strategy that performs well in bull markets but poorly in bear markets. You can use a regime-switching model to identify changes in the strategy's performance during different market regimes. The model may indicate\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is regime dependence? How can you test if a strategy is regime-dependent?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Regime dependence in finance refers to the phenomenon where the performance or effectiveness of a trading strategy, investment strategy, or risk management approach changes significantly across different market conditions or regimes. A regime is a distinct market state characterized by specific patterns of price movements, volatility, and other market metrics.\n",
      "\n",
      "Regimes can be identified using various methods, such as:\n",
      "\n",
      "1. **State-space models**: These models, like the Hidden Markov Model (HMM), estimate the probability of being in a particular regime based on observed data.\n",
      "2. **Regime-switching models**: These models, like the Threshold Autoregressive (TAR) model, identify regime changes based on threshold values.\n",
      "3. **Clustering algorithms**: Techniques like k-means or hierarchical clustering group similar market conditions together.\n",
      "\n",
      "To test if a strategy is regime-dependent, you can use the following approaches:\n",
      "\n",
      "1. **Visual inspection**: Plot the strategy's performance or returns against a regime indicator (e.g., a state variable from a state-space model or a regime classification from a clustering algorithm). Look for distinct patterns or clusters.\n",
      "2. **Regime-specific performance metrics**: Calculate metrics like Sharpe ratio, drawdown, or profit factor for each regime and compare them.\n",
      "3. **Regime-switching tests**: Use statistical tests, such as the CUSUM test or the Wald test, to detect changes in the strategy's performance or parameters across regimes.\n",
      "4. **Backtesting**: Run the strategy in different regimes using historical data and evaluate its performance using metrics like Sharpe ratio or drawdown.\n",
      "5. **Out-of-sample testing**: Test the strategy's performance in new, unseen data to ensure it generalizes well across regimes.\n",
      "\n",
      "Some common regime-dependent strategies include:\n",
      "\n",
      "1. **Mean-reversion**: Strategies that exploit price deviations from a long-term mean are often more effective in trending regimes.\n",
      "2. **Momentum**: Strategies that follow price trends are\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 7,\n",
      "  \"rationale\": \"Answer A provides a clear and concise explanation of regime dependence and its testing methods, including a step-by-step approach and practical examples. The answer is well-structured and easy to understand. Answer B is also good, but it lacks a clear structure and the explanation is less detailed.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q13: Compare equal-weight vs value-weight portfolios. When does each make sense?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Compare equal-weight vs value-weight portfolios. When does each make sense?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Equal-Weight vs Value-Weight Portfolios: A Comparison**\n",
      "\n",
      "In portfolio management, two common approaches are equal-weight and value-weight portfolios. The primary difference between them lies in how the assets are allocated within the portfolio.\n",
      "\n",
      "**Equal-Weight Portfolio**\n",
      "\n",
      "In an equal-weight portfolio, each asset is allocated an equal percentage of the total portfolio, regardless of its market capitalization. For example, if a portfolio consists of 5 stocks, each stock would represent 20% of the portfolio.\n",
      "\n",
      "**Value-Weight Portfolio**\n",
      "\n",
      "In a value-weight portfolio, the assets are allocated based on their market capitalization. The larger the market capitalization of an asset, the higher its weight in the portfolio. For instance, if a portfolio consists of 5 stocks, the largest stock would represent a larger percentage of the portfolio than the smaller stocks.\n",
      "\n",
      "**Comparison of Equal-Weight and Value-Weight Portfolios**\n",
      "\n",
      "| Characteristics | Equal-Weight Portfolio | Value-Weight Portfolio |\n",
      "| --- | --- | --- |\n",
      "| Asset Allocation | Equal percentage of each asset | Assets allocated based on market capitalization |\n",
      "| Risk | Generally lower risk due to diversification | Higher risk due to concentration in larger assets |\n",
      "| Performance | May outperform value-weight portfolios in certain market conditions | May outperform equal-weight portfolios in growing markets |\n",
      "| Management | Less complex and easier to manage | More complex and requires active management |\n",
      "\n",
      "**When Each Makes Sense**\n",
      "\n",
      "1.  **Equal-Weight Portfolio:**\n",
      "    *   Suitable for investors seeking lower risk and stable returns.\n",
      "    *   Ideal for those who want to avoid concentration risk and maintain a consistent portfolio composition.\n",
      "    *   May be preferred by investors who are risk-averse or have a long-term investment horizon.\n",
      "2.  **Value-Weight Portfolio:**\n",
      "    *   Suitable for investors seeking higher returns and willing to take on more risk.\n",
      "    *   Ideal for those who want\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Compare equal-weight vs value-weight portfolios. When does each make sense?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Equal-Weight vs Value-Weight Portfolios:**\n",
      "\n",
      "1.  **Equal-Weight Portfolio:** Each stock has an equal weight in the portfolio, regardless of its market capitalization. This approach is often used in index funds or ETFs that track a specific market index, like the S&P 500.\n",
      "2.  **Value-Weight Portfolio:** Each stock's weight is proportional to its market capitalization. This is the traditional approach used in most actively managed funds and passive index funds that track a market-capitalization-weighted index.\n",
      "\n",
      "**Key differences:**\n",
      "\n",
      "*   **Risk:** Value-weight portfolios tend to be more concentrated in the largest stocks, which can increase risk due to potential market volatility and concentration risk. Equal-weight portfolios, on the other hand, tend to be more diversified and may be less sensitive to market fluctuations.\n",
      "*   **Performance:** Value-weight portfolios often outperform equal-weight portfolios in bull markets, as the largest stocks tend to drive market growth. However, in bear markets, equal-weight portfolios may perform better due to their reduced exposure to the largest, most volatile stocks.\n",
      "*   **Tax efficiency:** Equal-weight portfolios can be more tax-efficient, as the portfolio's turnover is typically lower due to the equal weighting of stocks. This can result in lower capital gains distributions and lower tax liabilities for investors.\n",
      "\n",
      "**When to use each:**\n",
      "\n",
      "*   **Equal-Weight Portfolio:**\n",
      "    *   Tax-efficient investing: Equal-weight portfolios can be a good choice for tax-sensitive investors, as they tend to have lower turnover and capital gains distributions.\n",
      "    *   Diversification: Equal-weight portfolios can provide a more diversified portfolio, which may be beneficial for investors seeking to reduce risk and increase potential returns.\n",
      "    *   Small-cap or mid-cap investing: Equal-weight portfolios can be a good choice for investing in smaller-cap or mid-cap stocks, as they provide a more balanced representation of the\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provides a clear and concise comparison of equal-weight and value-weight portfolios, highlighting their key differences and practical applications. The response is well-structured and easy to understand, making it a valuable resource for investors. Answer B, while informative, is slightly less effective in its presentation and lacks the same level of detail as Answer A.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q14: What is liquidity risk and how can it show up in backtests?\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is liquidity risk and how can it show up in backtests?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Liquidity Risk:**\n",
      "\n",
      "Liquidity risk is the potential loss or inability to sell an asset quickly enough at a fair price. It arises when there is a mismatch between the demand for and supply of an asset, leading to a shortage of buyers or a surplus of sellers. This can result in a significant decrease in the asset's price, causing losses for investors.\n",
      "\n",
      "**Types of Liquidity Risk:**\n",
      "\n",
      "1. **Market Liquidity Risk**: The inability to buy or sell an asset at a fair price due to a lack of market participants or a sudden increase in demand.\n",
      "2. **Credit Liquidity Risk**: The risk that a counterparty will default on a payment or fail to deliver an asset.\n",
      "3. **Operational Liquidity Risk**: The risk that a firm will be unable to meet its financial obligations due to a lack of cash or other liquid assets.\n",
      "\n",
      "**Liquidity Risk in Backtests:**\n",
      "\n",
      "Liquidity risk can manifest in backtests in several ways:\n",
      "\n",
      "1. **Bid-Ask Spreads**: If a backtest assumes that trades can be executed at the midpoint of the bid-ask spread, but in reality, the spread is much wider, the backtest may overestimate returns.\n",
      "2. **Trade Execution**: If a backtest assumes that trades can be executed immediately, but in reality, there is a delay or a failure to execute trades, the backtest may overestimate returns.\n",
      "3. **Price Discontinuities**: If a backtest assumes that prices are continuous, but in reality, there are price discontinuities (e.g., gaps or jumps), the backtest may not accurately capture the impact of liquidity risk.\n",
      "4. **Order Flow**: If a backtest assumes that order flow is smooth and continuous, but in reality, there are sudden changes in order flow, the backtest may not accurately capture the impact of liquidity risk.\n",
      "\n",
      "**Mitig\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is liquidity risk and how can it show up in backtests?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Liquidity risk refers to the potential for a security or market to become difficult to buy or sell at a fair price, resulting in losses or missed opportunities. In backtesting, liquidity risk can manifest in several ways:\n",
      "\n",
      "1. **Slippage**: Unrealized losses due to the difference between the expected and actual execution prices. High slippage can lead to underperformance or even losses, especially in illiquid markets.\n",
      "2. **Trade rejection**: Trades that are rejected or partially filled due to insufficient liquidity, leading to missed opportunities or reduced position sizes.\n",
      "3. **Order book dynamics**: Changes in order book depth, width, or liquidity profiles can impact trading performance, particularly in markets with changing liquidity conditions.\n",
      "4. **Market impact**: The effect of a trade on the market price, which can be significant in illiquid or thin markets.\n",
      "5. **Order flow**: The ability to execute trades without affecting the market price, which is crucial in high-frequency trading and market-making strategies.\n",
      "\n",
      "To simulate liquidity risk in backtests, you can use various techniques, such as:\n",
      "\n",
      "1. **Slippage models**: Implementing models that estimate slippage based on market conditions, such as the bid-ask spread, order book depth, or market volatility.\n",
      "2. **Trade rejection rates**: Simulating trade rejection rates based on liquidity conditions, such as the percentage of rejected trades or the average rejection rate.\n",
      "3. **Order book simulations**: Modeling order book dynamics using techniques like order book reconstruction or simulation-based approaches.\n",
      "4. **Market impact models**: Using models like the Kyle model or the Glosten model to estimate market impact.\n",
      "5. **Real-world data**: Incorporating real-world data on liquidity conditions, such as order book data or trade execution data, to simulate realistic liquidity scenarios.\n",
      "\n",
      "By incorporating liquidity risk into your backtests, you can better evaluate the performance of your trading strategies and identify potential vulnerabilities in\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"B\",\n",
      "  \"score_A\": 8,\n",
      "  \"score_B\": 9,\n",
      "  \"rationale\": \"Answer B provides a clear and concise explanation of liquidity risk and its manifestation in backtests, including specific examples and practical techniques for simulating liquidity risk. The answer is well-structured and easy to understand. Answer A is also good, but it lacks the depth and practicality of Answer B.\"\n",
      "}\n",
      "\n",
      "==========================================================================================\n",
      "Q15: Explain the difference between in-sample, validation, and out-of-sample in quant research.\n",
      "==========================================================================================\n",
      "\n",
      "--- BASE ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain the difference between in-sample, validation, and out-of-sample in quant research.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In quantitative research, particularly in finance and investing, the terms in-sample, validation, and out-of-sample are crucial for evaluating the performance and robustness of a model. Here's a clear explanation of each:\n",
      "\n",
      "1. **In-sample (IS)**: This refers to the data used to train and calibrate a model. The IS data is typically a subset of the total available data, and it's used to estimate the model's parameters, such as coefficients, weights, or other variables. The IS data is usually the largest portion of the total data, and it's used to optimize the model's performance.\n",
      "\n",
      "2. **Validation (V)**: After training the model with the IS data, the next step is to validate its performance using a separate subset of data, known as the validation set. This set is usually smaller than the IS data and is used to evaluate the model's performance on unseen data. The validation set is used to assess the model's generalizability and robustness.\n",
      "\n",
      "3. **Out-of-sample (OOS)**: This refers to the data that's not used in the training or validation process. The OOS data is typically the smallest portion of the total data and is used to evaluate the model's performance on completely new, unseen data. The OOS data is used to assess the model's ability to generalize and make predictions on data that's not part of the training or validation sets.\n",
      "\n",
      "To illustrate the difference, consider a scenario where you're developing a trading strategy using historical stock prices. You might use the following data splits:\n",
      "\n",
      "* In-sample (IS): 80% of the data (e.g., 2015-2020)\n",
      "* Validation (V): 10% of the data (e.g., 2020-2021)\n",
      "* Out-of-sample (OOS): 10% of the data (e.g., 2021-2022)\n",
      "\n",
      "--- FT ANSWER ---\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain the difference between in-sample, validation, and out-of-sample in quant research.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "In quant research, data is typically split into three subsets: in-sample (IS), validation (V), and out-of-sample (OOS). This helps evaluate model performance and generalizability:\n",
      "\n",
      "1. **In-Sample (IS)**: The largest subset, used to train and tune the model. It includes the majority of the data (e.g., 80-90%) and is used to estimate parameters, select features, and optimize hyperparameters. IS performance is often overly optimistic due to overfitting.\n",
      "2. **Validation (V)**: A smaller subset (e.g., 10-20%) used to evaluate the model's performance on unseen data during training. It helps prevent overfitting by providing an early warning of potential issues. Validation metrics are often used to select the best model or hyperparameters.\n",
      "3. **Out-of-Sample (OOS)**: The smallest subset (e.g., 1-10%), used to evaluate the model's performance on completely new, unseen data. OOS performance is a more realistic indicator of the model's ability to generalize to real-world data. It's essential to ensure the OOS performance is comparable to the IS performance to avoid overfitting.\n",
      "\n",
      "By using these subsets, researchers can:\n",
      "\n",
      "* Evaluate the model's ability to generalize to new data (OOS)\n",
      "* Assess the risk of overfitting (IS vs. V)\n",
      "* Compare the model's performance on different data subsets (IS vs. V vs. OOS)\n",
      "* Select the best model or hyperparameters based on validation metrics<|eot_id|>\n",
      "\n",
      "--- JUDGE ---\n",
      "{\n",
      "  \"winner\": \"A\" or \"B\" or \"tie\",\n",
      "  \"score_A\": 1-10,\n",
      "  \"score_B\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"A\",\n",
      "  \"score_A\": 9,\n",
      "  \"score_B\": 8,\n",
      "  \"rationale\": \"Answer A provided a clear and concise explanation of the difference between in-sample, validation, and out-of-sample in quant research, including a practical example. The explanation was accurate and well-structured, making it easy to understand. Answer B provided a good explanation, but it was slightly less clear and concise.\"\n",
      "}\n",
      "\n",
      "Evaluated 15 questions in 877.4s.\n",
      "Appended 15 entries ‚Üí total 20\n",
      "Saved to ft_vs_base_eval_results.json\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# NEW 15 QUESTIONS ONLY\n",
    "# -----------------------------\n",
    "test_questions = [\n",
    "    \"What is the difference between market impact and slippage?\",\n",
    "    \"How does return autocorrelation affect performance evaluation?\",\n",
    "    \"What is selection bias in empirical finance studies?\",\n",
    "    \"When would you use log returns instead of simple returns, and why?\",\n",
    "    \"What does overfitting look like in time-series forecasting models?\",\n",
    "    \"Explain data snooping / multiple testing in factor research. How do you control it?\",\n",
    "    \"What is walk-forward (rolling) validation and why is it preferred for time series?\",\n",
    "    \"Explain leakage in feature engineering for financial ML, with 2 concrete examples.\",\n",
    "    \"What does it mean for a strategy to be 'capacity constrained'?\",\n",
    "    \"Why can Sharpe be gamed by smoothing returns? What metrics help detect this?\",\n",
    "    \"Explain volatility targeting and when it can improve risk-adjusted returns.\",\n",
    "    \"What is regime dependence? How can you test if a strategy is regime-dependent?\",\n",
    "    \"Compare equal-weight vs value-weight portfolios. When does each make sense?\",\n",
    "    \"What is liquidity risk and how can it show up in backtests?\",\n",
    "    \"Explain the difference between in-sample, validation, and out-of-sample in quant research.\",\n",
    "]\n",
    "\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_FILE = \"eval_results_sft_ft_vs_base.json\"\n",
    "\n",
    "print(\"Loading BASE model...\")\n",
    "base_model, tokenizer = load_base_model()\n",
    "\n",
    "print(\"Loading FT model...\")\n",
    "ft_model = load_ft_model(tokenizer)\n",
    "\n",
    "results = []\n",
    "start = time.time()\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*90}\\nQ{i}: {q}\\n{'='*90}\")\n",
    "\n",
    "    base_ans = generate_answer(base_model, tokenizer, q)\n",
    "    ft_ans = generate_answer(ft_model, tokenizer, q)\n",
    "\n",
    "    print(\"\\n--- BASE ANSWER ---\")\n",
    "    print(base_ans)\n",
    "\n",
    "    print(\"\\n--- FT ANSWER ---\")\n",
    "    print(ft_ans)\n",
    "\n",
    "    judge_json = judge_with_base(base_model, tokenizer, q, base_ans, ft_ans)\n",
    "    print(\"\\n--- JUDGE ---\")\n",
    "    print(judge_json)\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"base_answer\": base_ans,\n",
    "        \"ft_answer\": ft_ans,\n",
    "        \"judge_json\": judge_json,\n",
    "    })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\nEvaluated {len(results)} questions in {elapsed:.1f}s.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Append results to existing JSON\n",
    "# -----------------------------\n",
    "if Path(OUT_FILE).exists():\n",
    "    with open(OUT_FILE, \"r\") as f:\n",
    "        existing_results = json.load(f)\n",
    "else:\n",
    "    existing_results = []\n",
    "\n",
    "existing_results.extend(results)\n",
    "\n",
    "with open(OUT_FILE, \"w\") as f:\n",
    "    json.dump(existing_results, f, indent=2)\n",
    "\n",
    "print(f\"Appended {len(results)} entries ‚Üí total {len(existing_results)}\")\n",
    "print(f\"Saved to {OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78437bdf",
   "metadata": {},
   "source": [
    "## Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e696ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: unsloth in /home/jovyan/.local/lib/python3.10/site-packages (2025.12.9)\n",
      "Requirement already satisfied: peft in /home/jovyan/.local/lib/python3.10/site-packages (0.18.0)\n",
      "Requirement already satisfied: accelerate in /home/jovyan/.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: openai in /home/jovyan/.local/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: python-dotenv in /home/jovyan/.local/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.12.7 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (2025.12.7)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (2.9.1)\n",
      "Requirement already satisfied: torchvision in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.24.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.24.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.4)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.8)\n",
      "Requirement already satisfied: tyro in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (1.0.3)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.24.4)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.0.33.post2)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.49.0)\n",
      "Requirement already satisfied: triton>=3.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (3.5.1)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (4.3.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.36.0)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (4.57.3)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth) (0.24.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.14.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jovyan/.local/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.3.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.9.5)\n",
      "Requirement already satisfied: anyio in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.10.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (2024.4.28)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/jovyan/.local/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/jovyan/.local/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth) (0.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in /home/jovyan/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.0.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/jovyan/.local/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.13.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.0.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: torchao>=0.13.0 in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.15.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.12.7->unsloth) (9.5.0)\n",
      "Requirement already satisfied: msgspec in /home/jovyan/.local/lib/python3.10/site-packages (from unsloth_zoo>=2025.12.7->unsloth) (0.20.0)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (7.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->diffusers->unsloth) (3.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.16.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/jovyan/.local/lib/python3.10/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from tyro->unsloth) (4.4.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U unsloth peft accelerate openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa3857",
   "metadata": {},
   "source": [
    "## Create preference dataset first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5639a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the difference between risk and uncertainty in investing?\",\n",
    "    \"How does inflation erode real returns over time?\",\n",
    "    \"What is the equity risk premium and why does it exist?\",\n",
    "    \"How do nominal and real interest rates differ?\",\n",
    "    \"What role do expectations play in asset pricing?\",\n",
    "    \"What is time value of money and why is it fundamental?\",\n",
    "    \"How do opportunity costs affect investment decisions?\",\n",
    "    \"What is diversification and when does it fail?\",\n",
    "    \"What does risk-adjusted return mean in practice?\",\n",
    "    \"How does leverage amplify both gains and losses?\",\n",
    "    \"What is modern portfolio theory and its key assumptions?\",\n",
    "    \"What is the efficient frontier?\",\n",
    "    \"How does correlation affect portfolio risk?\",\n",
    "    \"What is beta and how is it used?\",\n",
    "    \"When is beta a poor measure of risk?\",\n",
    "    \"What is idiosyncratic versus systematic risk?\",\n",
    "    \"How does rebalancing improve portfolio discipline?\",\n",
    "    \"What are the tradeoffs of frequent rebalancing?\",\n",
    "    \"What is downside risk and how is it measured?\",\n",
    "    \"How does drawdown differ from volatility?\",\n",
    "    \"What does the Sharpe ratio measure?\",\n",
    "    \"When can the Sharpe ratio be misleading?\",\n",
    "    \"What is the Sortino ratio and when is it preferred?\",\n",
    "    \"How does skewness affect performance metrics?\",\n",
    "    \"What is maximum drawdown and why does it matter?\",\n",
    "    \"What does return autocorrelation imply?\",\n",
    "    \"How does serial correlation distort Sharpe ratios?\",\n",
    "    \"What is backtest overfitting?\",\n",
    "    \"What is walk-forward validation?\",\n",
    "    \"Why is out-of-sample testing critical?\",\n",
    "    \"What is loss aversion?\",\n",
    "    \"How does overconfidence affect investor outcomes?\",\n",
    "    \"What is confirmation bias in investing?\",\n",
    "    \"How does herd behavior impact markets?\",\n",
    "    \"What is mental accounting?\",\n",
    "    \"Why do investors chase past performance?\",\n",
    "    \"What is anchoring in price decisions?\",\n",
    "    \"How does framing change risk perception?\",\n",
    "    \"What is the disposition effect?\",\n",
    "    \"How can behavioral biases be mitigated?\",\n",
    "    \"What is liquidity risk?\",\n",
    "    \"How does bid-ask spread affect returns?\",\n",
    "    \"What is slippage?\",\n",
    "    \"What is market impact?\",\n",
    "    \"How do limit orders differ from market orders?\",\n",
    "    \"What is price discovery?\",\n",
    "    \"How do dark pools affect markets?\",\n",
    "    \"What is high-frequency trading?\",\n",
    "    \"How does volatility clustering occur?\",\n",
    "    \"What is tail risk?\",\n",
    "    \"What distinguishes stocks from bonds?\",\n",
    "    \"How do bond prices react to interest rate changes?\",\n",
    "    \"What is duration?\",\n",
    "    \"What is credit risk?\",\n",
    "    \"How do equities hedge inflation?\",\n",
    "    \"When do bonds fail as diversifiers?\",\n",
    "    \"What is real estate‚Äôs role in a portfolio?\",\n",
    "    \"How do commodities behave during inflation?\",\n",
    "    \"What are REITs?\",\n",
    "    \"What risks are unique to private equity?\",\n",
    "    \"What is intrinsic value?\",\n",
    "    \"How does discounted cash flow work?\",\n",
    "    \"What assumptions drive DCF models?\",\n",
    "    \"What is multiple expansion?\",\n",
    "    \"Why do valuation multiples differ across sectors?\",\n",
    "    \"What is margin of safety?\",\n",
    "    \"How do growth assumptions affect valuation?\",\n",
    "    \"When are relative valuations misleading?\",\n",
    "    \"What is terminal value?\",\n",
    "    \"How do interest rates affect equity valuations?\",\n",
    "    \"What is Value at Risk?\",\n",
    "    \"What is Expected Shortfall?\",\n",
    "    \"When is Expected Shortfall preferred over VaR?\",\n",
    "    \"What is stress testing?\",\n",
    "    \"What is scenario analysis?\",\n",
    "    \"How do stop-losses help or hurt?\",\n",
    "    \"What is position sizing?\",\n",
    "    \"How do correlations change in crises?\",\n",
    "    \"What is tail hedging?\",\n",
    "    \"How does volatility targeting work?\",\n",
    "    \"What causes business cycles?\",\n",
    "    \"How do interest rate hikes affect equities?\",\n",
    "    \"What is yield curve inversion?\",\n",
    "    \"Why does the yield curve matter?\",\n",
    "    \"How does monetary policy impact asset prices?\",\n",
    "    \"What is fiscal dominance?\",\n",
    "    \"How does currency risk affect returns?\",\n",
    "    \"What is purchasing power parity?\",\n",
    "    \"How do capital flows affect markets?\",\n",
    "    \"What is stagflation?\",\n",
    "    \"What is survivorship bias?\",\n",
    "    \"What is look-ahead bias?\",\n",
    "    \"What is selection bias?\",\n",
    "    \"What is data snooping?\",\n",
    "    \"Why is multiple testing dangerous?\",\n",
    "    \"What is leakage in financial machine learning?\",\n",
    "    \"Why are financial time series hard to model?\",\n",
    "    \"What is non-stationarity?\",\n",
    "    \"What is regime dependence?\",\n",
    "    \"How do structural breaks affect models?\",\n",
    "    \"What defines value investing?\",\n",
    "    \"What defines growth investing?\",\n",
    "    \"What is momentum investing?\",\n",
    "    \"Why does momentum persist?\",\n",
    "    \"What is factor investing?\",\n",
    "    \"What are common equity factors?\",\n",
    "    \"When do factors underperform?\",\n",
    "    \"What is smart beta?\",\n",
    "    \"What is active versus passive investing?\",\n",
    "    \"Why do most active managers underperform?\",\n",
    "    \"How should emergency funds be sized?\",\n",
    "    \"What is the role of insurance in financial planning?\",\n",
    "    \"How does risk tolerance differ from risk capacity?\",\n",
    "    \"How should young investors allocate assets?\",\n",
    "    \"How does human capital affect asset allocation?\",\n",
    "    \"When should debt be paid down versus invested?\",\n",
    "    \"How does compounding benefit long-term savers?\",\n",
    "    \"What mistakes do first-time investors make?\",\n",
    "    \"How should low-income households approach investing?\",\n",
    "    \"What is the importance of fee minimization?\",\n",
    "    \"What is capacity constraint in strategies?\",\n",
    "    \"Why do some strategies fail at scale?\",\n",
    "    \"How does turnover affect net returns?\",\n",
    "    \"What is transaction cost analysis?\",\n",
    "    \"How do taxes affect investment outcomes?\",\n",
    "    \"What is tax-loss harvesting?\",\n",
    "    \"How do ETFs maintain price alignment?\",\n",
    "    \"What risks do leveraged ETFs carry?\",\n",
    "    \"How does volatility decay work?\",\n",
    "    \"Why is liquidity pro-cyclical?\",\n",
    "    \"What is ESG investing?\",\n",
    "    \"What are critiques of ESG metrics?\",\n",
    "    \"How does short-termism harm markets?\",\n",
    "    \"What is fiduciary duty?\",\n",
    "    \"How should advisors manage conflicts of interest?\",\n",
    "    \"What is financial inclusion?\",\n",
    "    \"How can investing widen inequality?\",\n",
    "    \"How can investing reduce inequality?\",\n",
    "    \"What is sustainable investing?\",\n",
    "    \"How should uncertainty be communicated to clients?\",\n",
    "    \"Why do machine learning models struggle in finance?\",\n",
    "    \"What is overfitting in trading models?\",\n",
    "    \"How does regularization help?\",\n",
    "    \"Why does cross-validation fail for time series?\",\n",
    "    \"What is feature leakage?\",\n",
    "    \"Why is explainability important in finance machine learning?\",\n",
    "    \"How does model drift occur?\",\n",
    "    \"What is concept drift?\",\n",
    "    \"How should models be monitored post-deployment?\",\n",
    "    \"When should models be retrained?\",\n",
    "    \"What drives long-term equity returns?\",\n",
    "    \"How does demographic change affect markets?\",\n",
    "    \"Why does patience matter in investing?\",\n",
    "    \"What is sequence-of-returns risk?\",\n",
    "    \"How does retirement timing affect risk?\",\n",
    "    \"What is glide-path allocation?\",\n",
    "    \"How should portfolios change with age?\",\n",
    "    \"Why is consistency more important than timing?\",\n",
    "    \"What is behavioral alpha?\",\n",
    "    \"How do expectations shape long-term outcomes?\",\n",
    "    \"Why is humility important in investing?\",\n",
    "    \"How should uncertainty be priced?\",\n",
    "    \"What distinguishes speculation from investing?\",\n",
    "    \"How do narratives influence markets?\",\n",
    "    \"Why do bubbles form?\",\n",
    "    \"What causes bubbles to burst?\",\n",
    "    \"What is reflexivity in markets?\",\n",
    "    \"How does leverage create fragility?\",\n",
    "    \"Why is simplicity powerful in finance?\",\n",
    "    \"How should investors think probabilistically?\",\n",
    "    \"What does margin of error mean in forecasts?\",\n",
    "    \"Why do forecasts fail?\",\n",
    "    \"How can investors prepare for unknown risks?\",\n",
    "    \"What is antifragility in portfolios?\",\n",
    "    \"How should investors respond to drawdowns?\",\n",
    "    \"What role does discipline play in returns?\",\n",
    "    \"How do incentives shape financial behavior?\",\n",
    "    \"Why is long-term thinking rare?\",\n",
    "    \"How should advice differ for rich versus poor households?\",\n",
    "    \"What makes a financial explanation truly helpful?\",\n",
    "    \"Why does buying a stock guarantee profits over time?\",\n",
    "    \"How can investors eliminate all risk completely?\",\n",
    "    \"Why do stocks always go up every year?\",\n",
    "    \"Is diversification useless since markets are random?\",\n",
    "    \"How does astrology improve portfolio performance?\",\n",
    "    \"Why should everyone day-trade to get rich quickly?\",\n",
    "    \"How does owning more stocks reduce total market risk?\",\n",
    "    \"Why is past performance a perfect predictor of future returns?\",\n",
    "    \"How can leverage make losses impossible?\",\n",
    "    \"Why do interest rates only affect bonds and not stocks?\",\n",
    "    \"Is inflation always bad for all investors?\",\n",
    "    \"Why should low-income families avoid investing entirely?\",\n",
    "    \"How does printing money create wealth without consequences?\",\n",
    "    \"Why are financial markets controlled by a single hidden entity?\",\n",
    "    \"How does buying at the top maximize long-term returns?\",\n",
    "    \"Why do charts work better if you believe in them?\",\n",
    "    \"How can technical indicators predict exact future prices?\",\n",
    "    \"Why does higher volatility always mean higher returns?\",\n",
    "    \"Why should investors ignore risk if returns are high?\",\n",
    "    \"How does luck replace skill in all investing outcomes?\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61e439d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] Using existing output file: /home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin/DPO_preference_data.jsonl\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "[START] cwd=/home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin\n",
      "[START] total_questions=200 already_in_file=8 out=/home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin/DPO_preference_data.jsonl\n",
      "Q1/200 ‚Äì SKIP duplicate\n",
      "Q2/200 ‚Äì SKIP duplicate\n",
      "Q3/200 ‚Äì SKIP duplicate\n",
      "Q4/200 ‚Äì SKIP duplicate\n",
      "Q5/200 ‚Äì SKIP duplicate\n",
      "Q6/200 ‚Äì SKIP duplicate\n",
      "Q7/200 ‚Äì SKIP duplicate\n",
      "Q8/200 ‚Äì SKIP duplicate\n",
      "Q9/200 ‚Äì B saved=1 skipped=8 flipped=0 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q10/200 ‚Äì A saved=2 skipped=8 flipped=0 conf=0.90 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q11/200 ‚Äì A saved=3 skipped=8 flipped=0 conf=0.90 sim=0.16 fc=keep fc_conf=0.90\n",
      "Q12/200 ‚Äì B saved=4 skipped=8 flipped=0 conf=0.90 sim=0.17 fc=keep fc_conf=0.90\n",
      "Q13/200 ‚Äì A saved=5 skipped=8 flipped=0 conf=0.90 sim=0.19\n",
      "Q14/200 ‚Äì B saved=6 skipped=8 flipped=1 conf=0.90 sim=0.23 fc=flip fc_conf=0.90\n",
      "Q15/200 ‚Äì B saved=7 skipped=8 flipped=1 conf=0.90 sim=0.24 fc=keep fc_conf=0.95\n",
      "Q16/200 ‚Äì B saved=8 skipped=8 flipped=1 conf=0.90 sim=0.23 fc=keep fc_conf=0.95\n",
      "Q17/200 ‚Äì B saved=9 skipped=8 flipped=1 conf=0.90 sim=0.07 fc=keep fc_conf=0.95\n",
      "Q18/200 ‚Äì B saved=10 skipped=8 flipped=1 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q19/200 ‚Äì B saved=11 skipped=8 flipped=1 conf=0.90 sim=0.36 fc=keep fc_conf=0.95\n",
      "Q20/200 ‚Äì B saved=12 skipped=8 flipped=1 conf=0.90 sim=0.23 fc=keep fc_conf=0.95\n",
      "Q21/200 ‚Äì B saved=13 skipped=8 flipped=2 conf=0.90 sim=0.29 fc=flip fc_conf=0.95\n",
      "Q22/200 ‚Äì B saved=14 skipped=8 flipped=2 conf=0.90 sim=0.23 fc=keep fc_conf=0.95\n",
      "Q23/200 ‚Äì B saved=15 skipped=8 flipped=2 conf=0.90 sim=0.17 fc=keep fc_conf=0.95\n",
      "Q24/200 ‚Äì B saved=16 skipped=8 flipped=2 conf=0.90 sim=0.26 fc=keep fc_conf=0.90\n",
      "Q25/200 ‚Äì B saved=17 skipped=8 flipped=2 conf=0.90 sim=0.24 fc=keep fc_conf=0.95\n",
      "Q26/200 ‚Äì SKIP factcheck action=skip conf=0.90 issues=['Chosen answer incorrectly states that high autocorrelation suggests mean-reversion; high positive autocorrelation implies momentum, not mean-reversion', 'Rejected answer contains a misleading numeric example: autocorrelation coefficient of 0.5 does not mean 50% chance of positive return next day', 'Both answers conflate or confuse implications of positive vs negative autocorrelation and overfitting risks without clear distinctions']\n",
      "Q27/200 ‚Äì B saved=18 skipped=9 flipped=2 conf=0.90 sim=0.28 fc=keep fc_conf=0.90\n",
      "Q28/200 ‚Äì B saved=19 skipped=9 flipped=2 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q29/200 ‚Äì A saved=20 skipped=9 flipped=2 conf=0.95 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q30/200 ‚Äì B saved=21 skipped=9 flipped=2 conf=0.95 sim=0.20\n",
      "Q31/200 ‚Äì B saved=22 skipped=9 flipped=2 conf=0.95 sim=0.10\n",
      "Q32/200 ‚Äì B saved=23 skipped=9 flipped=2 conf=0.90 sim=0.14 fc=keep fc_conf=0.95\n",
      "Q33/200 ‚Äì SKIP gen: truncated\n",
      "Q34/200 ‚Äì B saved=24 skipped=10 flipped=2 conf=0.90 sim=0.15\n",
      "Q35/200 ‚Äì A saved=25 skipped=10 flipped=2 conf=0.90 sim=0.16\n",
      "Q36/200 ‚Äì A saved=26 skipped=10 flipped=2 conf=0.90 sim=0.18 fc=keep fc_conf=0.90\n",
      "Q37/200 ‚Äì B saved=27 skipped=10 flipped=2 conf=0.90 sim=0.15\n",
      "Q38/200 ‚Äì B saved=28 skipped=10 flipped=2 conf=0.90 sim=0.20 fc=keep fc_conf=0.95\n",
      "Q39/200 ‚Äì B saved=29 skipped=10 flipped=2 conf=0.95 sim=0.21\n",
      "Q40/200 ‚Äì A saved=30 skipped=10 flipped=2 conf=0.90 sim=0.16\n",
      "Q41/200 ‚Äì B saved=31 skipped=10 flipped=2 conf=0.90 sim=0.18\n",
      "Q42/200 ‚Äì B saved=32 skipped=10 flipped=2 conf=0.90 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q43/200 ‚Äì B saved=33 skipped=10 flipped=2 conf=0.90 sim=0.19\n",
      "Q44/200 ‚Äì A saved=34 skipped=10 flipped=2 conf=0.90 sim=0.18\n",
      "Q45/200 ‚Äì A saved=35 skipped=10 flipped=2 conf=0.90 sim=0.30 fc=keep fc_conf=0.90\n",
      "Q46/200 ‚Äì B saved=36 skipped=10 flipped=2 conf=0.90 sim=0.23\n",
      "Q47/200 ‚Äì B saved=37 skipped=10 flipped=2 conf=0.90 sim=0.16\n",
      "Q48/200 ‚Äì A saved=38 skipped=10 flipped=2 conf=0.95 sim=0.17\n",
      "Q49/200 ‚Äì B saved=39 skipped=10 flipped=2 conf=0.90 sim=0.19\n",
      "Q50/200 ‚Äì B saved=40 skipped=10 flipped=2 conf=0.90 sim=0.17 fc=keep fc_conf=0.95\n",
      "Q51/200 ‚Äì A saved=41 skipped=10 flipped=2 conf=0.90 sim=0.18 fc=keep fc_conf=0.95\n",
      "Q52/200 ‚Äì B saved=42 skipped=10 flipped=2 conf=0.90 sim=0.14 fc=keep fc_conf=0.95\n",
      "Q53/200 ‚Äì B saved=43 skipped=10 flipped=2 conf=0.90 sim=0.32 fc=keep fc_conf=0.95\n",
      "Q54/200 ‚Äì SKIP gen: too_short\n",
      "Q55/200 ‚Äì B saved=44 skipped=11 flipped=2 conf=0.90 sim=0.18 fc=keep fc_conf=0.90\n",
      "Q56/200 ‚Äì B saved=45 skipped=11 flipped=2 conf=0.90 sim=0.13 fc=keep fc_conf=0.90\n",
      "Q57/200 ‚Äì B saved=46 skipped=11 flipped=2 conf=0.90 sim=0.29 fc=keep fc_conf=0.90\n",
      "Q58/200 ‚Äì B saved=47 skipped=11 flipped=2 conf=0.90 sim=0.23\n",
      "Q59/200 ‚Äì B saved=48 skipped=11 flipped=2 conf=0.90 sim=0.20 fc=keep fc_conf=0.95\n",
      "Q60/200 ‚Äì B saved=49 skipped=11 flipped=2 conf=0.90 sim=0.18\n",
      "Q61/200 ‚Äì A saved=50 skipped=11 flipped=2 conf=0.90 sim=0.18\n",
      "Q62/200 ‚Äì B saved=51 skipped=11 flipped=2 conf=0.90 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q63/200 ‚Äì SKIP factcheck action=skip conf=0.90 issues=[\"Chosen answer lists many assumptions as 'no changes' but some are redundant or overly broad (e.g., 'no changes in terminal value' is not a standard assumption)\", 'Rejected answer contains a critical math error in terminal value calculation (terminal value formula misapplied, resulting in incorrect numeric example)', 'Both answers oversimplify or misstate assumptions (e.g., perpetual cash flows assumption is standard but not always infinite; assumptions about constant operating margin, depreciation, CapEx, working capital are model-specific and not universal)']\n",
      "Q64/200 ‚Äì B saved=52 skipped=12 flipped=2 conf=0.90 sim=0.26 fc=keep fc_conf=0.95\n",
      "Q65/200 ‚Äì B saved=53 skipped=12 flipped=2 conf=0.90 sim=0.11 fc=keep fc_conf=0.95\n",
      "Q66/200 ‚Äì A saved=54 skipped=12 flipped=2 conf=0.90 sim=0.15 fc=keep fc_conf=0.90\n",
      "Q67/200 ‚Äì A saved=55 skipped=12 flipped=2 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q68/200 ‚Äì B saved=56 skipped=12 flipped=2 conf=0.90 sim=0.14 fc=keep fc_conf=0.95\n",
      "Q69/200 ‚Äì B saved=57 skipped=12 flipped=2 conf=0.90 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q70/200 ‚Äì A saved=58 skipped=12 flipped=2 conf=0.90 sim=0.21 fc=keep fc_conf=0.90\n",
      "Q71/200 ‚Äì A saved=59 skipped=12 flipped=2 conf=0.90 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q72/200 ‚Äì A saved=60 skipped=12 flipped=2 conf=0.90 sim=0.32 fc=keep fc_conf=0.95\n",
      "Q73/200 ‚Äì B saved=61 skipped=12 flipped=2 conf=0.95 sim=0.27 fc=keep fc_conf=0.95\n",
      "Q74/200 ‚Äì B saved=62 skipped=12 flipped=2 conf=0.90 sim=0.20 fc=keep fc_conf=0.95\n",
      "Q75/200 ‚Äì A saved=63 skipped=12 flipped=2 conf=0.90 sim=0.18\n",
      "Q76/200 ‚Äì B saved=64 skipped=12 flipped=2 conf=0.90 sim=0.10\n",
      "Q77/200 ‚Äì B saved=65 skipped=12 flipped=2 conf=0.90 sim=0.20 fc=keep fc_conf=0.95\n",
      "Q78/200 ‚Äì A saved=66 skipped=12 flipped=2 conf=0.90 sim=0.12 fc=keep fc_conf=0.95\n",
      "Q79/200 ‚Äì B saved=67 skipped=12 flipped=2 conf=0.90 sim=0.25 fc=keep fc_conf=0.90\n",
      "Q80/200 ‚Äì B saved=68 skipped=12 flipped=2 conf=0.90 sim=0.25 fc=keep fc_conf=0.90\n",
      "Q81/200 ‚Äì B saved=69 skipped=12 flipped=2 conf=0.90 sim=0.23\n",
      "Q82/200 ‚Äì A saved=70 skipped=12 flipped=2 conf=0.90 sim=0.27 fc=keep fc_conf=0.95\n",
      "Q83/200 ‚Äì B saved=71 skipped=12 flipped=2 conf=0.90 sim=0.14\n",
      "Q84/200 ‚Äì B saved=72 skipped=12 flipped=2 conf=0.90 sim=0.22 fc=keep fc_conf=0.95\n",
      "Q85/200 ‚Äì B saved=73 skipped=12 flipped=2 conf=0.90 sim=0.23\n",
      "Q86/200 ‚Äì B saved=74 skipped=12 flipped=2 conf=0.95 sim=0.14 fc=keep fc_conf=0.95\n",
      "Q87/200 ‚Äì B saved=75 skipped=12 flipped=2 conf=0.90 sim=0.12 fc=keep fc_conf=0.95\n",
      "Q88/200 ‚Äì A saved=76 skipped=12 flipped=2 conf=0.90 sim=0.22 fc=keep fc_conf=0.95\n",
      "Q89/200 ‚Äì A saved=77 skipped=12 flipped=2 conf=0.90 sim=0.22\n",
      "Q90/200 ‚Äì B saved=78 skipped=12 flipped=2 conf=0.90 sim=0.31 fc=keep fc_conf=0.90\n",
      "Q91/200 ‚Äì B saved=79 skipped=12 flipped=2 conf=0.90 sim=0.18 fc=keep fc_conf=0.95\n",
      "Q92/200 ‚Äì B saved=80 skipped=12 flipped=2 conf=0.90 sim=0.24\n",
      "Q93/200 ‚Äì B saved=81 skipped=12 flipped=2 conf=0.90 sim=0.12\n",
      "Q94/200 ‚Äì B saved=82 skipped=12 flipped=2 conf=0.95 sim=0.15\n",
      "Q95/200 ‚Äì A saved=83 skipped=12 flipped=2 conf=0.90 sim=0.13 fc=keep fc_conf=0.95\n",
      "Q96/200 ‚Äì A saved=84 skipped=12 flipped=2 conf=0.90 sim=0.25 fc=keep fc_conf=0.95\n",
      "Q97/200 ‚Äì A saved=85 skipped=12 flipped=2 conf=0.90 sim=0.17\n",
      "Q98/200 ‚Äì A saved=86 skipped=12 flipped=2 conf=0.90 sim=0.20\n",
      "Q99/200 ‚Äì B saved=87 skipped=12 flipped=2 conf=0.90 sim=0.17\n",
      "Q100/200 ‚Äì A saved=88 skipped=12 flipped=2 conf=0.90 sim=0.20\n",
      "Q101/200 ‚Äì B saved=89 skipped=12 flipped=2 conf=0.95 sim=0.16\n",
      "Q102/200 ‚Äì B saved=90 skipped=12 flipped=2 conf=0.90 sim=0.16\n",
      "Q103/200 ‚Äì A saved=91 skipped=12 flipped=3 conf=0.90 sim=0.16 fc=flip fc_conf=0.90\n",
      "Q104/200 ‚Äì A saved=92 skipped=12 flipped=3 conf=0.90 sim=0.20\n",
      "Q105/200 ‚Äì B saved=93 skipped=12 flipped=3 conf=0.90 sim=0.21\n",
      "Q106/200 ‚Äì A saved=94 skipped=12 flipped=4 conf=0.90 sim=0.22 fc=flip fc_conf=0.90\n",
      "Q107/200 ‚Äì B saved=95 skipped=12 flipped=4 conf=0.90 sim=0.18\n",
      "Q108/200 ‚Äì B saved=96 skipped=12 flipped=4 conf=0.90 sim=0.16 fc=keep fc_conf=0.95\n",
      "Q109/200 ‚Äì A saved=97 skipped=12 flipped=4 conf=0.90 sim=0.23 fc=keep fc_conf=0.95\n",
      "Q110/200 ‚Äì B saved=98 skipped=12 flipped=4 conf=0.90 sim=0.14 fc=keep fc_conf=0.90\n",
      "Q111/200 ‚Äì SKIP gen: too_short, truncated\n",
      "Q112/200 ‚Äì B saved=99 skipped=13 flipped=4 conf=0.90 sim=0.23\n",
      "Q113/200 ‚Äì B saved=100 skipped=13 flipped=4 conf=0.90 sim=0.16\n",
      "Q114/200 ‚Äì A saved=101 skipped=13 flipped=4 conf=0.90 sim=0.30 fc=keep fc_conf=0.90\n",
      "Q115/200 ‚Äì A saved=102 skipped=13 flipped=4 conf=0.90 sim=0.21 fc=keep fc_conf=0.90\n",
      "Q116/200 ‚Äì A saved=103 skipped=13 flipped=4 conf=0.90 sim=0.31 fc=keep fc_conf=0.90\n",
      "Q117/200 ‚Äì B saved=104 skipped=13 flipped=5 conf=0.90 sim=0.15 fc=flip fc_conf=0.90\n",
      "Q118/200 ‚Äì B saved=105 skipped=13 flipped=5 conf=0.90 sim=0.31 fc=keep fc_conf=0.95\n",
      "Q119/200 ‚Äì B saved=106 skipped=13 flipped=5 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q120/200 ‚Äì A saved=107 skipped=13 flipped=5 conf=0.90 sim=0.08 fc=keep fc_conf=0.95\n",
      "Q121/200 ‚Äì B saved=108 skipped=13 flipped=5 conf=0.90 sim=0.26\n",
      "Q122/200 ‚Äì A saved=109 skipped=13 flipped=5 conf=0.90 sim=0.17 fc=keep fc_conf=0.95\n",
      "Q123/200 ‚Äì A saved=110 skipped=13 flipped=5 conf=0.90 sim=0.09 fc=keep fc_conf=0.90\n",
      "Q124/200 ‚Äì B saved=111 skipped=13 flipped=5 conf=0.95 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q125/200 ‚Äì A saved=112 skipped=13 flipped=5 conf=0.90 sim=0.28 fc=keep fc_conf=0.90\n",
      "Q126/200 ‚Äì A saved=113 skipped=13 flipped=5 conf=0.95 sim=0.13\n",
      "Q127/200 ‚Äì B saved=114 skipped=13 flipped=5 conf=0.90 sim=0.20\n",
      "Q128/200 ‚Äì B saved=115 skipped=13 flipped=5 conf=0.90 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q129/200 ‚Äì A saved=116 skipped=13 flipped=5 conf=0.95 sim=0.17\n",
      "Q130/200 ‚Äì A saved=117 skipped=13 flipped=5 conf=0.95 sim=0.14\n",
      "Q131/200 ‚Äì B saved=118 skipped=13 flipped=5 conf=0.90 sim=0.18\n",
      "Q132/200 ‚Äì B saved=119 skipped=13 flipped=5 conf=0.90 sim=0.27\n",
      "Q133/200 ‚Äì B saved=120 skipped=13 flipped=5 conf=0.90 sim=0.24\n",
      "Q134/200 ‚Äì A saved=121 skipped=13 flipped=5 conf=0.90 sim=0.20\n",
      "Q135/200 ‚Äì A saved=122 skipped=13 flipped=5 conf=0.90 sim=0.18\n",
      "Q136/200 ‚Äì A saved=123 skipped=13 flipped=5 conf=0.90 sim=0.26\n",
      "Q137/200 ‚Äì A saved=124 skipped=13 flipped=5 conf=0.90 sim=0.28\n",
      "Q138/200 ‚Äì A saved=125 skipped=13 flipped=5 conf=0.90 sim=0.17\n",
      "Q139/200 ‚Äì A saved=126 skipped=13 flipped=5 conf=0.90 sim=0.16\n",
      "Q140/200 ‚Äì B saved=127 skipped=13 flipped=5 conf=0.90 sim=0.19 fc=keep fc_conf=0.95\n",
      "Q141/200 ‚Äì B saved=128 skipped=13 flipped=5 conf=0.90 sim=0.16\n",
      "Q142/200 ‚Äì B saved=129 skipped=13 flipped=5 conf=0.90 sim=0.27 fc=keep fc_conf=0.95\n",
      "Q143/200 ‚Äì B saved=130 skipped=13 flipped=5 conf=0.95 sim=0.23\n",
      "Q144/200 ‚Äì A saved=131 skipped=13 flipped=5 conf=0.90 sim=0.27\n",
      "Q145/200 ‚Äì A saved=132 skipped=13 flipped=5 conf=0.90 sim=0.27 fc=keep fc_conf=0.95\n",
      "Q146/200 ‚Äì B saved=133 skipped=13 flipped=5 conf=0.90 sim=0.22\n",
      "Q147/200 ‚Äì B saved=134 skipped=13 flipped=5 conf=0.90 sim=0.18\n",
      "Q148/200 ‚Äì B saved=135 skipped=13 flipped=5 conf=0.90 sim=0.25\n",
      "Q149/200 ‚Äì B saved=136 skipped=13 flipped=5 conf=0.90 sim=0.31\n",
      "Q150/200 ‚Äì A saved=137 skipped=13 flipped=5 conf=0.90 sim=0.16\n",
      "Q151/200 ‚Äì B saved=138 skipped=13 flipped=5 conf=0.90 sim=0.25 fc=keep fc_conf=0.95\n",
      "Q152/200 ‚Äì A saved=139 skipped=13 flipped=5 conf=0.90 sim=0.23\n",
      "Q153/200 ‚Äì A saved=140 skipped=13 flipped=5 conf=0.90 sim=0.12 fc=keep fc_conf=0.95\n",
      "Q154/200 ‚Äì A saved=141 skipped=13 flipped=6 conf=0.90 sim=0.26 fc=flip fc_conf=0.90\n",
      "Q155/200 ‚Äì A saved=142 skipped=13 flipped=6 conf=0.90 sim=0.18\n",
      "Q156/200 ‚Äì B saved=143 skipped=13 flipped=6 conf=0.95 sim=0.16 fc=keep fc_conf=0.95\n",
      "Q157/200 ‚Äì A saved=144 skipped=13 flipped=6 conf=0.90 sim=0.21 fc=keep fc_conf=0.90\n",
      "Q158/200 ‚Äì B saved=145 skipped=13 flipped=6 conf=0.90 sim=0.14\n",
      "Q159/200 ‚Äì B saved=146 skipped=13 flipped=6 conf=0.90 sim=0.19 fc=keep fc_conf=0.90\n",
      "Q160/200 ‚Äì B saved=147 skipped=13 flipped=6 conf=0.90 sim=0.11\n",
      "Q161/200 ‚Äì B saved=148 skipped=13 flipped=6 conf=0.90 sim=0.14\n",
      "Q162/200 ‚Äì A saved=149 skipped=13 flipped=6 conf=0.90 sim=0.12 fc=keep fc_conf=0.95\n",
      "Q163/200 ‚Äì B saved=150 skipped=13 flipped=6 conf=0.95 sim=0.10 fc=keep fc_conf=0.95\n",
      "Q164/200 ‚Äì B saved=151 skipped=13 flipped=6 conf=0.90 sim=0.13\n",
      "Q165/200 ‚Äì A saved=152 skipped=13 flipped=6 conf=0.90 sim=0.13\n",
      "Q166/200 ‚Äì B saved=153 skipped=13 flipped=6 conf=0.90 sim=0.10\n",
      "Q167/200 ‚Äì B saved=154 skipped=13 flipped=6 conf=0.90 sim=0.17\n",
      "Q168/200 ‚Äì A saved=155 skipped=13 flipped=6 conf=0.90 sim=0.13 fc=keep fc_conf=0.95\n",
      "Q169/200 ‚Äì B saved=156 skipped=13 flipped=6 conf=0.90 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q170/200 ‚Äì B saved=157 skipped=13 flipped=6 conf=0.90 sim=0.14 fc=keep fc_conf=0.90\n",
      "Q171/200 ‚Äì B saved=158 skipped=13 flipped=6 conf=0.90 sim=0.24 fc=keep fc_conf=0.95\n",
      "Q172/200 ‚Äì B saved=159 skipped=13 flipped=6 conf=0.90 sim=0.19\n",
      "Q173/200 ‚Äì B saved=160 skipped=13 flipped=6 conf=0.90 sim=0.20\n",
      "Q174/200 ‚Äì B saved=161 skipped=13 flipped=6 conf=0.90 sim=0.11\n",
      "Q175/200 ‚Äì B saved=162 skipped=13 flipped=6 conf=0.95 sim=0.23 fc=keep fc_conf=0.95\n",
      "Q176/200 ‚Äì B saved=163 skipped=13 flipped=6 conf=0.90 sim=0.14 fc=keep fc_conf=0.95\n",
      "Q177/200 ‚Äì A saved=164 skipped=13 flipped=6 conf=0.90 sim=0.08 fc=keep fc_conf=0.90\n",
      "Q178/200 ‚Äì A saved=165 skipped=13 flipped=6 conf=0.90 sim=0.10\n",
      "Q179/200 ‚Äì B saved=166 skipped=13 flipped=6 conf=0.90 sim=0.30 fc=keep fc_conf=0.90\n",
      "Q180/200 ‚Äì B saved=167 skipped=13 flipped=6 conf=0.90 sim=0.16 fc=keep fc_conf=0.95\n",
      "Q181/200 ‚Äì SKIP gen: too_short\n",
      "Q182/200 ‚Äì A saved=168 skipped=14 flipped=6 conf=0.90 sim=0.18 fc=keep fc_conf=0.95\n",
      "Q183/200 ‚Äì B saved=169 skipped=14 flipped=6 conf=0.90 sim=0.22 fc=keep fc_conf=0.95\n",
      "Q184/200 ‚Äì B saved=170 skipped=14 flipped=6 conf=0.90 sim=0.16 fc=keep fc_conf=0.95\n",
      "Q185/200 ‚Äì SKIP gen: too_short\n",
      "Q186/200 ‚Äì A saved=171 skipped=15 flipped=6 conf=0.90 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q187/200 ‚Äì B saved=172 skipped=15 flipped=6 conf=0.90 sim=0.16\n",
      "Q188/200 ‚Äì SKIP gen: too_short\n",
      "Q189/200 ‚Äì SKIP factcheck action=skip conf=0.90 issues=['Chosen answer lists many speculative or conditional scenarios that do not guarantee losses are impossible with leverage', 'Rejected answer incorrectly states that leverage can make losses impossible, but actually explains a typical loss scenario with leverage', 'Both answers misunderstand that leverage inherently increases risk of losses; losses cannot be made impossible by leverage alone']\n",
      "Q190/200 ‚Äì A saved=173 skipped=17 flipped=7 conf=0.90 sim=0.21 fc=flip fc_conf=0.90\n",
      "Q191/200 ‚Äì A saved=174 skipped=17 flipped=7 conf=0.90 sim=0.22 fc=keep fc_conf=0.95\n",
      "Q192/200 ‚Äì A saved=175 skipped=17 flipped=7 conf=0.90 sim=0.15 fc=keep fc_conf=0.95\n",
      "Q193/200 ‚Äì B saved=176 skipped=17 flipped=7 conf=0.90 sim=0.18\n",
      "Q194/200 ‚Äì B saved=177 skipped=17 flipped=7 conf=0.95 sim=0.21 fc=keep fc_conf=0.95\n",
      "Q195/200 ‚Äì A saved=178 skipped=17 flipped=7 conf=0.95 sim=0.20\n",
      "Q196/200 ‚Äì B saved=179 skipped=17 flipped=7 conf=0.90 sim=0.16\n",
      "Q197/200 ‚Äì A saved=180 skipped=17 flipped=7 conf=0.95 sim=0.26\n",
      "Q198/200 ‚Äì SKIP gen: too_short\n",
      "Q199/200 ‚Äì B saved=181 skipped=18 flipped=7 conf=0.90 sim=0.13 fc=keep fc_conf=0.95\n",
      "Q200/200 ‚Äì B saved=182 skipped=18 flipped=7 conf=0.90 sim=0.15 fc=keep fc_conf=0.90\n",
      "\n",
      "[DONE] saved=182 skipped=18 flipped=7 factchecked=107 out=/home/jovyan/work/MLE_in_Gen_AI-Course/class7/Homework_Kevin/DPO_preference_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -----------------------------\n",
    "# Config (single source of truth)\n",
    "# -----------------------------\n",
    "FT_ADAPTER_PATH = \"llama31-8b-finance-qlora-lora\"\n",
    "BASE_MODEL_ID = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "OUT_FILE = \"DPO_preference_data.jsonl\"   # JSONL (1 JSON per line)\n",
    "DEBUG_EVERY = 1\n",
    "\n",
    "# Primary judge gates\n",
    "SKIP_IF_JUDGE_ERROR = True\n",
    "REQUIRE_JUDGE_CONFIDENCE = True\n",
    "MIN_JUDGE_CONF = 0.70\n",
    "\n",
    "# Generation\n",
    "MAX_NEW_TOKENS = 512\n",
    "TEMPERATURE = 0.7\n",
    "TOP_P = 0.9\n",
    "GEN_ATTEMPTS = 3\n",
    "\n",
    "SYSTEM_A = \"You are a finance expert. Be concise, direct, and effective. Prefer short bullets. Avoid filler.\"\n",
    "SYSTEM_B = \"You are a finance expert. Be clear, professional, and helpful. Explain simply. Use a brief example if helpful.\"\n",
    "\n",
    "# Judge (preference)\n",
    "JUDGE_MODEL = \"gpt-4.1-mini\"\n",
    "JUDGE_CONCURRENCY = 12\n",
    "JUDGE_RETRIES = 3\n",
    "\n",
    "# Fact-check gate (targeted)\n",
    "FACTCHECK_MODEL = \"gpt-4.1-mini\"\n",
    "FACTCHECK_RETRIES = 2\n",
    "FACTCHECK_CONCURRENCY = 12\n",
    "FACTCHECK_ENABLED = True\n",
    "FACTCHECK_MIN_CONF = 0.70        # skip if fact-check confidence < this\n",
    "FACTCHECK_TRIGGER_CONF = 0.80    # only fact-check if judge_conf >= this AND risk flagged\n",
    "\n",
    "# Quality gates\n",
    "MIN_CHARS = 180\n",
    "MAX_SIMILARITY = 0.92\n",
    "REQUIRE_END_PUNCT = True\n",
    "\n",
    "# -----------------------------\n",
    "# Required: questions list\n",
    "# -----------------------------\n",
    "# If you already defined questions in another cell, do NOT reassign here.\n",
    "# questions = [...]\n",
    "\n",
    "assert isinstance(questions, list) and len(questions) > 0, \"questions must be a non-empty list[str]\"\n",
    "\n",
    "# -----------------------------\n",
    "# Output helpers (create + streaming append)\n",
    "# -----------------------------\n",
    "def ensure_outfile(path: str) -> str:\n",
    "    p = Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not p.exists():\n",
    "        p.write_text(\"\", encoding=\"utf-8\")\n",
    "        print(f\"[INIT] Created output file: {p.resolve()}\")\n",
    "    else:\n",
    "        print(f\"[INIT] Using existing output file: {p.resolve()}\")\n",
    "    return str(p)\n",
    "\n",
    "OUT_FILE = ensure_outfile(OUT_FILE)\n",
    "\n",
    "def append_jsonl(path: str, record: Dict[str, Any]) -> None:\n",
    "    line = json.dumps(record, ensure_ascii=False)\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(line + \"\\n\")\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "\n",
    "# -----------------------------\n",
    "# Load FT model once\n",
    "# -----------------------------\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_ID,\n",
    "    max_seq_length=4096,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, FT_ADAPTER_PATH)\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "def _extract_assistant(text: str) -> str:\n",
    "    marker = \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "    if marker in text:\n",
    "        text = text.split(marker, 1)[-1]\n",
    "    return text.replace(\"<|eot_id|>\", \"\").strip()\n",
    "\n",
    "def _looks_truncated(ans: str) -> bool:\n",
    "    if not ans:\n",
    "        return True\n",
    "    s = ans.strip()\n",
    "    if REQUIRE_END_PUNCT and (s[-1] not in \".!?\\\"')]}\"):\n",
    "        last_line = s.splitlines()[-1].strip()\n",
    "        if len(last_line) < 25 or (last_line[-1] not in \".!?\\\"')]}\"):\n",
    "            return True\n",
    "    bad_endings = (\" To\", \" And\", \" Or\", \" Because\", \" When\", \" Which\", \" With\", \" Such as\", \" For example\", \" e.g.\")\n",
    "    return any(s.endswith(x) for x in bad_endings)\n",
    "\n",
    "def _simple_similarity(a: str, b: str) -> float:\n",
    "    ta = set(re.findall(r\"\\w+\", a.lower()))\n",
    "    tb = set(re.findall(r\"\\w+\", b.lower()))\n",
    "    if not ta or not tb:\n",
    "        return 1.0\n",
    "    return len(ta & tb) / len(ta | tb)\n",
    "\n",
    "@torch.no_grad()\n",
    "def gen_answer(system_prompt: str, user_prompt: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(model.device)\n",
    "\n",
    "    out = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        top_p=TOP_P,\n",
    "        do_sample=True,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    return _extract_assistant(tokenizer.decode(out[0], skip_special_tokens=False))\n",
    "\n",
    "def generate_pair(question: str) -> Tuple[str, str]:\n",
    "    last_a, last_b = \"\", \"\"\n",
    "    for _ in range(GEN_ATTEMPTS):\n",
    "        a = gen_answer(SYSTEM_A, question)\n",
    "        b = gen_answer(SYSTEM_B, question)\n",
    "        last_a, last_b = a, b\n",
    "\n",
    "        if len(a) < MIN_CHARS or len(b) < MIN_CHARS:\n",
    "            continue\n",
    "        if _looks_truncated(a) or _looks_truncated(b):\n",
    "            continue\n",
    "        sim = _simple_similarity(a, b)\n",
    "        if sim >= MAX_SIMILARITY:\n",
    "            continue\n",
    "        return a, b\n",
    "\n",
    "    return last_a, last_b\n",
    "\n",
    "# -----------------------------\n",
    "# OpenAI client\n",
    "# -----------------------------\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "# -----------------------------\n",
    "# Preference judge (async) + confidence + rationale\n",
    "# -----------------------------\n",
    "JUDGE_SYSTEM = (\n",
    "    \"You are a strict finance/investing expert advisor who helps both wealthy and low-income families. \"\n",
    "    \"You prioritize factual correctness and sound reasoning over verbosity. \"\n",
    "    \"Penalize math/logic errors, hallucinated claims, and unfinished/truncated answers. \"\n",
    "    \"If both are similar, choose the one that is more correct and more actionable with fewer words.\"\n",
    ")\n",
    "\n",
    "async def judge(question: str, a: str, b: str) -> Dict[str, Any]:\n",
    "    user = f\"\"\"\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer A:\n",
    "{a}\n",
    "\n",
    "Answer B:\n",
    "{b}\n",
    "\n",
    "Choose the better answer by this rubric (in order):\n",
    "1) Factual correctness / no hallucinations\n",
    "2) Sound finance reasoning + correct caveats\n",
    "3) Practical usefulness for both rich and low-income families (actionable, risk-aware)\n",
    "4) Clarity and concision (prefer shorter if equally correct)\n",
    "\n",
    "Return ONLY strict JSON:\n",
    "{{\n",
    "  \"winner\": \"A\" or \"B\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"rationale\": \"max 1 sentence\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, JUDGE_RETRIES + 1):\n",
    "        try:\n",
    "            r = await client.chat.completions.create(\n",
    "                model=JUDGE_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": JUDGE_SYSTEM},\n",
    "                    {\"role\": \"user\", \"content\": user},\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "            raw = (r.choices[0].message.content or \"\").strip()\n",
    "\n",
    "            parsed = None\n",
    "            try:\n",
    "                parsed = json.loads(raw)\n",
    "            except Exception:\n",
    "                m = re.search(r'\\{[\\s\\S]*?\\}', raw)\n",
    "                if m:\n",
    "                    try:\n",
    "                        parsed = json.loads(m.group(0))\n",
    "                    except Exception:\n",
    "                        parsed = None\n",
    "\n",
    "            if parsed and parsed.get(\"winner\") in (\"A\", \"B\"):\n",
    "                return {\n",
    "                    \"winner\": parsed[\"winner\"],\n",
    "                    \"confidence\": parsed.get(\"confidence\", 0.0),\n",
    "                    \"rationale\": parsed.get(\"rationale\", \"\"),\n",
    "                    \"raw\": raw,\n",
    "                }\n",
    "\n",
    "            last_err = f\"Could not parse judge JSON. Raw head: {raw[:200]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "\n",
    "        await asyncio.sleep(0.5 * attempt)\n",
    "\n",
    "    return {\"winner\": \"A\", \"confidence\": 0.0, \"rationale\": \"\", \"raw\": \"\", \"error\": last_err}\n",
    "\n",
    "# -----------------------------\n",
    "# Fact-check gate (async)\n",
    "# Returns: {\"action\": \"keep\"|\"flip\"|\"skip\", \"confidence\": 0-1, \"issues\": [...], \"raw\": \"...\"}\n",
    "# -----------------------------\n",
    "FACTCHECK_SYSTEM = (\n",
    "    \"You are a meticulous finance expert and fact-checker. \"\n",
    "    \"Your job is to prevent incorrect preferred answers from entering a DPO dataset. \"\n",
    "    \"Be strict about math, definitions, causal claims, and unstable numeric claims. \"\n",
    "    \"If both answers are flawed or too speculative, choose SKIP.\"\n",
    ")\n",
    "\n",
    "def _risk_flag(question: str, a: str, b: str, judge_rationale: str) -> bool:\n",
    "    q = question.lower()\n",
    "    ra = a.lower()\n",
    "    rb = b.lower()\n",
    "    rr = (judge_rationale or \"\").lower()\n",
    "\n",
    "    # theory-heavy / easy-to-hallucinate topics\n",
    "    risky_terms = [\n",
    "        \"risk-neutral\", \"stochastic discount factor\", \"sdf\", \"state price\", \"no-arbitrage\",\n",
    "        \"capm\", \"consumption\", \"expectations hypothesis\", \"term structure\", \"duration\", \"convexity\",\n",
    "        \"var\", \"expected shortfall\", \"cvar\", \"garch\", \"newey\", \"hansen-hodrick\", \"autocorrelation\",\n",
    "        \"sharpe\", \"sortino\", \"beta\", \"alpha\", \"regression\", \"leakage\", \"overfitting\", \"backtest\"\n",
    "    ]\n",
    "    if any(t in q for t in risky_terms):\n",
    "        return True\n",
    "\n",
    "    # numbers / ranges / % (unstable claims)\n",
    "    if re.search(r\"\\b\\d+(\\.\\d+)?\\s*%|\\b\\d+(\\.\\d+)?\\s*(bp|bps)\\b\", a) or re.search(r\"\\b\\d+(\\.\\d+)?\\s*%|\\b\\d+(\\.\\d+)?\\s*(bp|bps)\\b\", b):\n",
    "        return True\n",
    "\n",
    "    # judge rationale mentions math/inaccuracy\n",
    "    if \"math\" in rr or \"incorrect\" in rr or \"inaccurate\" in rr or \"formula\" in rr:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "async def fact_check(question: str, a: str, b: str, winner: str) -> Dict[str, Any]:\n",
    "    chosen = a if winner == \"A\" else b\n",
    "    rejected = b if winner == \"A\" else a\n",
    "\n",
    "    user = f\"\"\"\n",
    "We are building DPO preference data for a finance expert assistant.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Chosen answer (currently preferred):\n",
    "{chosen}\n",
    "\n",
    "Rejected answer:\n",
    "{rejected}\n",
    "\n",
    "Task:\n",
    "1) Check the CHOSEN answer for factual correctness and sound finance reasoning.\n",
    "2) If CHOSEN is clearly better and correct, return action=\"keep\".\n",
    "3) If REJECTED is actually more correct/helpful, return action=\"flip\".\n",
    "4) If BOTH are flawed/speculative/contain math mistakes or unstable numeric claims, return action=\"skip\".\n",
    "\n",
    "Return ONLY strict JSON:\n",
    "{{\n",
    "  \"action\": \"keep\" or \"flip\" or \"skip\",\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"issues\": [\"short bullet points of concrete problems, if any (max 3)\"]\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, FACTCHECK_RETRIES + 1):\n",
    "        try:\n",
    "            r = await client.chat.completions.create(\n",
    "                model=FACTCHECK_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": FACTCHECK_SYSTEM},\n",
    "                    {\"role\": \"user\", \"content\": user},\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "            raw = (r.choices[0].message.content or \"\").strip()\n",
    "\n",
    "            parsed = None\n",
    "            try:\n",
    "                parsed = json.loads(raw)\n",
    "            except Exception:\n",
    "                m = re.search(r'\\{[\\s\\S]*?\\}', raw)\n",
    "                if m:\n",
    "                    try:\n",
    "                        parsed = json.loads(m.group(0))\n",
    "                    except Exception:\n",
    "                        parsed = None\n",
    "\n",
    "            if parsed and parsed.get(\"action\") in (\"keep\", \"flip\", \"skip\"):\n",
    "                conf = parsed.get(\"confidence\", 0.0)\n",
    "                try:\n",
    "                    conf = float(conf) if conf is not None else 0.0\n",
    "                except Exception:\n",
    "                    conf = 0.0\n",
    "                return {\n",
    "                    \"action\": parsed[\"action\"],\n",
    "                    \"confidence\": conf,\n",
    "                    \"issues\": parsed.get(\"issues\", []),\n",
    "                    \"raw\": raw,\n",
    "                }\n",
    "\n",
    "            last_err = f\"Could not parse fact-check JSON. Raw head: {raw[:200]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "\n",
    "        await asyncio.sleep(0.4 * attempt)\n",
    "\n",
    "    return {\"action\": \"skip\", \"confidence\": 0.0, \"issues\": [\"fact_check_parse_failed\"], \"raw\": \"\", \"error\": last_err}\n",
    "\n",
    "# -----------------------------\n",
    "# Main loop (sequential gen; judge/fact-check async; streaming write)\n",
    "# -----------------------------\n",
    "async def run():\n",
    "    total = len(questions)\n",
    "    saved = 0\n",
    "    skipped = 0\n",
    "    flipped = 0\n",
    "    factchecked = 0\n",
    "\n",
    "    # dedup by prompt from existing file\n",
    "    seen_prompts = set()\n",
    "    with open(OUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "                if \"prompt\" in obj:\n",
    "                    seen_prompts.add(obj[\"prompt\"])\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    print(f\"[START] cwd={Path.cwd().resolve()}\")\n",
    "    print(f\"[START] total_questions={total} already_in_file={len(seen_prompts)} out={Path(OUT_FILE).resolve()}\")\n",
    "\n",
    "    judge_sem = asyncio.Semaphore(JUDGE_CONCURRENCY)\n",
    "    fact_sem = asyncio.Semaphore(FACTCHECK_CONCURRENCY)\n",
    "\n",
    "    async def judge_with_sem(q, a, b):\n",
    "        async with judge_sem:\n",
    "            return await judge(q, a, b)\n",
    "\n",
    "    async def fact_with_sem(q, a, b, winner):\n",
    "        async with fact_sem:\n",
    "            return await fact_check(q, a, b, winner)\n",
    "\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        if q in seen_prompts:\n",
    "            skipped += 1\n",
    "            if DEBUG_EVERY:\n",
    "                print(f\"Q{i}/{total} ‚Äì SKIP duplicate\")\n",
    "            continue\n",
    "\n",
    "        # 1) Generate A/B sequentially (CUDA-safe)\n",
    "        t0 = time.time()\n",
    "        a, b = generate_pair(q)\n",
    "        sim = _simple_similarity(a, b)\n",
    "\n",
    "        reasons = []\n",
    "        if len(a) < MIN_CHARS or len(b) < MIN_CHARS:\n",
    "            reasons.append(\"too_short\")\n",
    "        if _looks_truncated(a) or _looks_truncated(b):\n",
    "            reasons.append(\"truncated\")\n",
    "        if sim >= MAX_SIMILARITY:\n",
    "            reasons.append(f\"too_similar({sim:.2f})\")\n",
    "\n",
    "        if reasons:\n",
    "            skipped += 1\n",
    "            if DEBUG_EVERY:\n",
    "                print(f\"Q{i}/{total} ‚Äì SKIP gen: {', '.join(reasons)}\")\n",
    "            continue\n",
    "\n",
    "        # 2) Judge (I/O bound)\n",
    "        j = await judge_with_sem(q, a, b)\n",
    "        winner = j.get(\"winner\", \"A\")\n",
    "        conf = j.get(\"confidence\", 0.0)\n",
    "        judge_err = j.get(\"error\", None)\n",
    "\n",
    "        if SKIP_IF_JUDGE_ERROR and judge_err:\n",
    "            skipped += 1\n",
    "            if DEBUG_EVERY:\n",
    "                print(f\"Q{i}/{total} ‚Äì SKIP judge_error: {judge_err}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            conf_val = float(conf) if conf is not None else 0.0\n",
    "        except Exception:\n",
    "            conf_val = 0.0\n",
    "\n",
    "        if REQUIRE_JUDGE_CONFIDENCE and conf_val < MIN_JUDGE_CONF:\n",
    "            skipped += 1\n",
    "            if DEBUG_EVERY:\n",
    "                print(f\"Q{i}/{total} ‚Äì SKIP low_confidence: {conf_val:.2f}\")\n",
    "            continue\n",
    "\n",
    "        # 3) Targeted fact-check (only if risk flagged)\n",
    "        fc = None\n",
    "        if FACTCHECK_ENABLED and conf_val >= FACTCHECK_TRIGGER_CONF and _risk_flag(q, a, b, j.get(\"rationale\", \"\")):\n",
    "            factchecked += 1\n",
    "            fc = await fact_with_sem(q, a, b, winner)\n",
    "            action = fc.get(\"action\", \"skip\")\n",
    "            fc_conf = float(fc.get(\"confidence\", 0.0) or 0.0)\n",
    "\n",
    "            if action == \"skip\" or fc_conf < FACTCHECK_MIN_CONF:\n",
    "                skipped += 1\n",
    "                if DEBUG_EVERY:\n",
    "                    print(f\"Q{i}/{total} ‚Äì SKIP factcheck action={action} conf={fc_conf:.2f} issues={fc.get('issues')}\")\n",
    "                continue\n",
    "\n",
    "            if action == \"flip\":\n",
    "                winner = \"B\" if winner == \"A\" else \"A\"\n",
    "                flipped += 1\n",
    "\n",
    "        chosen = a if winner == \"A\" else b\n",
    "        rejected = b if winner == \"A\" else a\n",
    "\n",
    "        record = {\n",
    "            \"prompt\": q,\n",
    "            \"chosen\": chosen,\n",
    "            \"rejected\": rejected,\n",
    "            \"meta\": {\n",
    "                \"winner\": winner,\n",
    "                \"confidence\": conf_val,\n",
    "                \"rationale\": j.get(\"rationale\", \"\"),\n",
    "                \"system_A\": SYSTEM_A,\n",
    "                \"system_B\": SYSTEM_B,\n",
    "                \"judge_model\": JUDGE_MODEL,\n",
    "                \"judge_raw\": j.get(\"raw\", \"\"),\n",
    "                \"judge_error\": judge_err,\n",
    "                \"factchecked\": bool(fc),\n",
    "                \"factcheck_action\": (fc or {}).get(\"action\", None),\n",
    "                \"factcheck_confidence\": (fc or {}).get(\"confidence\", None),\n",
    "                \"factcheck_issues\": (fc or {}).get(\"issues\", None),\n",
    "                \"factcheck_raw\": (fc or {}).get(\"raw\", None),\n",
    "                \"len_A\": len(a),\n",
    "                \"len_B\": len(b),\n",
    "                \"similarity\": sim,\n",
    "                \"gen_seconds\": round(time.time() - t0, 2),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # 4) STREAM write immediately\n",
    "        append_jsonl(OUT_FILE, record)\n",
    "        seen_prompts.add(q)\n",
    "        saved += 1\n",
    "\n",
    "        if DEBUG_EVERY:\n",
    "            extra = \"\"\n",
    "            if fc:\n",
    "                extra = f\" fc={record['meta']['factcheck_action']} fc_conf={float(record['meta']['factcheck_confidence'] or 0):.2f}\"\n",
    "            print(\n",
    "                f\"Q{i}/{total} ‚Äì {winner} saved={saved} skipped={skipped} flipped={flipped} \"\n",
    "                f\"conf={conf_val:.2f} sim={sim:.2f}{extra}\"\n",
    "            )\n",
    "\n",
    "    print(\n",
    "        f\"\\n[DONE] saved={saved} skipped={skipped} flipped={flipped} \"\n",
    "        f\"factchecked={factchecked} out={Path(OUT_FILE).resolve()}\"\n",
    "    )\n",
    "\n",
    "await run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ea820bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:00<00:00, 5435.26 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prompt in train dataset (num_proc=64): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:08<00:00, 22.74 examples/s] \n",
      "Applying chat template to train dataset (num_proc=64): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:25<00:00,  7.31 examples/s]\n",
      "Tokenizing train dataset (num_proc=64): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 190/190 [00:26<00:00,  7.25 examples/s]\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 190 | Num Epochs = 1 | Total steps = 24\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 41,943,040 of 8,072,204,288 (0.52% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 03:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>rewards / chosen</th>\n",
       "      <th>rewards / rejected</th>\n",
       "      <th>rewards / accuracies</th>\n",
       "      <th>rewards / margins</th>\n",
       "      <th>logps / chosen</th>\n",
       "      <th>logps / rejected</th>\n",
       "      <th>logits / chosen</th>\n",
       "      <th>logits / rejected</th>\n",
       "      <th>eval_logits / chosen</th>\n",
       "      <th>eval_logits / rejected</th>\n",
       "      <th>nll_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.678100</td>\n",
       "      <td>0.104784</td>\n",
       "      <td>0.067752</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.037032</td>\n",
       "      <td>-172.858185</td>\n",
       "      <td>-158.079453</td>\n",
       "      <td>-0.568802</td>\n",
       "      <td>-0.586924</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>0.268530</td>\n",
       "      <td>0.165223</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.103307</td>\n",
       "      <td>-165.902496</td>\n",
       "      <td>-158.191895</td>\n",
       "      <td>-0.564892</td>\n",
       "      <td>-0.577850</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DPO-aligned model saved to: llama31-8b-finance-dpo-lora-kevin\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ BEST full solution: Unsloth 4-bit base + your SFT LoRA + TRL DPO (uses DPOConfig)\n",
    "# - Loads your JSONL preferences: {\"prompt\",\"chosen\",\"rejected\",...}\n",
    "# - Policy = base + SFT adapter (trainable)\n",
    "# - Ref    = base + SFT adapter (frozen)\n",
    "# - Saves DPO adapter to: llama31-8b-finance-dpo-lora-kevin\n",
    "#\n",
    "# If you hit an import error for DPOConfig (older TRL), tell me your `pip show trl` version.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import PeftModel\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE_MODEL_ID      = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "SFT_ADAPTER_PATH   = \"llama31-8b-finance-qlora-lora\"\n",
    "DATA_FILE          = \"DPO_preference_data.jsonl\"   # <- make sure this is .jsonl\n",
    "OUT_DIR            = \"llama31-8b-finance-dpo-lora-kevin\"\n",
    "\n",
    "MAX_SEQ_LEN        = 4096\n",
    "MAX_LENGTH         = 2048\n",
    "MAX_PROMPT_LENGTH  = 1024\n",
    "BETA               = 0.1\n",
    "\n",
    "# Training\n",
    "PER_DEVICE_BS      = 1\n",
    "GRAD_ACCUM         = 8\n",
    "LR                 = 5e-6\n",
    "EPOCHS             = 1\n",
    "LOGGING_STEPS      = 10\n",
    "SAVE_STEPS         = 200\n",
    "WARMUP_RATIO       = 0.03\n",
    "JIT_COMPILE        = False  # set True only if you know it works in your env\n",
    "\n",
    "# -----------------------------\n",
    "# Safety checks\n",
    "# -----------------------------\n",
    "assert os.path.exists(DATA_FILE), f\"Missing data file: {DATA_FILE}\"\n",
    "assert os.path.exists(SFT_ADAPTER_PATH), f\"Missing adapter dir: {SFT_ADAPTER_PATH}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load dataset\n",
    "# -----------------------------\n",
    "dataset = load_dataset(\"json\", data_files=DATA_FILE)[\"train\"]\n",
    "required_cols = {\"prompt\", \"chosen\", \"rejected\"}\n",
    "missing = required_cols - set(dataset.column_names)\n",
    "assert not missing, f\"Dataset missing required columns: {missing}\"\n",
    "\n",
    "# (Optional) light cleanup if you accidentally stored empty lines\n",
    "dataset = dataset.filter(lambda x: isinstance(x[\"prompt\"], str) and len(x[\"prompt\"].strip()) > 0)\n",
    "\n",
    "# -----------------------------\n",
    "# Load tokenizer via Unsloth\n",
    "# -----------------------------\n",
    "_, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_ID,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# -----------------------------\n",
    "# Policy model (trainable)\n",
    "# -----------------------------\n",
    "policy, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_ID,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "policy = PeftModel.from_pretrained(policy, SFT_ADAPTER_PATH, is_trainable=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Reference model (frozen)\n",
    "# -----------------------------\n",
    "ref, _ = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_ID,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "ref = PeftModel.from_pretrained(ref, SFT_ADAPTER_PATH, is_trainable=False)\n",
    "ref.eval()\n",
    "for p in ref.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# -----------------------------\n",
    "# DPO config (TRL expects this, not TrainingArguments)\n",
    "# -----------------------------\n",
    "dpo_args = DPOConfig(\n",
    "    output_dir=OUT_DIR,\n",
    "    per_device_train_batch_size=PER_DEVICE_BS,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    save_steps=SAVE_STEPS,\n",
    "    report_to=\"none\",\n",
    "\n",
    "    # precision\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "\n",
    "    # optimizer good for 4-bit + LoRA\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "\n",
    "    # DPO-specific\n",
    "    beta=BETA,\n",
    "    max_length=MAX_LENGTH,\n",
    "    max_prompt_length=MAX_PROMPT_LENGTH,\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Trainer\n",
    "# -----------------------------\n",
    "trainer = DPOTrainer(\n",
    "    model=policy,\n",
    "    ref_model=ref,\n",
    "    args=dpo_args,\n",
    "    train_dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# (Optional) compile\n",
    "if JIT_COMPILE and hasattr(torch, \"compile\"):\n",
    "    trainer.model = torch.compile(trainer.model)\n",
    "\n",
    "# -----------------------------\n",
    "# Train + save\n",
    "# -----------------------------\n",
    "trainer.train()\n",
    "trainer.save_model(OUT_DIR)\n",
    "tokenizer.save_pretrained(OUT_DIR)\n",
    "\n",
    "print(\"‚úÖ DPO-aligned model saved to:\", OUT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ORIGINAL base (also used as judge)...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading QLoRA adapter model...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Loading DPO adapter model...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "\n",
      "====================================================================================================\n",
      "Q1: Explain look-ahead bias in backtesting and how to avoid it.\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain look-ahead bias in backtesting and how to avoid it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**What is Look-Ahead Bias in Backtesting?**\n",
      "\n",
      "Look-ahead bias, also known as data snooping or overfitting, is a common issue in backtesting that occurs when a model or strategy is optimized using data that is not available at the time of the investment decision. This means that the model is \"looking ahead\" to future data to make predictions or decisions, rather than relying on the available information at the time.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you're backtesting a trading strategy that uses a moving average crossover to buy or sell a stock. You use historical data from 2010 to 2020 to optimize the strategy, including the moving average period and the buy/sell signals. However, when you test the strategy on the same data, you're essentially \"looking ahead\" to the future buy/sell signals that were used to optimize the strategy. This is not a realistic representation of how the strategy would perform in real life.\n",
      "\n",
      "**Consequences of Look-Ahead Bias:**\n",
      "\n",
      "Look-ahead bias can lead to overly optimistic results, as the model is essentially cheating by using future data to make decisions. This can result in:\n",
      "\n",
      "1. Overfitting: The model becomes too specialized to the specific data used to optimize it, rather than generalizing to new, unseen data.\n",
      "2. Unrealistic expectations: The model's performance may not be replicable in real life, leading to disappointment and frustration.\n",
      "3. Poor decision-making: The model's reliance on future data can lead to poor investment decisions, as the model is not making decisions based on available information.\n",
      "\n",
      "**How to Avoid Look-Ahead Bias:**\n",
      "\n",
      "To avoid look-ahead bias, follow these best practices:\n",
      "\n",
      "1. **Use walk-forward optimization**: Split your data into training and testing sets, and optimize your model on the training set. Then, test the model on the testing set to evaluate its performance.\n",
      "2. **Use a\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain look-ahead bias in backtesting and how to avoid it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**What is look-ahead bias?**\n",
      "\n",
      "Look-ahead bias is a common issue in backtesting that occurs when a model uses information available after a trade has been executed to make decisions. This means the model is \"looking ahead\" to future data, which is not possible in real-world trading. Look-ahead bias can lead to overly optimistic results and poor out-of-sample performance.\n",
      "\n",
      "**Examples of look-ahead bias:**\n",
      "\n",
      "1. **Using future data to set parameters**: If a model uses future data to determine optimal parameters, such as a moving average length or a threshold, it will not generalize well to new data.\n",
      "2. **Including post-trade data in the training set**: If a model is trained on data that includes the outcome of the trade (e.g., a buy signal followed by a price increase), it will not be able to replicate the same performance in real-world trading.\n",
      "3. **Using real-time data to make decisions**: If a model uses real-time data to make decisions, it will not be able to replicate the same performance in backtesting, where data is typically available at a slower pace.\n",
      "\n",
      "**How to avoid look-ahead bias:**\n",
      "\n",
      "1. **Use only in-sample data**: Train the model on data available up to the point of the trade, and use only in-sample data to make decisions.\n",
      "2. **Use walk-forward optimization**: Train the model on a subset of the data, and then test it on a subsequent subset. This process is repeated, with the model being re-trained on the next subset after each test.\n",
      "3. **Use a fixed, pre-determined strategy**: Define a strategy based on historical data, and then test it on new data without adjusting the parameters.\n",
      "4. **Use a holdout set**: Set aside a portion of the data as a holdout set, and test the model on this set after training.\n",
      "5. **Use a rolling window**: Train the\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain look-ahead bias in backtesting and how to avoid it.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**What is look-ahead bias?**\n",
      "\n",
      "Look-ahead bias, also known as data snooping or overfitting, occurs when a backtest uses information that is not available at the time the trade is executed. This can include:\n",
      "\n",
      "1. **Future data**: Using data that is not yet available to make trading decisions.\n",
      "2. **Unrealistic assumptions**: Assuming that the model will always perform perfectly or that the market will behave in a certain way.\n",
      "3. **Overfitting**: Fitting the model too closely to the training data, making it perform well on the training set but poorly on new, unseen data.\n",
      "\n",
      "**Examples of look-ahead bias:**\n",
      "\n",
      "1. Using future prices to determine entry and exit points.\n",
      "2. Using economic indicators that are released after the fact to make trading decisions.\n",
      "3. Using a model that is optimized on a specific dataset, but then applying it to a different dataset without re-optimizing.\n",
      "\n",
      "**How to avoid look-ahead bias:**\n",
      "\n",
      "1. **Use only available data**: Only use data that is available at the time the trade is executed.\n",
      "2. **Use walk-forward optimization**: Split the data into training and testing sets, and use the training set to optimize the model, then test it on the testing set.\n",
      "3. **Use out-of-sample testing**: Test the model on data that is not used for training, to ensure that it generalizes well.\n",
      "4. **Use robust metrics**: Use metrics that are robust to overfitting, such as Sharpe ratio or Sortino ratio.\n",
      "5. **Use cross-validation**: Use techniques like k-fold cross-validation to ensure that the model is not overfitting to a specific subset of the data.\n",
      "6. **Use a holdout set**: Set aside a portion of the data as a holdout set, and test the model on this set to ensure that it generalizes well.\n",
      "7. **Use a\n",
      "\n",
      "--- JUDGE: original vs qlora (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"qlora\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9,\n",
      "  \"score_qlora\": 7,\n",
      "  \"rationale\": \"The original answer provided a clear and concise explanation of look-ahead bias, including examples and practical advice on how to avoid it. The qlora answer was more concise, but lacked examples and practical advice. The original answer demonstrated a deeper understanding of the topic.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"dpo\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9,\n",
      "  \"score_dpo\": 7,\n",
      "  \"rationale\": \"The original answer provided a clear and concise explanation of look-ahead bias, including its definition, consequences, and methods to avoid it. The answer also provided practical examples and a clear structure. The dpo answer, while good, was slightly less clear and concise.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\" or \"dpo\" or \"tie\",\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"qlora's answer provided a clear and concise explanation of look-ahead bias, including examples and practical tips to avoid it. The response was well-structured and easy to understand. dpo's answer was also good, but lacked a clear conclusion and some of the points were not as well-explained.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q2: What is survivorship bias and why does it matter in equity datasets?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is survivorship bias and why does it matter in equity datasets?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Survivorship Bias:**\n",
      "\n",
      "Survivorship bias is a statistical phenomenon where the analysis of a dataset is skewed by the inclusion of only those elements that have survived to the present, while excluding those that have failed or dropped out. This bias can lead to inaccurate conclusions and a distorted view of the data.\n",
      "\n",
      "**Equity Datasets:**\n",
      "\n",
      "In the context of equity datasets, survivorship bias occurs when only the surviving companies (those that have not gone bankrupt or been acquired) are included in the analysis, while the companies that have failed or been acquired are excluded. This can lead to a biased view of the performance of the surviving companies, as the dataset does not account for the companies that did not survive.\n",
      "\n",
      "**Why it Matters:**\n",
      "\n",
      "Survivorship bias matters in equity datasets because it can:\n",
      "\n",
      "1. **Overstate returns**: By excluding companies that have failed, the dataset may overstate the returns of the surviving companies, as the failed companies would have contributed to the overall returns.\n",
      "2. **Mislead investors**: Survivorship bias can lead investors to believe that certain investment strategies or companies are more successful than they actually are.\n",
      "3. **Distort risk assessments**: By excluding companies that have failed, the dataset may not accurately reflect the risks associated with investing in the surviving companies.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you analyze a dataset of mutual funds and find that the average annual return is 10%. However, you only include funds that are still active and exclude those that have been closed or merged. In reality, the average annual return may be lower, as the closed or merged funds would have contributed to the overall returns.\n",
      "\n",
      "**Mitigating Survivorship Bias:**\n",
      "\n",
      "To mitigate survivorship bias, it's essential to use datasets that include both surviving and failed companies. This can be achieved by:\n",
      "\n",
      "1. **Using comprehensive datasets**: Include all companies, regardless of their current status.\n",
      "2. **Using\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is survivorship bias and why does it matter in equity datasets?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Survivorship bias is a statistical phenomenon where the analysis of a dataset excludes observations that are no longer present, often because they have failed or been removed. In equity datasets, this typically occurs when a stock is delisted or merged, and the dataset only includes the surviving companies.\n",
      "\n",
      "For example, consider a study of stock performance that includes only companies listed at the end of the sample period. If a company was listed at the beginning of the sample but delisted later, its performance data will be missing, creating a biased sample. The study may conclude that companies with high performance are more likely to survive, when in fact the high performance is a result of the company's survival.\n",
      "\n",
      "Survivorship bias can lead to:\n",
      "\n",
      "1. **Overestimation of performance**: Companies that fail or are delisted may have had poor performance, which is excluded from the analysis.\n",
      "2. **Selection bias**: The sample may not be representative of the population, as only the \"winners\" are included.\n",
      "3. **Incorrect conclusions**: The analysis may attribute the success of surviving companies to their characteristics, when in fact the success is a result of their survival.\n",
      "\n",
      "To mitigate survivorship bias, researchers often use:\n",
      "\n",
      "1. **Longitudinal data**: Include all companies in the sample, even if they are delisted or merged.\n",
      "2. **Matching**: Match delisted companies with similar characteristics to those that survived.\n",
      "3. **Propensity score matching**: Match companies based on their probability of survival.\n",
      "4. **Bootstrapping**: Re-sample the dataset with replacement to account for missing observations.\n",
      "\n",
      "By acknowledging and addressing survivorship bias, researchers can ensure that their conclusions are based on a more comprehensive and representative sample.<|eot_id|>\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is survivorship bias and why does it matter in equity datasets?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Survivorship bias occurs when a dataset only includes entities that have survived to the present, excluding those that have failed or been removed. In equity datasets, this typically means that only listed companies that remain listed are included, while those that have delisted (e.g., due to bankruptcy, merger, or regulatory issues) are excluded.\n",
      "\n",
      "This bias matters for several reasons:\n",
      "\n",
      "1. **Incomplete picture**: Survivorship bias can lead to an incomplete understanding of the market, as the dataset may not accurately represent the full population of listed companies.\n",
      "2. **Selection bias**: The remaining companies may not be representative of the original population, as they may have characteristics that contributed to their survival (e.g., stronger financials, better management).\n",
      "3. **Inaccurate performance metrics**: When calculating performance metrics (e.g., returns, Sharpe ratio), the exclusion of delisted companies can lead to biased results, as the sample may not accurately reflect the true population.\n",
      "4. **Misleading conclusions**: Survivorship bias can lead to incorrect conclusions about market trends, company performance, or investment strategies.\n",
      "\n",
      "To mitigate survivorship bias, researchers and investors often use:\n",
      "\n",
      "1. **Longitudinal datasets**: Include all listed companies, even if they have delisted.\n",
      "2. **Weighted sampling**: Use weights to adjust for the exclusion of delisted companies.\n",
      "3. **Matching**: Match delisted companies with similar characteristics to the remaining companies.\n",
      "4. **Robustness checks**: Verify results using alternative datasets or methods to ensure the findings are not driven by survivorship bias.\n",
      "\n",
      "By acknowledging and addressing survivorship bias, researchers and investors can gain a more accurate understanding of the equity market and make more informed decisions.<|eot_id|>\n",
      "\n",
      "--- JUDGE: original vs qlora (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"qlora\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_original\": 7,\n",
      "  \"score_qlora\": 9,\n",
      "  \"rationale\": \"qlora's answer provided a clear and concise explanation of survivorship bias, its effects, and methods to mitigate it. The answer was well-structured and easy to understand. qlora's answer also provided a good balance of theory and practical advice.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"dpo\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"dpo\",\n",
      "  \"score_original\": 7,\n",
      "  \"score_dpo\": 9,\n",
      "  \"rationale\": \"The dpo answer provided a more comprehensive explanation of survivorship bias, including its effects on equity datasets and methods to mitigate it. The original answer was clear but lacked depth and practical examples.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\" or \"dpo\" or \"tie\",\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"qlora's answer provided a clear and concise explanation of survivorship bias, its effects, and methods to mitigate it. The answer was well-structured and provided practical advice. dpo's answer was also good, but lacked a clear conclusion and practical advice.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q3: Compare VaR and Expected Shortfall conceptually. When is ES preferred?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Compare VaR and Expected Shortfall conceptually. When is ES preferred?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Value-at-Risk (VaR) and Expected Shortfall (ES) Comparison**\n",
      "\n",
      "Both Value-at-Risk (VaR) and Expected Shortfall (ES) are risk management metrics used to quantify potential losses in a portfolio. However, they differ in their approach and application:\n",
      "\n",
      "**Value-at-Risk (VaR)**\n",
      "\n",
      "*   Defines the maximum potential loss (or gain) with a given probability (e.g., 95%) over a specific time horizon (e.g., one day).\n",
      "*   Focuses on the worst-case scenario, providing a single number that represents the maximum potential loss.\n",
      "*   Assumes that losses are normally distributed and that the probability of a loss exceeding the VaR is small.\n",
      "\n",
      "**Expected Shortfall (ES)**\n",
      "\n",
      "*   Measures the average potential loss (or gain) beyond the VaR, providing a more comprehensive view of potential losses.\n",
      "*   Takes into account the entire distribution of potential losses, not just the worst-case scenario.\n",
      "*   Provides a more accurate representation of potential losses, especially in cases where the distribution of losses is skewed or fat-tailed.\n",
      "\n",
      "**When is ES preferred?**\n",
      "\n",
      "ES is preferred in situations where:\n",
      "\n",
      "*   The distribution of potential losses is skewed or fat-tailed, such as in cases of extreme market events or natural disasters.\n",
      "*   The VaR is too conservative or too optimistic, leading to inaccurate risk assessments.\n",
      "*   A more comprehensive view of potential losses is required, beyond just the worst-case scenario.\n",
      "*   Regulatory requirements demand a more robust risk management framework, such as in the case of banks and financial institutions.\n",
      "\n",
      "In summary, while VaR provides a quick and easy-to-understand measure of potential losses, ES offers a more nuanced and accurate representation of potential losses, making it a preferred choice in situations where a more comprehensive risk management framework is required.<|eot_id|>\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Compare VaR and Expected Shortfall conceptually. When is ES preferred?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Conceptual comparison:\n",
      "\n",
      "1. **VaR (Value-at-Risk)**: VaR is a single-number risk measure that estimates the maximum potential loss (in dollars or percentage) at a given confidence level (e.g., 95%) over a specified time horizon (e.g., one day). It is often used as a benchmark to evaluate the performance of risk management strategies.\n",
      "\n",
      "2. **Expected Shortfall (ES)**: ES is a more comprehensive risk measure that calculates the average loss (in dollars or percentage) beyond the VaR threshold. It is also known as the Conditional Value-at-Risk (CVaR). ES provides a more nuanced view of risk by incorporating the severity of potential losses.\n",
      "\n",
      "Preference for ES:\n",
      "\n",
      "1. **More informative**: ES provides a better understanding of the potential losses beyond the VaR threshold, which is essential for risk management and capital allocation decisions.\n",
      "2. **Better for tail risk**: ES is more sensitive to extreme events, making it a better choice for capturing tail risk and systemic risk.\n",
      "3. **More robust**: ES is less sensitive to outliers and extreme values, which can lead to more accurate risk assessments.\n",
      "4. **Regulatory adoption**: ES is increasingly adopted by regulatory bodies, such as the Basel Committee on Banking Supervision, as a more robust risk measure.\n",
      "\n",
      "When to prefer ES:\n",
      "\n",
      "1. **Risk management**: ES is preferred for risk management decisions, such as setting capital requirements, allocating risk capital, and designing hedging strategies.\n",
      "2. **Systemic risk**: ES is more effective in capturing systemic risk and tail risk, making it a better choice for financial institutions and regulatory bodies.\n",
      "3. **Extreme events**: ES is more sensitive to extreme events, such as market crashes or liquidity crises, which can lead to more accurate risk assessments.\n",
      "4. **Comprehensive risk assessment**: ES provides a more comprehensive view of risk by incorporating the severity of potential losses\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Compare VaR and Expected Shortfall conceptually. When is ES preferred?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "**Value-at-Risk (VaR)**: VaR is a widely used risk measure that estimates the maximum potential loss (or loss in value) of a portfolio over a specific time horizon with a given confidence level (e.g., 95%). It is typically calculated as the 95th percentile of the distribution of potential losses.\n",
      "\n",
      "**Expected Shortfall (ES)**: ES, also known as Conditional Value-at-Risk (CVaR), is a risk measure that estimates the average potential loss (or loss in value) of a portfolio beyond the VaR threshold. It is calculated as the expected value of losses above the VaR level.\n",
      "\n",
      "**Key differences**:\n",
      "\n",
      "1. **Focus**: VaR focuses on the maximum potential loss, while ES focuses on the average potential loss beyond the VaR threshold.\n",
      "2. **Threshold**: VaR is typically calculated at a specific confidence level (e.g., 95%), while ES is calculated at the VaR threshold.\n",
      "3. **Risk assessment**: VaR provides a single number, while ES provides a distribution of potential losses, allowing for a more nuanced understanding of risk.\n",
      "\n",
      "**When is ES preferred?**:\n",
      "\n",
      "1. **Regulatory requirements**: ES is often required by regulatory bodies, such as the Basel Committee, as a more comprehensive risk measure.\n",
      "2. **Risk management**: ES provides a more detailed understanding of potential losses, making it a better choice for risk management and stress testing.\n",
      "3. **Tail risk**: ES is more sensitive to extreme events, making it a better choice for tail risk management.\n",
      "4. **Multi-asset portfolios**: ES is more suitable for multi-asset portfolios, as it can capture the interdependencies between assets.\n",
      "\n",
      "In summary, while VaR is a widely used risk measure, ES provides a more comprehensive understanding of potential losses, making it a preferred choice for regulatory requirements, risk management, tail risk management, and multi-\n",
      "\n",
      "--- JUDGE: original vs qlora (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"qlora\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"dpo\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"The original answer provided a clear and concise explanation of the key differences between VaR and ES, including their focus, threshold, and risk assessment. It also provided a clear explanation of when ES is preferred, including regulatory requirements, risk management, tail risk management, and multi-asset portfolios. The dpo answer was clear but lacked the depth and detail of the original.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\" or \"dpo\" or \"tie\",\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"qlora's answer provided a clear and concise comparison of VaR and ES, highlighting the key differences and when ES is preferred. The answer demonstrated a good understanding of the concepts and their practical applications. dpo's answer was also good, but lacked some detail and clarity.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q4: Why might a model have high AUC but poor calibration?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why might a model have high AUC but poor calibration?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A model with high AUC (Area Under the Curve) but poor calibration is a common issue in machine learning and predictive modeling. Here are some reasons why this might occur:\n",
      "\n",
      "1. **Overfitting**: The model may be too complex and is fitting the noise in the training data rather than the underlying patterns. As a result, it performs well on the training data but fails to generalize to new, unseen data.\n",
      "2. **Imbalanced data**: If the classes in the data are imbalanced (e.g., one class has a much larger number of instances than the other), the model may be biased towards the majority class, leading to poor calibration.\n",
      "3. **Non-linear relationships**: The relationship between the features and the target variable may be non-linear, and the model may not be able to capture these relationships accurately.\n",
      "4. **High variance**: The model may be highly variable, meaning that small changes in the data or the model's parameters can result in large changes in the predictions.\n",
      "5. **Lack of regularization**: The model may not be regularized enough, leading to overfitting and poor calibration.\n",
      "6. **Insufficient data**: The model may not have enough data to learn from, leading to poor calibration.\n",
      "7. **Model selection**: The model may not be the best choice for the problem, or the hyperparameters may not be tuned correctly.\n",
      "\n",
      "To address these issues, you can try the following:\n",
      "\n",
      "1. **Regularization**: Add regularization techniques, such as L1 or L2 regularization, dropout, or early stopping, to prevent overfitting.\n",
      "2. **Data preprocessing**: Preprocess the data to handle imbalanced classes, missing values, or outliers.\n",
      "3. **Feature engineering**: Create new features that capture non-linear relationships between the features and the target variable.\n",
      "4. **Model selection**: Try different models or ensemble methods to find the best one for the problem.\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why might a model have high AUC but poor calibration?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "High AUC (Area Under the Curve) but poor calibration in a model can occur due to:\n",
      "\n",
      "1. **Threshold effect**: A model with high AUC may still be poorly calibrated if it's not optimized for a specific decision threshold. AUC measures the model's ability to rank samples, but real-world decisions often require a specific probability or threshold.\n",
      "2. **Overfitting**: A model that's overly complex or has too many features may have high AUC on the training data but fail to generalize well to new data, leading to poor calibration.\n",
      "3. **Class imbalance**: When one class is significantly more common than the other, a model may prioritize that class, leading to poor calibration and high AUC.\n",
      "4. **Non-linear relationships**: A model that's not designed to handle non-linear relationships between features and the target variable may struggle with calibration, even if it has high AUC.\n",
      "5. **Data distribution**: A model may perform well on a specific data distribution (e.g., uniform, normal) but fail to generalize to other distributions, leading to poor calibration.\n",
      "6. **Evaluation metrics**: Using AUC as the sole evaluation metric can mask issues with calibration. Consider using additional metrics like Brier score, calibration plots, or decision threshold analysis.\n",
      "7. **Model type**: Certain model types (e.g., decision trees, random forests) are more prone to calibration issues than others (e.g., logistic regression, neural networks).\n",
      "8. **Hyperparameter tuning**: Failing to properly tune hyperparameters can lead to poor calibration, even if the model has high AUC.\n",
      "\n",
      "To address these issues, consider:\n",
      "\n",
      "* Using a calibration metric (e.g., Brier score, expected calibration error) in addition to AUC.\n",
      "* Implementing techniques like Platt scaling, isotonic regression, or temperature scaling to improve calibration.\n",
      "* Regularly monitoring and adjusting the decision threshold.\n",
      "* Using techniques\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why might a model have high AUC but poor calibration?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "High AUC (Area Under the Receiver Operating Characteristic Curve) indicates good classification performance, but poor calibration means the model's confidence is not aligned with its actual accuracy. This discrepancy can arise from:\n",
      "\n",
      "1. **Overconfidence**: The model is overly confident in its predictions, leading to a high AUC but underestimating the true probabilities of the classes.\n",
      "2. **Thresholding**: AUC is sensitive to the choice of threshold, which may not reflect the actual decision boundary. A model with a high AUC might still be poorly calibrated if the threshold is not optimal.\n",
      "3. **Class imbalance**: When one class is significantly more frequent than the others, the model may focus on that class, leading to high AUC but poor calibration for the minority classes.\n",
      "4. **Non-linear relationships**: Complex relationships between features and the target variable can lead to poor calibration, even with a high AUC.\n",
      "5. **Data distribution**: A model trained on a specific data distribution may not generalize well to new data, resulting in poor calibration.\n",
      "6. **Model complexity**: Overfitting or underfitting can lead to poor calibration, even if the AUC is high.\n",
      "7. **Evaluation metrics**: Using AUC as the sole evaluation metric can mask poor calibration. Consider using other metrics, such as Brier score, log loss, or expected calibration error.\n",
      "\n",
      "To address poor calibration, consider:\n",
      "\n",
      "1. **Post-processing**: Apply a threshold or adjust the confidence levels to match the actual accuracy.\n",
      "2. **Ensemble methods**: Combine multiple models to reduce overconfidence and improve calibration.\n",
      "3. **Regularization**: Add regularization terms to the loss function to prevent overfitting.\n",
      "4. **Data augmentation**: Increase the size and diversity of the training data to improve generalization.\n",
      "5. **Evaluation metrics**: Use a combination of metrics, including AUC, Brier score, and expected calibration error, to\n",
      "\n",
      "--- JUDGE: original vs qlora (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"qlora\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 8,\n",
      "  \"score_qlora\": 6,\n",
      "  \"rationale\": \"The original answer provides a more comprehensive explanation of the reasons why a model might have high AUC but poor calibration, including overfitting, class imbalance, and non-linear relationships. The qlora answer is more concise but lacks depth and practical advice.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"dpo\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 8,\n",
      "  \"score_dpo\": 6,\n",
      "  \"rationale\": \"The original answer provides a clear and concise explanation of the reasons why a model might have high AUC but poor calibration, including overfitting, class imbalance, and non-linear relationships. The answer also provides actionable advice on how to address these issues. The dpo answer is more concise but lacks the depth and practicality of the original.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\" or \"dpo\" or \"tie\",\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"qlora's answer provided a more comprehensive explanation of the reasons why a model might have high AUC but poor calibration, including threshold effect, overfitting, class imbalance, and non-linear relationships. The answer also provided actionable suggestions for addressing these issues. dpo's answer, while concise, was more focused on the symptoms of poor calibration and did not provide the same level of detail and practical advice.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q5: Why can a high Sharpe ratio be misleading in small samples?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why can a high Sharpe ratio be misleading in small samples?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A high Sharpe ratio can be misleading in small samples because it is sensitive to the volatility of the sample period. In small samples, the ratio of excess returns to volatility (Sharpe ratio) can be skewed by a single event or a short-term market fluctuation.\n",
      "\n",
      "There are two main reasons for this:\n",
      "\n",
      "1. **Noise**: Small samples are more susceptible to noise, which can lead to inaccurate estimates of volatility and returns. This noise can cause the Sharpe ratio to be artificially high or low, leading to incorrect conclusions.\n",
      "2. **Sampling error**: The Sharpe ratio is a sample statistic, and like all sample statistics, it is subject to sampling error. In small samples, the sampling error can be large, leading to a high Sharpe ratio that may not reflect the true underlying performance of the investment.\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "1. **Use larger samples**: If possible, use longer time periods or more data points to reduce the impact of noise and sampling error.\n",
      "2. **Consider the confidence interval**: Calculate the confidence interval for the Sharpe ratio to understand the uncertainty surrounding the estimate.\n",
      "3. **Compare to benchmarks**: Compare the Sharpe ratio to that of a benchmark or a peer group to put it into context.\n",
      "4. **Use other metrics**: Consider using other metrics, such as the Sortino ratio or the Calmar ratio, which are less sensitive to volatility and may provide a more accurate picture of investment performance.\n",
      "\n",
      "By being aware of these limitations, investors and analysts can make more informed decisions when interpreting the Sharpe ratio in small samples.<|eot_id|>\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why can a high Sharpe ratio be misleading in small samples?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A high Sharpe ratio in small samples can be misleading due to the following reasons:\n",
      "\n",
      "1. **Noise and sampling error**: Small samples are more susceptible to noise and sampling error, which can lead to overestimation of returns and underestimation of volatility. This can result in an artificially high Sharpe ratio.\n",
      "2. **Volatility clustering**: Small samples may not capture the full range of volatility, leading to an underestimation of volatility and an overestimation of the Sharpe ratio.\n",
      "3. **Non-stationarity**: Small samples may not be representative of the underlying process, and the Sharpe ratio may not be a reliable measure of risk-adjusted performance.\n",
      "4. **Overfitting**: Small samples can lead to overfitting, where the model is too closely tied to the specific data and does not generalize well to new data.\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "1. **Increase the sample size**: Larger samples provide a more robust estimate of the Sharpe ratio.\n",
      "2. **Use robust estimation methods**: Techniques like the median Sharpe ratio or the rolling Sharpe ratio can be more robust to noise and sampling error.\n",
      "3. **Consider alternative metrics**: Other metrics, such as the Sortino ratio or the Omega ratio, may be more suitable for small samples.\n",
      "4. **Use out-of-sample validation**: Validate the Sharpe ratio on a separate, unseen dataset to ensure it generalizes well.<|eot_id|>\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "You are a helpful finance and investing assistant. Be accurate, concise, and practical.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Why can a high Sharpe ratio be misleading in small samples?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "A high Sharpe ratio in small samples can be misleading due to the following reasons:\n",
      "\n",
      "1. **Volatility clustering**: Small samples tend to capture periods of high volatility, which can inflate the Sharpe ratio. This can lead to overestimation of the strategy's risk-adjusted returns.\n",
      "2. **Sampling error**: Small samples are more susceptible to sampling error, which can result in an overestimation of the true Sharpe ratio. As the sample size increases, the sampling error decreases, and the Sharpe ratio becomes more reliable.\n",
      "3. **Data mining bias**: Small samples can lead to data mining bias, where the strategy's performance is optimized to the specific data set used. This can result in an overestimation of the strategy's Sharpe ratio.\n",
      "4. **Overfitting**: Small samples can lead to overfitting, where the strategy is too closely tailored to the specific data set used, resulting in poor performance on new, unseen data.\n",
      "5. **Survivorship bias**: Small samples may not capture the full range of possible outcomes, including those that led to the strategy's elimination (e.g., due to poor performance or liquidity issues).\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "* Use larger sample sizes to reduce sampling error and increase the reliability of the Sharpe ratio.\n",
      "* Implement robustness checks, such as bootstrapping or Monte Carlo simulations, to assess the strategy's performance under different scenarios.\n",
      "* Consider using alternative risk-adjusted metrics, such as the Sortino ratio or the Omega ratio, which are less sensitive to volatility clustering.\n",
      "* Ensure that the sample is representative of the full range of possible outcomes, including those that led to the strategy's elimination.<|eot_id|>\n",
      "\n",
      "--- JUDGE: original vs qlora (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"qlora\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9,\n",
      "  \"score_qlora\": 8,\n",
      "  \"rationale\": \"The original answer provided a more comprehensive explanation of why a high Sharpe ratio can be misleading in small samples, including the concepts of noise, sampling error, and volatility clustering. The qlora answer provided a good explanation, but it was not as thorough. The original answer also provided more practical advice on how to mitigate these issues.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\" or \"dpo\" or \"tie\",\n",
      "  \"score_original\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"The original answer provided a clear and concise explanation of why a high Sharpe ratio can be misleading in small samples, including the concepts of noise, sampling error, and volatility clustering. The dpo answer provided some good points, but was less comprehensive and clear. The original answer demonstrated a deeper understanding of the topic and provided more practical advice.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo (JSON) ----------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\" or \"dpo\" or \"tie\",\n",
      "  \"score_qlora\": 1-10,\n",
      "  \"score_dpo\": 1-10,\n",
      "  \"rationale\": \"1-3 sentences\"\n",
      "}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9,\n",
      "  \"score_dpo\": 8,\n",
      "  \"rationale\": \"qlora's answer provided a more comprehensive explanation of the reasons why a high Sharpe ratio can be misleading in small samples, including noise and sampling error, volatility clustering, non-stationarity, and overfitting. The answer also provided practical suggestions for mitigating these issues. dpo's answer was clear and concise, but lacked some of the depth and practicality of qlora's response.\"\n",
      "}\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY\n",
      "Ran 5 questions with 3 pairwise judgments each (15 total judge calls) in 538.0s.\n",
      "\n",
      "Win counts (pairwise):\n",
      "  original: 0\n",
      "     qlora: 0\n",
      "       dpo: 0\n",
      "       tie: 0\n",
      "\n",
      "Average judge scores (if parsable):\n",
      "  original: n/a\n",
      "     qlora: n/a\n",
      "       dpo: n/a\n",
      "\n",
      "Saved: eval_3way_results.json\n"
     ]
    }
   ],
   "source": [
    "# Finetuning eval (3-way):\n",
    "# Compare:\n",
    "#  1) ORIGINAL base: unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\n",
    "#  2) QLoRA adapter: llama31-8b-finance-qlora-lora\n",
    "#  3) DPO LoRA adapter: llama31-8b-finance-dpo-lora-kevin\n",
    "#\n",
    "# Outputs:\n",
    "#  - per-question answers for all 3\n",
    "#  - pairwise judge results (Base-as-judge): Original vs QLoRA, Original vs DPO, QLoRA vs DPO\n",
    "#  - simple aggregate win counts + average scores\n",
    "#  - saves JSON: eval_3way_results.json\n",
    "#\n",
    "# Deps:\n",
    "# pip install -U unsloth transformers peft accelerate bitsandbytes torch\n",
    "\n",
    "import time, json\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE_MODEL_ID = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "ADAPTERS = {\n",
    "    \"qlora\": \"llama31-8b-finance-qlora-lora\",        # local folder OR HF repo id\n",
    "    \"dpo\":   \"llama31-8b-finance-dpo-lora-kevin\",    # local folder OR HF repo id\n",
    "}\n",
    "\n",
    "MAX_NEW_TOKENS = 384\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.9\n",
    "SEED = 42\n",
    "MAX_SEQ_LEN = 4096\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Test questions\n",
    "# -----------------------------\n",
    "test_questions = [\n",
    "    \"Explain look-ahead bias in backtesting and how to avoid it.\",\n",
    "    \"What is survivorship bias and why does it matter in equity datasets?\",\n",
    "    \"Compare VaR and Expected Shortfall conceptually. When is ES preferred?\",\n",
    "    \"Why might a model have high AUC but poor calibration?\",\n",
    "    \"Why can a high Sharpe ratio be misleading in small samples?\",\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def load_base_model():\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=BASE_MODEL_ID,\n",
    "        max_seq_length=MAX_SEQ_LEN,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "    return model, tokenizer\n",
    "\n",
    "def load_model_with_adapter(adapter_path: str):\n",
    "    \"\"\"\n",
    "    Load a fresh base model instance, attach a PEFT LoRA adapter, then set for inference.\n",
    "    \"\"\"\n",
    "    model, _ = FastLanguageModel.from_pretrained(\n",
    "        model_name=BASE_MODEL_ID,\n",
    "        max_seq_length=MAX_SEQ_LEN,\n",
    "        load_in_4bit=True,\n",
    "        dtype=None,\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(model, adapter_path)\n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "    return model\n",
    "\n",
    "def format_chat(tokenizer, user_text: str):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful finance and investing assistant. Be accurate, concise, and practical.\"},\n",
    "        {\"role\": \"user\", \"content\": user_text},\n",
    "    ]\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    return input_ids\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_answer(model, tokenizer, question: str):\n",
    "    input_ids = format_chat(tokenizer, question).to(model.device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=model.device)\n",
    "\n",
    "    gen = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=MAX_NEW_TOKENS,\n",
    "        temperature=TEMPERATURE,\n",
    "        do_sample=(TEMPERATURE > 0),\n",
    "        top_p=TOP_P,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(gen[0], skip_special_tokens=False)\n",
    "\n",
    "    # Best-effort extraction of assistant content\n",
    "    for marker in [\"<|assistant|>\", \"assistant\\n\", \"### Assistant:\"]:\n",
    "        if marker in text:\n",
    "            return text.split(marker, 1)[-1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def judge_pair_with_base(judge_model, tokenizer, question: str, ans_A: str, ans_B: str, label_A=\"A\", label_B=\"B\"):\n",
    "    \"\"\"\n",
    "    Base-model-as-judge. Returns a JSON string (best-effort).\n",
    "    \"\"\"\n",
    "    judge_prompt = f\"\"\"\n",
    "You are grading two answers to the same finance/investing question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer {label_A}:\n",
    "{ans_A}\n",
    "\n",
    "Answer {label_B}:\n",
    "{ans_B}\n",
    "\n",
    "Rubric (most important first):\n",
    "1) Factual correctness (no hallucinations)\n",
    "2) Finance-specific insight / domain depth\n",
    "3) Practical usefulness (how-to, pitfalls, examples)\n",
    "4) Clarity and concision\n",
    "\n",
    "Return STRICT JSON only:\n",
    "{{\n",
    "  \"winner\": \"{label_A}\" or \"{label_B}\" or \"tie\",\n",
    "  \"score_{label_A}\": 1-10,\n",
    "  \"score_{label_B}\": 1-10,\n",
    "  \"rationale\": \"1-3 sentences\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    input_ids = format_chat(tokenizer, judge_prompt).to(judge_model.device)\n",
    "    attention_mask = torch.ones_like(input_ids, device=judge_model.device)\n",
    "\n",
    "    gen = judge_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.0,\n",
    "        do_sample=False,\n",
    "        use_cache=True,\n",
    "    )\n",
    "\n",
    "    out = tokenizer.decode(gen[0], skip_special_tokens=False)\n",
    "\n",
    "    # best-effort extract JSON\n",
    "    if \"{\" in out and \"}\" in out:\n",
    "        out = out[out.find(\"{\"): out.rfind(\"}\") + 1]\n",
    "    return out.strip()\n",
    "\n",
    "def safe_parse_json(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# -----------------------------\n",
    "# Load models\n",
    "# -----------------------------\n",
    "print(\"Loading ORIGINAL base (also used as judge)...\")\n",
    "base_model, tokenizer = load_base_model()\n",
    "\n",
    "print(\"Loading QLoRA adapter model...\")\n",
    "qlora_model = load_model_with_adapter(ADAPTERS[\"qlora\"])\n",
    "\n",
    "print(\"Loading DPO adapter model...\")\n",
    "dpo_model = load_model_with_adapter(ADAPTERS[\"dpo\"])\n",
    "\n",
    "models = {\n",
    "    \"original\": base_model,\n",
    "    \"qlora\": qlora_model,\n",
    "    \"dpo\": dpo_model,\n",
    "}\n",
    "\n",
    "# -----------------------------\n",
    "# Run 3-way evaluation\n",
    "# -----------------------------\n",
    "results = []\n",
    "start = time.time()\n",
    "\n",
    "# aggregate stats\n",
    "win_counts = {\n",
    "    \"original\": 0,\n",
    "    \"qlora\": 0,\n",
    "    \"dpo\": 0,\n",
    "    \"tie\": 0,\n",
    "}\n",
    "score_sums = {\"original\": 0.0, \"qlora\": 0.0, \"dpo\": 0.0}\n",
    "score_counts = {\"original\": 0, \"qlora\": 0, \"dpo\": 0}\n",
    "\n",
    "pairings = [\n",
    "    (\"original\", \"qlora\"),\n",
    "    (\"original\", \"dpo\"),\n",
    "    (\"qlora\", \"dpo\"),\n",
    "]\n",
    "\n",
    "for i, q in enumerate(test_questions, 1):\n",
    "    print(f\"\\n{'='*100}\\nQ{i}: {q}\\n{'='*100}\")\n",
    "\n",
    "    answers = {}\n",
    "    for name, m in models.items():\n",
    "        ans = generate_answer(m, tokenizer, q)\n",
    "        answers[name] = ans\n",
    "        print(f\"\\n--- {name.upper()} ANSWER --------------------------------------------------\")\n",
    "        print(ans)\n",
    "\n",
    "    judges = {}\n",
    "    for a, b in pairings:\n",
    "        # Keep labels consistent so parsing is easy\n",
    "        judge_json = judge_pair_with_base(\n",
    "            judge_model=base_model,\n",
    "            tokenizer=tokenizer,\n",
    "            question=q,\n",
    "            ans_A=answers[a],\n",
    "            ans_B=answers[b],\n",
    "            label_A=a,\n",
    "            label_B=b,\n",
    "        )\n",
    "        judges[f\"{a}_vs_{b}\"] = judge_json\n",
    "        print(f\"\\n--- JUDGE: {a} vs {b} (JSON) ----------------------------------------------\")\n",
    "        print(judge_json)\n",
    "\n",
    "        parsed = safe_parse_json(judge_json)\n",
    "        if parsed:\n",
    "            winner = parsed.get(\"winner\", \"tie\")\n",
    "            if winner in win_counts:\n",
    "                win_counts[winner] += 1\n",
    "            else:\n",
    "                win_counts[\"tie\"] += 1\n",
    "\n",
    "            # accumulate scores if present\n",
    "            for name in [a, b]:\n",
    "                k = f\"score_{name}\"\n",
    "                if k in parsed:\n",
    "                    try:\n",
    "                        score_sums[name] += float(parsed[k])\n",
    "                        score_counts[name] += 1\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"answers\": answers,\n",
    "        \"judges\": judges,\n",
    "    })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "\n",
    "# -----------------------------\n",
    "# Summary\n",
    "# -----------------------------\n",
    "avg_scores = {}\n",
    "for name in [\"original\", \"qlora\", \"dpo\"]:\n",
    "    avg_scores[name] = (score_sums[name] / score_counts[name]) if score_counts[name] else None\n",
    "\n",
    "print(f\"\\n\\n{'='*100}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"Ran {len(test_questions)} questions with {len(pairings)} pairwise judgments each \"\n",
    "      f\"({len(test_questions)*len(pairings)} total judge calls) in {elapsed:.1f}s.\\n\")\n",
    "\n",
    "print(\"Win counts (pairwise):\")\n",
    "for k, v in win_counts.items():\n",
    "    print(f\"  {k:>8}: {v}\")\n",
    "\n",
    "print(\"\\nAverage judge scores (if parsable):\")\n",
    "for k, v in avg_scores.items():\n",
    "    print(f\"  {k:>8}: {v if v is not None else 'n/a'}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Save\n",
    "# -----------------------------\n",
    "out = {\n",
    "    \"base_model_id\": BASE_MODEL_ID,\n",
    "    \"adapters\": ADAPTERS,\n",
    "    \"gen_config\": {\n",
    "        \"max_new_tokens\": MAX_NEW_TOKENS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_p\": TOP_P,\n",
    "        \"seed\": SEED,\n",
    "        \"max_seq_len\": MAX_SEQ_LEN,\n",
    "    },\n",
    "    \"pairings\": pairings,\n",
    "    \"results\": results,\n",
    "    \"summary\": {\n",
    "        \"elapsed_sec\": elapsed,\n",
    "        \"win_counts\": win_counts,\n",
    "        \"avg_scores\": avg_scores,\n",
    "        \"score_counts\": score_counts,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"eval_results_alignment_ft_vs_base_vs_dpo.json\", \"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved: eval_results_alignment_ft_vs_base_vs_dpo.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a7556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model once...\n",
      "==((====))==  Unsloth 2025.12.9: Fast Llama patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    inference-ai GPU cuda. Num GPUs = 1. Max memory: 47.988 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Adapters available: ['default', 'dpo']\n",
      "Using qlora adapter name: default\n",
      "Using dpo adapter name: dpo\n",
      "\n",
      "====================================================================================================\n",
      "Q1: Explain look-ahead bias in backtesting and how to avoid it.\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "**What is Look-Ahead Bias in Backtesting?**\n",
      "\n",
      "Look-ahead bias, also known as data snooping or overfitting, is a common issue in backtesting that occurs when a model or strategy is optimized using data that is not available at the time of the investment decision. This means that the model is \"looking ahead\" to future data to make predictions or decisions, rather than relying on the available information at the time.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you're backtesting a trading strategy that uses a moving average crossover to buy or sell a stock. You use historical data from 2010 to 2020 to optimize the strategy, including the moving average period and the buy/sell signals. However, when you test the strategy on the same data, you're essentially \"looking ahead\" to the future buy/sell signals that were used to optimize the strategy. This is not a realistic representation of how the strategy would perform in real life.\n",
      "\n",
      "**Consequences of Look-Ahead Bias:**\n",
      "\n",
      "Look-ahead bias can lead to overly optimistic results, as the model is essentially cheating by using future data to make decisions. This can result in:\n",
      "\n",
      "1. Overfitting: The model becomes too specialized to the specific data used to optimize it, rather than generalizing to new, unseen data.\n",
      "2. Unrealistic expectations: The model's performance may not be replicable in real life, leading to disappointment and frustration.\n",
      "3. Poor decision-making: The model's reliance on future data can lead to poor investment decisions, as the model is not making decisions based on available information.\n",
      "\n",
      "**How to Avoid Look-Ahead Bias:**\n",
      "\n",
      "To avoid look-ahead bias, follow these best practices:\n",
      "\n",
      "1. **Use walk-forward optimization**: Split your data into training and testing sets, and optimize your model on the training set. Then, test the model on the testing set to evaluate its performance.\n",
      "2. **Use a\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "**What is look-ahead bias?**\n",
      "\n",
      "Look-ahead bias is a common issue in backtesting that occurs when a model uses information available after a trade has been executed to make decisions. This means the model is \"looking ahead\" to future data, which is not possible in real-world trading. Look-ahead bias can lead to overly optimistic results and poor out-of-sample performance.\n",
      "\n",
      "**Examples of look-ahead bias:**\n",
      "\n",
      "1. **Using future data to set parameters**: If a model uses future data to determine optimal parameters, such as a moving average length or a threshold, it will not generalize well to new data.\n",
      "2. **Including post-trade data in the training set**: If a model is trained on data that includes the outcome of the trade (e.g., a buy signal followed by a price increase), it will not be able to replicate the same performance in real-world trading.\n",
      "3. **Using real-time data to make decisions**: If a model uses real-time data to make decisions, it will not be able to replicate the same performance in backtesting, where data is typically available at a slower pace.\n",
      "\n",
      "**How to avoid look-ahead bias:**\n",
      "\n",
      "1. **Use only in-sample data**: Train the model on data available up to the point of the trade, and use only in-sample data to make decisions.\n",
      "2. **Use walk-forward optimization**: Train the model on a subset of the data, and then test it on a subsequent subset. This process is repeated, with the model being re-trained on the next subset after each test.\n",
      "3. **Use a fixed, pre-determined strategy**: Define a strategy based on historical data, and then test it on new data without adjusting the parameters.\n",
      "4. **Use a holdout set**: Set aside a portion of the data as a holdout set, and test the model on this set after training.\n",
      "5. **Use a rolling window**: Train the\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "**What is look-ahead bias?**\n",
      "\n",
      "Look-ahead bias, also known as data snooping or overfitting, occurs when a backtest uses information that is not available at the time the trade is executed. This can include:\n",
      "\n",
      "1. **Future data**: Using data that is not yet available to make trading decisions.\n",
      "2. **Unrealistic assumptions**: Assuming that the model will always perform perfectly or that the market will behave in a certain way.\n",
      "3. **Overfitting**: Fitting the model too closely to the training data, making it perform well on the training set but poorly on new, unseen data.\n",
      "\n",
      "**Examples of look-ahead bias:**\n",
      "\n",
      "1. Using future prices to determine entry and exit points.\n",
      "2. Using economic indicators that are released after the fact to make trading decisions.\n",
      "3. Using a model that is optimized on a specific dataset, but then applying it to a different dataset without re-optimizing.\n",
      "\n",
      "**How to avoid look-ahead bias:**\n",
      "\n",
      "1. **Use only available data**: Only use data that is available at the time the trade is executed.\n",
      "2. **Use walk-forward optimization**: Split the data into training and testing sets, and use the training set to optimize the model, then test it on the testing set.\n",
      "3. **Use out-of-sample testing**: Test the model on data that is not used for training, to ensure that it generalizes well.\n",
      "4. **Use robust metrics**: Use metrics that are robust to overfitting, such as Sharpe ratio or Sortino ratio.\n",
      "5. **Use cross-validation**: Use techniques like k-fold cross-validation to ensure that the model is not overfitting to a specific subset of the data.\n",
      "6. **Use a holdout set**: Set aside a portion of the data as a holdout set, and test the model on this set to ensure that it generalizes well.\n",
      "7. **Use a\n",
      "\n",
      "--- JUDGE: original vs qlora ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_original\": 6.0,\n",
      "  \"score_qlora\": 8.0,\n",
      "  \"rationale\": \"The original answer incorrectly conflates look-ahead bias with data snooping and overfitting, which are related but distinct issues, reducing factual correctness. The qlora answer correctly defines look-ahead bias, provides clearer examples, and offers more comprehensive and practical avoidance techniques, enhancing finance depth and usefulness.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"dpo\",\n",
      "  \"score_original\": 6.0,\n",
      "  \"score_dpo\": 8.0,\n",
      "  \"rationale\": \"The original answer correctly defines look-ahead bias and its consequences but is incomplete and somewhat inaccurate by conflating look-ahead bias with overfitting and data snooping. The dpo answer provides a clearer, more detailed explanation with practical examples and multiple concrete methods to avoid look-ahead bias, enhancing its practical usefulness and depth.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 8.0,\n",
      "  \"score_dpo\": 6.0,\n",
      "  \"rationale\": \"Qlora provides a clearer and more focused explanation of look-ahead bias with relevant examples and practical avoidance techniques, while dpo includes some inaccuracies (e.g., equating look-ahead bias with data snooping and overfitting) and less precise avoidance methods.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q2: What is survivorship bias and why does it matter in equity datasets?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "**Survivorship Bias:**\n",
      "\n",
      "Survivorship bias is a statistical phenomenon where the analysis of a dataset is skewed by the inclusion of only those elements that have survived to the present, while excluding those that have failed or dropped out. This bias can lead to inaccurate conclusions and a distorted view of the data.\n",
      "\n",
      "**Equity Datasets:**\n",
      "\n",
      "In the context of equity datasets, survivorship bias occurs when only the surviving companies (those that have not gone bankrupt or been acquired) are included in the analysis, while the companies that have failed or been acquired are excluded. This can lead to a biased view of the performance of the surviving companies, as the dataset does not account for the companies that did not survive.\n",
      "\n",
      "**Why it Matters:**\n",
      "\n",
      "Survivorship bias matters in equity datasets because it can:\n",
      "\n",
      "1. **Overstate returns**: By excluding companies that have failed, the dataset may overstate the returns of the surviving companies, as the failed companies would have contributed to the overall returns.\n",
      "2. **Mislead investors**: Survivorship bias can lead investors to believe that certain investment strategies or companies are more successful than they actually are.\n",
      "3. **Distort risk assessments**: By excluding companies that have failed, the dataset may not accurately reflect the risks associated with investing in the surviving companies.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "Suppose you analyze a dataset of mutual funds and find that the average annual return is 10%. However, you only include funds that are still active and exclude those that have been closed or merged. In reality, the average annual return may be lower, as the closed or merged funds would have contributed to the overall returns.\n",
      "\n",
      "**Mitigating Survivorship Bias:**\n",
      "\n",
      "To mitigate survivorship bias, it's essential to use datasets that include both surviving and failed companies. This can be achieved by:\n",
      "\n",
      "1. **Using comprehensive datasets**: Include all companies, regardless of their current status.\n",
      "2. **Using\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "Survivorship bias is a statistical phenomenon where the analysis of a dataset excludes observations that are no longer present, often because they have failed or been removed. In equity datasets, this typically occurs when a stock is delisted or merged, and the dataset only includes the surviving companies.\n",
      "\n",
      "For example, consider a study of stock performance that includes only companies listed at the end of the sample period. If a company was listed at the beginning of the sample but delisted later, its performance data will be missing, creating a biased sample. The study may conclude that companies with high performance are more likely to survive, when in fact the high performance is a result of the company's survival.\n",
      "\n",
      "Survivorship bias can lead to:\n",
      "\n",
      "1. **Overestimation of performance**: Companies that fail or are delisted may have had poor performance, which is excluded from the analysis.\n",
      "2. **Selection bias**: The sample may not be representative of the population, as only the \"winners\" are included.\n",
      "3. **Incorrect conclusions**: The analysis may attribute the success of surviving companies to their characteristics, when in fact the success is a result of their survival.\n",
      "\n",
      "To mitigate survivorship bias, researchers often use:\n",
      "\n",
      "1. **Longitudinal data**: Include all companies in the sample, even if they are delisted or merged.\n",
      "2. **Matching**: Match delisted companies with similar characteristics to those that survived.\n",
      "3. **Propensity score matching**: Match companies based on their probability of survival.\n",
      "4. **Bootstrapping**: Re-sample the dataset with replacement to account for missing observations.\n",
      "\n",
      "By acknowledging and addressing survivorship bias, researchers can ensure that their conclusions are based on a more comprehensive and representative sample.\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "Survivorship bias occurs when a dataset only includes entities that have survived to the present, excluding those that have failed or been removed. In equity datasets, this typically means that only listed companies that remain listed are included, while those that have delisted (e.g., due to bankruptcy, merger, or regulatory issues) are excluded.\n",
      "\n",
      "This bias matters for several reasons:\n",
      "\n",
      "1. **Incomplete picture**: Survivorship bias can lead to an incomplete understanding of the market, as the dataset may not accurately represent the full population of listed companies.\n",
      "2. **Selection bias**: The remaining companies may not be representative of the original population, as they may have characteristics that contributed to their survival (e.g., stronger financials, better management).\n",
      "3. **Inaccurate performance metrics**: When calculating performance metrics (e.g., returns, Sharpe ratio), the exclusion of delisted companies can lead to biased results, as the sample may not accurately reflect the true population.\n",
      "4. **Misleading conclusions**: Survivorship bias can lead to incorrect conclusions about market trends, company performance, or investment strategies.\n",
      "\n",
      "To mitigate survivorship bias, researchers and investors often use:\n",
      "\n",
      "1. **Longitudinal datasets**: Include all listed companies, even if they have delisted.\n",
      "2. **Weighted sampling**: Use weights to adjust for the exclusion of delisted companies.\n",
      "3. **Matching**: Match delisted companies with similar characteristics to the remaining companies.\n",
      "4. **Robustness checks**: Verify results using alternative datasets or methods to ensure the findings are not driven by survivorship bias.\n",
      "\n",
      "By acknowledging and addressing survivorship bias, researchers and investors can gain a more accurate understanding of the equity market and make more informed decisions.\n",
      "\n",
      "--- JUDGE: original vs qlora ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9.0,\n",
      "  \"score_qlora\": 7.0,\n",
      "  \"rationale\": \"The original answer provides a clearer, more practical explanation with a relevant example and actionable mitigation steps, though it is incomplete at the end. The qlora answer is factually correct and includes advanced mitigation techniques but is less clear and slightly less practical in its explanation.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"tie\",\n",
      "  \"score_original\": 9.0,\n",
      "  \"score_dpo\": 9.0,\n",
      "  \"rationale\": \"Both answers accurately define survivorship bias and explain its importance in equity datasets with practical implications. The original answer provides a clear example and mitigation steps but is cut off, while the dpo answer offers more detailed mitigation techniques and a thorough explanation of the bias's impact. Both are factually correct, deep, practical, and clear.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"tie\",\n",
      "  \"score_qlora\": 9.0,\n",
      "  \"score_dpo\": 9.0,\n",
      "  \"rationale\": \"Both answers accurately define survivorship bias and explain its importance in equity datasets with clear examples and consequences. Qlora provides more detailed mitigation techniques including propensity score matching and bootstrapping, while dpo includes weighted sampling and robustness checks, enhancing practical usefulness. Both are factually correct, sufficiently deep, and clearly presented.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q3: Compare VaR and Expected Shortfall conceptually. When is ES preferred?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "**Value-at-Risk (VaR) and Expected Shortfall (ES) Comparison**\n",
      "\n",
      "Both Value-at-Risk (VaR) and Expected Shortfall (ES) are risk management metrics used to quantify potential losses in a portfolio. However, they differ in their approach and application:\n",
      "\n",
      "**Value-at-Risk (VaR)**\n",
      "\n",
      "*   Defines the maximum potential loss (or gain) with a given probability (e.g., 95%) over a specific time horizon (e.g., one day).\n",
      "*   Focuses on the worst-case scenario, providing a single number that represents the maximum potential loss.\n",
      "*   Assumes that losses are normally distributed and that the probability of a loss exceeding the VaR is small.\n",
      "\n",
      "**Expected Shortfall (ES)**\n",
      "\n",
      "*   Measures the average potential loss (or gain) beyond the VaR, providing a more comprehensive view of potential losses.\n",
      "*   Takes into account the entire distribution of potential losses, not just the worst-case scenario.\n",
      "*   Provides a more accurate representation of potential losses, especially in cases where the distribution of losses is skewed or fat-tailed.\n",
      "\n",
      "**When is ES preferred?**\n",
      "\n",
      "ES is preferred in situations where:\n",
      "\n",
      "*   The distribution of potential losses is skewed or fat-tailed, such as in cases of extreme market events or natural disasters.\n",
      "*   The VaR is too conservative or too optimistic, leading to inaccurate risk assessments.\n",
      "*   A more comprehensive view of potential losses is required, beyond just the worst-case scenario.\n",
      "*   Regulatory requirements demand a more robust risk management framework, such as in the case of banks and financial institutions.\n",
      "\n",
      "In summary, while VaR provides a quick and easy-to-understand measure of potential losses, ES offers a more nuanced and accurate representation of potential losses, making it a preferred choice in situations where a more comprehensive risk management framework is required.\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "Conceptual comparison:\n",
      "\n",
      "1. **VaR (Value-at-Risk)**: VaR is a single-number risk measure that estimates the maximum potential loss (in dollars or percentage) at a given confidence level (e.g., 95%) over a specified time horizon (e.g., one day). It is often used as a benchmark to evaluate the performance of risk management strategies.\n",
      "\n",
      "2. **Expected Shortfall (ES)**: ES is a more comprehensive risk measure that calculates the average loss (in dollars or percentage) beyond the VaR threshold. It is also known as the Conditional Value-at-Risk (CVaR). ES provides a more nuanced view of risk by incorporating the severity of potential losses.\n",
      "\n",
      "Preference for ES:\n",
      "\n",
      "1. **More informative**: ES provides a better understanding of the potential losses beyond the VaR threshold, which is essential for risk management and capital allocation decisions.\n",
      "2. **Better for tail risk**: ES is more sensitive to extreme events, making it a better choice for capturing tail risk and systemic risk.\n",
      "3. **More robust**: ES is less sensitive to outliers and extreme values, which can lead to more accurate risk assessments.\n",
      "4. **Regulatory adoption**: ES is increasingly adopted by regulatory bodies, such as the Basel Committee on Banking Supervision, as a more robust risk measure.\n",
      "\n",
      "When to prefer ES:\n",
      "\n",
      "1. **Risk management**: ES is preferred for risk management decisions, such as setting capital requirements, allocating risk capital, and designing hedging strategies.\n",
      "2. **Systemic risk**: ES is more effective in capturing systemic risk and tail risk, making it a better choice for financial institutions and regulatory bodies.\n",
      "3. **Extreme events**: ES is more sensitive to extreme events, such as market crashes or liquidity crises, which can lead to more accurate risk assessments.\n",
      "4. **Comprehensive risk assessment**: ES provides a more comprehensive view of risk by incorporating the severity of potential losses\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "**Value-at-Risk (VaR)**: VaR is a widely used risk measure that estimates the maximum potential loss (or loss in value) of a portfolio over a specific time horizon with a given confidence level (e.g., 95%). It is typically calculated as the 95th percentile of the distribution of potential losses.\n",
      "\n",
      "**Expected Shortfall (ES)**: ES, also known as Conditional Value-at-Risk (CVaR), is a risk measure that estimates the average potential loss (or loss in value) of a portfolio beyond the VaR threshold. It is calculated as the expected value of losses above the VaR level.\n",
      "\n",
      "**Key differences**:\n",
      "\n",
      "1. **Focus**: VaR focuses on the maximum potential loss, while ES focuses on the average potential loss beyond the VaR threshold.\n",
      "2. **Threshold**: VaR is typically calculated at a specific confidence level (e.g., 95%), while ES is calculated at the VaR threshold.\n",
      "3. **Risk assessment**: VaR provides a single number, while ES provides a distribution of potential losses, allowing for a more nuanced understanding of risk.\n",
      "\n",
      "**When is ES preferred?**:\n",
      "\n",
      "1. **Regulatory requirements**: ES is often required by regulatory bodies, such as the Basel Committee, as a more comprehensive risk measure.\n",
      "2. **Risk management**: ES provides a more detailed understanding of potential losses, making it a better choice for risk management and stress testing.\n",
      "3. **Tail risk**: ES is more sensitive to extreme events, making it a better choice for tail risk management.\n",
      "4. **Multi-asset portfolios**: ES is more suitable for multi-asset portfolios, as it can capture the interdependencies between assets.\n",
      "\n",
      "In summary, while VaR is a widely used risk measure, ES provides a more comprehensive understanding of potential losses, making it a preferred choice for regulatory requirements, risk management, tail risk management, and multi-\n",
      "\n",
      "--- JUDGE: original vs qlora ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_original\": 7.0,\n",
      "  \"score_qlora\": 9.0,\n",
      "  \"rationale\": \"Both answers correctly explain VaR and ES conceptually, but qlora provides clearer definitions, explicitly mentions ES as CVaR, and better details when ES is preferred, including regulatory context and practical applications. The original answer is accurate but less precise and somewhat vague on assumptions and practical implications.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"dpo\",\n",
      "  \"score_original\": 7.0,\n",
      "  \"score_dpo\": 9.0,\n",
      "  \"rationale\": \"The dpo answer is more precise and technically accurate, correctly defining VaR and ES, including the concept of ES as CVaR, and highlighting regulatory context and tail risk sensitivity. The original answer is generally correct but contains inaccuracies (e.g., VaR assumes normality, which is not a requirement) and is less clear on key conceptual distinctions.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9.0,\n",
      "  \"score_dpo\": 7.0,\n",
      "  \"rationale\": \"Qlora's answer is more detailed, clearly explains the conceptual differences, and provides a thorough and practical explanation of when ES is preferred, including regulatory context and risk management applications. Dpo's answer is accurate but less comprehensive and slightly less clear, with a minor inaccuracy in describing ES as providing a distribution rather than an average loss beyond VaR.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q4: Why might a model have high AUC but poor calibration?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "A model with high AUC (Area Under the Curve) but poor calibration is a common issue in machine learning and predictive modeling. Here are some reasons why this might occur:\n",
      "\n",
      "1. **Overfitting**: The model may be too complex and is fitting the noise in the training data rather than the underlying patterns. As a result, it performs well on the training data but fails to generalize to new, unseen data.\n",
      "2. **Imbalanced data**: If the classes in the data are imbalanced (e.g., one class has a much larger number of instances than the other), the model may be biased towards the majority class, leading to poor calibration.\n",
      "3. **Non-linear relationships**: The relationship between the features and the target variable may be non-linear, and the model may not be able to capture these relationships accurately.\n",
      "4. **High variance**: The model may be highly variable, meaning that small changes in the data or the model's parameters can result in large changes in the predictions.\n",
      "5. **Lack of regularization**: The model may not be regularized enough, leading to overfitting and poor calibration.\n",
      "6. **Insufficient data**: The model may not have enough data to learn from, leading to poor calibration.\n",
      "7. **Model selection**: The model may not be the best choice for the problem, or the hyperparameters may not be tuned correctly.\n",
      "\n",
      "To address these issues, you can try the following:\n",
      "\n",
      "1. **Regularization**: Add regularization techniques, such as L1 or L2 regularization, dropout, or early stopping, to prevent overfitting.\n",
      "2. **Data preprocessing**: Preprocess the data to handle imbalanced classes, missing values, or outliers.\n",
      "3. **Feature engineering**: Create new features that capture non-linear relationships between the features and the target variable.\n",
      "4. **Model selection**: Try different models or ensemble methods to find the best one for the problem.\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "High AUC (Area Under the Curve) but poor calibration in a model can occur due to:\n",
      "\n",
      "1. **Threshold effect**: A model with high AUC may still be poorly calibrated if it's not optimized for a specific decision threshold. AUC measures the model's ability to rank samples, but real-world decisions often require a specific probability or threshold.\n",
      "2. **Overfitting**: A model that's overly complex or has too many features may have high AUC on the training data but fail to generalize well to new data, leading to poor calibration.\n",
      "3. **Class imbalance**: When one class is significantly more common than the other, a model may prioritize that class, leading to poor calibration and high AUC.\n",
      "4. **Non-linear relationships**: A model that's not designed to handle non-linear relationships between features and the target variable may struggle with calibration, even if it has high AUC.\n",
      "5. **Data distribution**: A model may perform well on a specific data distribution (e.g., uniform, normal) but fail to generalize to other distributions, leading to poor calibration.\n",
      "6. **Evaluation metrics**: Using AUC as the sole evaluation metric can mask issues with calibration. Consider using additional metrics like Brier score, calibration plots, or decision threshold analysis.\n",
      "7. **Model type**: Certain model types (e.g., decision trees, random forests) are more prone to calibration issues than others (e.g., logistic regression, neural networks).\n",
      "8. **Hyperparameter tuning**: Failing to properly tune hyperparameters can lead to poor calibration, even if the model has high AUC.\n",
      "\n",
      "To address these issues, consider:\n",
      "\n",
      "* Using a calibration metric (e.g., Brier score, expected calibration error) in addition to AUC.\n",
      "* Implementing techniques like Platt scaling, isotonic regression, or temperature scaling to improve calibration.\n",
      "* Regularly monitoring and adjusting the decision threshold.\n",
      "* Using techniques\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "High AUC (Area Under the Receiver Operating Characteristic Curve) indicates good classification performance, but poor calibration means the model's confidence is not aligned with its actual accuracy. This discrepancy can arise from:\n",
      "\n",
      "1. **Overconfidence**: The model is overly confident in its predictions, leading to a high AUC but underestimating the true probabilities of the classes.\n",
      "2. **Thresholding**: AUC is sensitive to the choice of threshold, which may not reflect the actual decision boundary. A model with a high AUC might still be poorly calibrated if the threshold is not optimal.\n",
      "3. **Class imbalance**: When one class is significantly more frequent than the others, the model may focus on that class, leading to high AUC but poor calibration for the minority classes.\n",
      "4. **Non-linear relationships**: Complex relationships between features and the target variable can lead to poor calibration, even with a high AUC.\n",
      "5. **Data distribution**: A model trained on a specific data distribution may not generalize well to new data, resulting in poor calibration.\n",
      "6. **Model complexity**: Overfitting or underfitting can lead to poor calibration, even if the AUC is high.\n",
      "7. **Evaluation metrics**: Using AUC as the sole evaluation metric can mask poor calibration. Consider using other metrics, such as Brier score, log loss, or expected calibration error.\n",
      "\n",
      "To address poor calibration, consider:\n",
      "\n",
      "1. **Post-processing**: Apply a threshold or adjust the confidence levels to match the actual accuracy.\n",
      "2. **Ensemble methods**: Combine multiple models to reduce overconfidence and improve calibration.\n",
      "3. **Regularization**: Add regularization terms to the loss function to prevent overfitting.\n",
      "4. **Data augmentation**: Increase the size and diversity of the training data to improve generalization.\n",
      "5. **Evaluation metrics**: Use a combination of metrics, including AUC, Brier score, and expected calibration error, to\n",
      "\n",
      "--- JUDGE: original vs qlora ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_original\": 6.0,\n",
      "  \"score_qlora\": 8.0,\n",
      "  \"rationale\": \"The qlora answer provides a more precise and finance-relevant explanation, including the important distinction between ranking performance (AUC) and probability calibration, and suggests specific calibration techniques like Platt scaling and isotonic regression. The original answer is broader but less focused on calibration-specific issues and lacks mention of calibration metrics and post-processing methods, reducing its practical usefulness.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"dpo\",\n",
      "  \"score_original\": 6.0,\n",
      "  \"score_dpo\": 8.0,\n",
      "  \"rationale\": \"The dpo answer provides a more precise explanation of the difference between AUC and calibration, correctly noting that AUC is threshold-independent and that calibration relates to probability estimates. It also suggests relevant evaluation metrics and practical remedies, improving depth and usefulness. The original answer contains some inaccuracies (e.g., AUC sensitivity to threshold) and less clarity on calibration specifics.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 8.0,\n",
      "  \"score_dpo\": 6.0,\n",
      "  \"rationale\": \"Qlora provides a more comprehensive and detailed explanation of why a model might have high AUC but poor calibration, including specific causes and practical remedies. Dpo's answer is less precise, contains some inaccuracies (e.g., AUC is threshold-independent), and offers less depth on calibration techniques.\"\n",
      "}\n",
      "\n",
      "====================================================================================================\n",
      "Q5: Why can a high Sharpe ratio be misleading in small samples?\n",
      "====================================================================================================\n",
      "\n",
      "--- ORIGINAL ANSWER --------------------------------------------------\n",
      "A high Sharpe ratio can be misleading in small samples because it is sensitive to the volatility of the sample period. In small samples, the ratio of excess returns to volatility (Sharpe ratio) can be skewed by a single event or a short-term market fluctuation.\n",
      "\n",
      "There are two main reasons for this:\n",
      "\n",
      "1. **Noise**: Small samples are more susceptible to noise, which can lead to inaccurate estimates of volatility and returns. This noise can cause the Sharpe ratio to be artificially high or low, leading to incorrect conclusions.\n",
      "2. **Sampling error**: The Sharpe ratio is a sample statistic, and like all sample statistics, it is subject to sampling error. In small samples, the sampling error can be large, leading to a high Sharpe ratio that may not reflect the true underlying performance of the investment.\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "1. **Use larger samples**: If possible, use longer time periods or more data points to reduce the impact of noise and sampling error.\n",
      "2. **Consider the confidence interval**: Calculate the confidence interval for the Sharpe ratio to understand the uncertainty surrounding the estimate.\n",
      "3. **Compare to benchmarks**: Compare the Sharpe ratio to that of a benchmark or a peer group to put it into context.\n",
      "4. **Use other metrics**: Consider using other metrics, such as the Sortino ratio or the Calmar ratio, which are less sensitive to volatility and may provide a more accurate picture of investment performance.\n",
      "\n",
      "By being aware of these limitations, investors and analysts can make more informed decisions when interpreting the Sharpe ratio in small samples.\n",
      "\n",
      "--- QLORA ANSWER --------------------------------------------------\n",
      "A high Sharpe ratio in small samples can be misleading due to the following reasons:\n",
      "\n",
      "1. **Noise and sampling error**: Small samples are more susceptible to noise and sampling error, which can lead to overestimation of returns and underestimation of volatility. This can result in an artificially high Sharpe ratio.\n",
      "2. **Volatility clustering**: Small samples may not capture the full range of volatility, leading to an underestimation of volatility and an overestimation of the Sharpe ratio.\n",
      "3. **Non-stationarity**: Small samples may not be representative of the underlying process, and the Sharpe ratio may not be a reliable measure of risk-adjusted performance.\n",
      "4. **Overfitting**: Small samples can lead to overfitting, where the model is too closely tied to the specific data and does not generalize well to new data.\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "1. **Increase the sample size**: Larger samples provide a more robust estimate of the Sharpe ratio.\n",
      "2. **Use robust estimation methods**: Techniques like the median Sharpe ratio or the rolling Sharpe ratio can be more robust to noise and sampling error.\n",
      "3. **Consider alternative metrics**: Other metrics, such as the Sortino ratio or the Omega ratio, may be more suitable for small samples.\n",
      "4. **Use out-of-sample validation**: Validate the Sharpe ratio on a separate, unseen dataset to ensure it generalizes well.\n",
      "\n",
      "--- DPO ANSWER --------------------------------------------------\n",
      "A high Sharpe ratio in small samples can be misleading due to the following reasons:\n",
      "\n",
      "1. **Volatility clustering**: Small samples tend to capture periods of high volatility, which can inflate the Sharpe ratio. This can lead to overestimation of the strategy's risk-adjusted returns.\n",
      "2. **Sampling error**: Small samples are more susceptible to sampling error, which can result in an overestimation of the true Sharpe ratio. As the sample size increases, the sampling error decreases, and the Sharpe ratio becomes more reliable.\n",
      "3. **Data mining bias**: Small samples can lead to data mining bias, where the strategy's performance is optimized to the specific data set used. This can result in an overestimation of the strategy's Sharpe ratio.\n",
      "4. **Overfitting**: Small samples can lead to overfitting, where the strategy is too closely tailored to the specific data set used, resulting in poor performance on new, unseen data.\n",
      "5. **Survivorship bias**: Small samples may not capture the full range of possible outcomes, including those that led to the strategy's elimination (e.g., due to poor performance or liquidity issues).\n",
      "\n",
      "To mitigate these issues, it's essential to:\n",
      "\n",
      "* Use larger sample sizes to reduce sampling error and increase the reliability of the Sharpe ratio.\n",
      "* Implement robustness checks, such as bootstrapping or Monte Carlo simulations, to assess the strategy's performance under different scenarios.\n",
      "* Consider using alternative risk-adjusted metrics, such as the Sortino ratio or the Omega ratio, which are less sensitive to volatility clustering.\n",
      "* Ensure that the sample is representative of the full range of possible outcomes, including those that led to the strategy's elimination.\n",
      "\n",
      "--- JUDGE: original vs qlora ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_original\": 8.0,\n",
      "  \"score_qlora\": 9.0,\n",
      "  \"rationale\": \"Both answers correctly identify noise and sampling error as key issues with high Sharpe ratios in small samples, but qlora provides additional depth by mentioning volatility clustering, non-stationarity, and overfitting, enhancing practical usefulness. The mitigation strategies in qlora are also more nuanced, including robust estimation methods and out-of-sample validation, which adds valuable finance depth.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: original vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"original\",\n",
      "  \"score_original\": 9.0,\n",
      "  \"score_dpo\": 7.0,\n",
      "  \"rationale\": \"The original answer is factually accurate, clearly explains the key statistical issues (noise and sampling error), and provides practical mitigation steps with clarity. The dpo answer introduces some less relevant or less directly related concepts (e.g., survivorship bias, overfitting) that are not typically primary reasons why a high Sharpe ratio is misleading in small samples, reducing its focus and clarity.\"\n",
      "}\n",
      "\n",
      "--- JUDGE: qlora vs dpo ----------------------------------------------------\n",
      "{\n",
      "  \"winner\": \"qlora\",\n",
      "  \"score_qlora\": 9.0,\n",
      "  \"score_dpo\": 7.0,\n",
      "  \"rationale\": \"Qlora's answer is more factually accurate and comprehensive, correctly identifying key issues like noise, sampling error, non-stationarity, and overfitting, and providing practical mitigation strategies. Dpo's answer includes some inaccuracies (e.g., volatility clustering inflating Sharpe ratio is misstated) and less clarity, though it adds useful points like survivorship bias and robustness checks.\"\n",
      "}\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY\n",
      "elapsed_sec=457.2\n",
      "Win counts:\n",
      "  original: 2\n",
      "     qlora: 8\n",
      "       dpo: 3\n",
      "       tie: 2\n",
      "Avg scores:\n",
      "  original: 7.3\n",
      "     qlora: 8.4\n",
      "       dpo: 7.6\n",
      "\n",
      "Saved: eval_3way_results.json\n"
     ]
    }
   ],
   "source": [
    "# 3-way Finetuning eval (OOM-safe, single-model, adapter swapping)\n",
    "# Compare:\n",
    "#  1) ORIGINAL base: unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\n",
    "#  2) QLoRA adapter: llama31-8b-finance-qlora-lora\n",
    "#  3) DPO LoRA adapter: llama31-8b-finance-dpo-lora-kevin\n",
    "#\n",
    "# Judge: GPT-4.1-mini (recommended). No extra local judge model loaded.\n",
    "#\n",
    "# Output:\n",
    "#  - per-question answers for all 3\n",
    "#  - pairwise judge results: original_vs_qlora, original_vs_dpo, qlora_vs_dpo\n",
    "#  - aggregates: win counts + avg scores\n",
    "#  - saves: eval_3way_results.json\n",
    "#\n",
    "# pip install -U unsloth transformers peft accelerate bitsandbytes torch openai python-dotenv\n",
    "\n",
    "import os, json, re, time, math, asyncio\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from peft import PeftModel\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "BASE_MODEL_ID = \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\"\n",
    "\n",
    "ADAPTERS = {\n",
    "    \"qlora\": \"llama31-8b-finance-qlora-lora\",        # local folder OR HF repo id\n",
    "    \"dpo\":   \"llama31-8b-finance-dpo-lora-kevin\",    # local folder OR HF repo id\n",
    "}\n",
    "\n",
    "OUT_JSON = \"eval_results_alignment_ft_vs_base_vs_dpo.json\"\n",
    "\n",
    "MAX_SEQ_LEN = 4096\n",
    "MAX_NEW_TOKENS_ANS = 384\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.9\n",
    "SEED = 42\n",
    "\n",
    "JUDGE_MODEL = \"gpt-4.1-mini\"\n",
    "JUDGE_MAX_TOKENS = 220\n",
    "JUDGE_CONCURRENCY = 8\n",
    "JUDGE_RETRIES = 3\n",
    "\n",
    "SYSTEM_ANSWER = \"You are a helpful finance and investing assistant. Be accurate, concise, and practical.\"\n",
    "JUDGE_SYSTEM = (\n",
    "    \"You are a strict evaluator for finance/investing answers. \"\n",
    "    \"Prioritize: (1) factual correctness, (2) finance depth, (3) practical usefulness, (4) clarity. \"\n",
    "    \"Return ONLY valid JSON, no extra text.\"\n",
    ")\n",
    "\n",
    "test_questions = [\n",
    "    \"Explain look-ahead bias in backtesting and how to avoid it.\",\n",
    "    \"What is survivorship bias and why does it matter in equity datasets?\",\n",
    "    \"Compare VaR and Expected Shortfall conceptually. When is ES preferred?\",\n",
    "    \"Why might a model have high AUC but poor calibration?\",\n",
    "    \"Why can a high Sharpe ratio be misleading in small samples?\",\n",
    "]\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Model load (ONE TIME)\n",
    "# -----------------------------\n",
    "print(\"Loading base model once...\")\n",
    "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=BASE_MODEL_ID,\n",
    "    max_seq_length=MAX_SEQ_LEN,\n",
    "    load_in_4bit=True,\n",
    "    dtype=None,\n",
    ")\n",
    "base_model = FastLanguageModel.for_inference(base_model)\n",
    "\n",
    "# Turn base into a PEFT-wrapped model once so we can load adapters into it\n",
    "# (this avoids loading multiple base copies)\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTERS[\"qlora\"])  # temporary\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "model.set_adapter(\"default\")  # adapter name in PEFT is often \"default\"\n",
    "\n",
    "# Load second adapter into same model under a different name\n",
    "# If load_adapter isn't available in your peft version, we'll fallback to loading via from_pretrained into the SAME wrapper.\n",
    "if hasattr(model, \"load_adapter\"):\n",
    "    model.load_adapter(ADAPTERS[\"dpo\"], adapter_name=\"dpo\")\n",
    "else:\n",
    "    # Fallback: attach second adapter using peft's loading API\n",
    "    # This is a safe, common workaround if your peft is older.\n",
    "    from peft import PeftConfig\n",
    "    # This will still reuse the same base weights; adapter weights are added.\n",
    "    model = PeftModel.from_pretrained(model, ADAPTERS[\"dpo\"], adapter_name=\"dpo\")\n",
    "    model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Rename the first adapter to \"qlora\" if it's still \"default\"\n",
    "# (Some PEFT versions keep it as \"default\". We'll map both cases.)\n",
    "available = list(getattr(model, \"peft_config\", {}).keys())\n",
    "if \"qlora\" not in available:\n",
    "    if \"default\" in available:\n",
    "        qlora_adapter_name = \"default\"\n",
    "    else:\n",
    "        # take first adapter as qlora\n",
    "        qlora_adapter_name = available[0] if available else \"default\"\n",
    "else:\n",
    "    qlora_adapter_name = \"qlora\"\n",
    "\n",
    "dpo_adapter_name = \"dpo\"\n",
    "\n",
    "print(\"Adapters available:\", list(getattr(model, \"peft_config\", {}).keys()))\n",
    "print(\"Using qlora adapter name:\", qlora_adapter_name)\n",
    "print(\"Using dpo adapter name:\", dpo_adapter_name)\n",
    "\n",
    "# -----------------------------\n",
    "# Generation utilities\n",
    "# -----------------------------\n",
    "def _chat_input_ids(system: str, user: str) -> torch.Tensor:\n",
    "    messages = [{\"role\": \"system\", \"content\": system}, {\"role\": \"user\", \"content\": user}]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_answer_variant(variant: str, question: str) -> str:\n",
    "    \"\"\"\n",
    "    variant: \"original\" | \"qlora\" | \"dpo\"\n",
    "    Uses the SAME model in memory; swaps adapters.\n",
    "    \"\"\"\n",
    "    # switch adapter\n",
    "    if variant == \"original\":\n",
    "        # disable adapters\n",
    "        if hasattr(model, \"disable_adapter\"):\n",
    "            with model.disable_adapter():\n",
    "                return _generate(question)\n",
    "        else:\n",
    "            # older PEFT: set_adapter(None) may not exist; best-effort by using base_model directly\n",
    "            return _generate(question, use_base_only=True)\n",
    "\n",
    "    elif variant == \"qlora\":\n",
    "        model.set_adapter(qlora_adapter_name)\n",
    "        return _generate(question)\n",
    "\n",
    "    elif variant == \"dpo\":\n",
    "        model.set_adapter(dpo_adapter_name)\n",
    "        return _generate(question)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown variant: {variant}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def _generate(question: str, use_base_only: bool = False) -> str:\n",
    "    m = base_model if use_base_only else model\n",
    "    input_ids = _chat_input_ids(SYSTEM_ANSWER, question).to(m.device)\n",
    "    in_len = input_ids.shape[-1]\n",
    "\n",
    "    out = m.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=torch.ones_like(input_ids, device=m.device),\n",
    "        max_new_tokens=MAX_NEW_TOKENS_ANS,\n",
    "        temperature=TEMPERATURE,\n",
    "        do_sample=(TEMPERATURE > 0),\n",
    "        top_p=TOP_P,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    # decode only new tokens\n",
    "    new_tokens = out[0, in_len:]\n",
    "    text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# Judge (GPT) utilities\n",
    "# -----------------------------\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "def _extract_json(text: str) -> Optional[Dict[str, Any]]:\n",
    "    if not text:\n",
    "        return None\n",
    "    text = text.strip()\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.search(r\"\\{[\\s\\S]*?\\}\", text)\n",
    "    if m:\n",
    "        s = m.group(0)\n",
    "        s = re.sub(r\",\\s*([}\\]])\", r\"\\1\", s)\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _coerce_winner(w: Any, a: str, b: str) -> str:\n",
    "    if w is None:\n",
    "        return \"tie\"\n",
    "    s = str(w).strip().lower()\n",
    "    if s == \"tie\":\n",
    "        return \"tie\"\n",
    "    if s in (\"a\", a.lower()):\n",
    "        return a\n",
    "    if s in (\"b\", b.lower()):\n",
    "        return b\n",
    "    return \"tie\"\n",
    "\n",
    "def _coerce_score(x: Any) -> Optional[float]:\n",
    "    try:\n",
    "        v = float(x)\n",
    "        if math.isfinite(v):\n",
    "            return max(1.0, min(10.0, v))\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "async def judge_pair(question: str, ansA: str, ansB: str, labelA: str, labelB: str) -> Dict[str, Any]:\n",
    "    prompt = f\"\"\"\n",
    "Grade two answers to the same finance/investing question.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer {labelA}:\n",
    "{ansA}\n",
    "\n",
    "Answer {labelB}:\n",
    "{ansB}\n",
    "\n",
    "Return ONLY strict JSON:\n",
    "{{\n",
    "  \"winner\": \"{labelA}\" or \"{labelB}\" or \"tie\",\n",
    "  \"score_{labelA}\": 1-10,\n",
    "  \"score_{labelB}\": 1-10,\n",
    "  \"rationale\": \"1-3 sentences\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, JUDGE_RETRIES + 1):\n",
    "        try:\n",
    "            r = await client.chat.completions.create(\n",
    "                model=JUDGE_MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": JUDGE_SYSTEM},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=JUDGE_MAX_TOKENS,\n",
    "            )\n",
    "            raw = (r.choices[0].message.content or \"\").strip()\n",
    "            obj = _extract_json(raw)\n",
    "            if isinstance(obj, dict):\n",
    "                winner = _coerce_winner(obj.get(\"winner\"), labelA, labelB)\n",
    "                sA = _coerce_score(obj.get(f\"score_{labelA}\"))\n",
    "                sB = _coerce_score(obj.get(f\"score_{labelB}\"))\n",
    "                rationale = str(obj.get(\"rationale\", \"\")).strip()\n",
    "                return {\n",
    "                    \"final\": {\"winner\": winner, f\"score_{labelA}\": sA, f\"score_{labelB}\": sB, \"rationale\": rationale},\n",
    "                    \"raw\": raw,\n",
    "                    \"parsed_debug\": obj,\n",
    "                }\n",
    "            last_err = f\"Unparsable judge JSON (head): {raw[:200]}\"\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "        await asyncio.sleep(0.4 * attempt)\n",
    "\n",
    "    return {\n",
    "        \"final\": {\"winner\": \"tie\", f\"score_{labelA}\": None, f\"score_{labelB}\": None, \"rationale\": \"\"},\n",
    "        \"raw\": \"\",\n",
    "        \"parsed_debug\": None,\n",
    "        \"error\": last_err,\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# Main eval\n",
    "# -----------------------------\n",
    "async def main():\n",
    "    pairings = [(\"original\", \"qlora\"), (\"original\", \"dpo\"), (\"qlora\", \"dpo\")]\n",
    "\n",
    "    results = []\n",
    "    win_counts = {\"original\": 0, \"qlora\": 0, \"dpo\": 0, \"tie\": 0}\n",
    "    score_sums  = {\"original\": 0.0, \"qlora\": 0.0, \"dpo\": 0.0}\n",
    "    score_counts= {\"original\": 0, \"qlora\": 0, \"dpo\": 0}\n",
    "\n",
    "    start = time.time()\n",
    "    sem = asyncio.Semaphore(JUDGE_CONCURRENCY)\n",
    "\n",
    "    async def judge_with_sem(q, a, b, la, lb):\n",
    "        async with sem:\n",
    "            return await judge_pair(q, a, b, la, lb)\n",
    "\n",
    "    for i, q in enumerate(test_questions, 1):\n",
    "        print(f\"\\n{'='*100}\\nQ{i}: {q}\\n{'='*100}\")\n",
    "\n",
    "        # Generate 3 answers (sequential, CUDA-safe)\n",
    "        answers = {}\n",
    "        for v in [\"original\", \"qlora\", \"dpo\"]:\n",
    "            ans = generate_answer_variant(v, q)\n",
    "            answers[v] = ans\n",
    "            print(f\"\\n--- {v.upper()} ANSWER --------------------------------------------------\")\n",
    "            print(ans)\n",
    "\n",
    "        # Judge pairwise (concurrent across 3 pairings)\n",
    "        judge_tasks = []\n",
    "        for a, b in pairings:\n",
    "            judge_tasks.append(judge_with_sem(q, answers[a], answers[b], a, b))\n",
    "\n",
    "        judge_outs = await asyncio.gather(*judge_tasks)\n",
    "\n",
    "        judges = {}\n",
    "        for (a, b), jr in zip(pairings, judge_outs):\n",
    "            key = f\"{a}_vs_{b}\"\n",
    "            judges[key] = jr\n",
    "            final = jr[\"final\"]\n",
    "            print(f\"\\n--- JUDGE: {a} vs {b} ----------------------------------------------------\")\n",
    "            print(json.dumps(final, indent=2))\n",
    "\n",
    "            # aggregate\n",
    "            winner = final.get(\"winner\", \"tie\")\n",
    "            win_counts[winner] = win_counts.get(winner, 0) + 1\n",
    "\n",
    "            for name in (a, b):\n",
    "                sv = final.get(f\"score_{name}\", None)\n",
    "                if sv is not None:\n",
    "                    score_sums[name] += float(sv)\n",
    "                    score_counts[name] += 1\n",
    "\n",
    "        results.append({\"question\": q, \"answers\": answers, \"judges\": judges})\n",
    "\n",
    "        # free some KV cache between questions\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    avg_scores = {k: (score_sums[k] / score_counts[k] if score_counts[k] else None) for k in score_sums}\n",
    "\n",
    "    print(f\"\\n\\n{'='*100}\\nSUMMARY\")\n",
    "    print(f\"elapsed_sec={elapsed:.1f}\")\n",
    "    print(\"Win counts:\")\n",
    "    for k, v in win_counts.items():\n",
    "        print(f\"  {k:>8}: {v}\")\n",
    "    print(\"Avg scores:\")\n",
    "    for k, v in avg_scores.items():\n",
    "        print(f\"  {k:>8}: {v if v is not None else 'n/a'}\")\n",
    "\n",
    "    out = {\n",
    "        \"base_model_id\": BASE_MODEL_ID,\n",
    "        \"adapters\": ADAPTERS,\n",
    "        \"gen_config\": {\n",
    "            \"max_new_tokens_answer\": MAX_NEW_TOKENS_ANS,\n",
    "            \"temperature\": TEMPERATURE,\n",
    "            \"top_p\": TOP_P,\n",
    "            \"seed\": SEED,\n",
    "            \"max_seq_len\": MAX_SEQ_LEN,\n",
    "        },\n",
    "        \"judge\": {\"model\": JUDGE_MODEL},\n",
    "        \"pairings\": pairings,\n",
    "        \"results\": results,\n",
    "        \"summary\": {\n",
    "            \"elapsed_sec\": elapsed,\n",
    "            \"win_counts\": win_counts,\n",
    "            \"avg_scores\": avg_scores,\n",
    "            \"score_counts\": score_counts,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    with open(OUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"\\nSaved: {OUT_JSON}\")\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
